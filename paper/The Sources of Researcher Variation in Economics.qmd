---
title: "The Sources of Researcher Variation in Economics\\thanks{Corresponding author Nick Huntington-Klein, nhuntington-klein@seattleu.edu, +1 (206) 296-5815. Department of Economics, Seattle University, 901 12th Ave., Seattle, WA, 98122. Huntington-Klein and Pörtner are the project organizers. This project was supported by the Alfred P. Sloan foundation grant G-2022-19377. The Seattle University IRB determined this study to be exempt from IRB review in accordance with federal regulation criteria. We would like to thank Kian Farzaneh, Amrapali Samanta, and Erica Long for research assistance and seminar participants at the Center for Education data and Research (CEDR)/Center for Analysis of Longitudinal Data in Education Research (CALDER) at the University of Washington, Institut national de recherche en sciences et technologies du numérique (INRIA), La Universidad de las Americas, Ludwig-Maximilians-Universität München (LMU Munich), Western Washington University, and the 2024 Annual Meeting of WEAI for helpful comments and suggestions. We would also like to thank the researchers Mira Chaskes, Jennifer A. Heissel, Elaine L. Hill, Rajius Idzalika, Joshua D. Merfeld, and Ethan Sawyer, who contributed but did not want an authorship slot, the researchers who wished to remain anonymous, and the researchers who enlisted in the study but were ineligible or unable to complete all three rounds of the project. Data and code for this project are available at \\url{https://github.com/many-economists/analysis}. Preregistration for the project is available at OSF: \\url{https://doi.org/10.17605/OSF.IO/CJ9YX}. Suggested citation: Huntington-Klein, Pörtner, et al. (2025), \"The Sources of Researcher Variation in Economics.\"}"
author:
  - id: HK1
    number: 1
    name: Nick Huntington-Klein
    email: nhuntington-klein@seattleu.edu
    phone: 1-206-296-5815
    fax: NONE
    orcid: 0000-0002-7352-3991
    degrees: PhD
    attributes:
      corresponding: True
    affiliations:
      - id: NHK1_1
        number: 1
        name: Seattle University
        department: Department of Economics
        address: 901 12th Ave, Seattle, WA, 98122
  - id: CP2
    number: 2
    name: Claus C. Pörtner
    email: cportner@seattleu.edu
    phone: 1-206-296-2593
    fax: NONE
    orcid: 0000-0001-8052-9462
    degrees: PhD
    attributes:
      corresponding: True
    affiliations:
      - id: CP1_1
        number: 1
        name: Seattle University
        department: Department of Economics
        address: 901 12th Ave, Seattle, WA, 98122
      - id: CP1_2
        number: 2
        name: Center for Studies in Demography and Ecology 
        address: University of Washington, Seattle, WA, 98195
  - id: Acharya3
    number: 3
    name: Yubraj Acharya
    email: yua36@psu.edu
    phone: 8148656898
    fax: NONE
    orcid: 0000-0002-9003-636X 
    degrees: PhD
    attributes:
      corresponding: False
    affiliations:
      - id: Acharya3_1
        number: 1
        name: The Pennsylvania State University
        department: Department of Health Policy and Administration
        address: 601 Ford Building, University Park, PA 16801
  - id: Adamkovic4
    number: 4
    name: Matus Adamkovic
    email: matus.m.adamkovic@jyu.fi
    phone: +421908330003
    fax: NONE
    orcid: 0000-0002-9648-9108
    degrees: PhD
    attributes:
      corresponding: False
    affiliations:
      - id: Adamkovic4_1
        number: 1
        name: Slovak Academy of Sciences
        department: Centre of Social and Psychological Sciences
        address: Šancová 56, 81105 Bratislava, Slovakia
      - id: Adamkovic4_2
        number: 2
        name:  University of Jyväskylä
        department: Faculty of Humanities and Social Sciences
        address: Seminaarinkatu 15, 40014 Jyväskylän yliopisto, Finland
      - id: Adamkovic4_3
        number: 3
        name:  Charles University
        department: Faculty of Education
        address: Magdalény Rettigové 4, 11000 Prague, Czech Republic
  - id: Adema5
    number: 5
    name: Joop Adema
    email: adema@ifo.de
    phone: +31623877422
    fax: NONE
    orcid: NONE
    degrees: Master's Degree
    attributes:
      corresponding: False
    affiliations:
      - id: Adema5_1
        number: 1
        name: ifo Institute
        department: NONE
        address: Poschingerstrasse 5,  81679 München, Germany
  - id: Agasa6
    number: 6
    name: Lameck Ondieki Agasa
    email: lagasa@kisiiuniversity.ac.ke
    phone: +254721570048
    fax: NONE
    orcid: 0000-0002-3740-8865
    degrees: Master's Degree
    attributes:
      corresponding: False
    affiliations:
      - id: Agasa6_1
        number: 1
        name: Kisii University
        department: Department of Mathematics and Actuarial Sciences
        address: P.O. Box 408-40200, Kisii University
  - id: Ahmad7
    number: 7
    name: Imtiaz Ahmad
    email: imtiaz.ahmad@s3h.nust.edu.pk
    phone: +92 3334747147
    fax: NONE
    orcid: 0000-0002-6329-5964
    degrees: PhD
    attributes:
      corresponding: False
    affiliations:
      - id: Ahmad7_1
        number: 1
        name: National University of Sciences and Technology
        department: Department of Economics
        address: NONE
  - id: Akbulut-Yuksel8
    number: 8
    name: Mevlude Akbulut-Yuksel
    email: mevlude@dal.ca
    phone: +1-902-499-2567
    fax: NONE
    orcid: NONE
    degrees: PhD
    attributes:
      corresponding: False
    affiliations:
      - id: Akbulut-Yuksel8_1
        number: 1
        name: Dalhousie University; IZA
        department: Department of Economics
        address: 6214 University Avenue Halifax, Nova Scotia B3H 4R2 CANADA
  - id: Andresen9
    number: 9
    name: Martin Eckhoff Andresen
    email: m.e.andresen@econ.uio.no
    phone: +4740239166
    fax: NONE
    orcid: 0000-0002-5230-1580
    degrees: PhD
    attributes:
      corresponding: False
    affiliations:
      - id: Andresen9_1
        number: 1
        name: University of Oslo
        department: Department of Economics
        address: Moltke Moes vei 31, 0851 Oslo, Norway
  - id: Angenendt10
    number: 10
    name: David Angenendt
    email: david.angenendt@tum.de
    phone: +498928925394
    fax: NONE
    orcid: 0000-0001-9583-6289
    degrees: PhD
    attributes:
      corresponding: False
    affiliations:
      - id: Angenendt10_1
        number: 1
        name: Technical University of Munich
        department: TUM School of Management
        address: Arcisstr. 21, 80333 Munich, Germany
      - id: Angenendt10_2
        number: 2
        name:  University of Cambridge
        department: Centre for Business Research
        address: 11-12 Trumpington Street, Cambridge, CB2 1AG, UK
  - id: Antón11
    number: 11
    name: José-Ignacio Antón
    email: janton@usal.es
    phone: 0034645758310
    fax: NONE
    orcid: 0000-0001-9623-3121
    degrees: PhD
    attributes:
      corresponding: False
    affiliations:
      - id: Antón11_1
        number: 1
        name: University of Salamanca
        department: Department of Applied Economics
        address: Departamento de Economía Aplicada, Facultad de Derecho, Campus Miguel de Unamuno, s/n, 37007 Salamanca (Spain)
  - id: Arenas12
    number: 12
    name: Andreu Arenas
    email: andreu.arenas@ub.edu
    phone: +34650513478
    fax: NONE
    orcid: 0000-0002-0185-6017
    degrees: PhD
    attributes:
      corresponding: False
    affiliations:
      - id: Arenas12_1
        number: 1
        name: University of Barcelona
        department: Economics Department and Institut d'Economia de Barcelona
        address: J.M. Keynes 1-11, 08034 Barcelona (Spain)
  - id: Aslim13
    number: 13
    name: Erkmen Giray Aslim
    email: aslime@gvsu.edu
    phone: 603-205-3708
    fax: NONE
    orcid: NONE
    degrees: PhD
    attributes:
      corresponding: False
    affiliations:
      - id: Aslim13_1
        number: 1
        name: Grand Valley State University
        department: Department of Economics
        address: 3120 L. William Seidman Center, 50 Front Avenue SW, Grand Rapids, MI 49504
  - id: Avdeev14
    number: 14
    name: Stanislav Avdeev
    email: stnavdeev@gmail.com
    phone: +31651865403
    fax: NONE
    orcid: 0000-0002-3130-1418
    degrees: Master's Degree
    attributes:
      corresponding: False
    affiliations:
      - id: Avdeev14_1
        number: 1
        name: University of Amsterdam
        department: Amsterdam School of Economics
        address: Roetersstraat 11, 1018 WB Amsterdam, the Netherlands
  - id: Bacher-Hicks15
    number: 15
    name: Andrew Bacher-Hicks
    email: abhicks@bu.edu
    phone: 617-358-1388
    fax: NONE
    orcid: NONE
    degrees: PhD
    attributes:
      corresponding: False
    affiliations:
      - id: Bacher-Hicks15_1
        number: 1
        name: Boston University
        department: Wheelock College of Education and Human Development
        address: 2 Silber Way, Boston, MA 02215
  - id: Baker16
    number: 16
    name: Bradley J. Baker
    email: bradley.baker@temple.edu
    phone: 215.204.6163
    fax: NONE
    orcid: 0000-0002-1697-4198
    degrees: PhD
    attributes:
      corresponding: False
    affiliations:
      - id: Baker16_1
        number: 1
        name: Temple University
        department: Department of Sport, Tourism and Hospitality Management
        address: 1810 N. 13th St. Speakman Hall 111 Philadelphia, PA 19122 USA
  - id: Bandara17
    number: 17
    name: Imesh Nuwan Bandara
    email: imeshnu1@gmail.com
    phone: 8572891428
    fax: NONE
    orcid: NONE
    degrees: Master's Degree
    attributes:
      corresponding: False
    affiliations:
      - id: Bandara17_1
        number: 1
        name: Independent
        department: NONE
        address: NONE
  - id: Bansal18
    number: 18
    name: Avijit Bansal
    email: avijit@iimcal.ac.in
    phone: +91 8976-37-2927
    fax: NONE
    orcid: 0000-0002-8873-9373
    degrees: PhD
    attributes:
      corresponding: False
    affiliations:
      - id: Bansal18_1
        number: 1
        name: Indian Institute of Management Calcutta
        department: Finance & Control Area
        address: Indian Institute of Management Calcutta, DH road, Kolkata, India - 700104
  - id: Bartram19
    number: 19
    name: David Bartram
    email: d.bartram@le.ac.uk
    phone: +447909734199
    fax: NONE
    orcid: 0000-0002-7278-2270
    degrees: PhD
    attributes:
      corresponding: False
    affiliations:
      - id: Bartram19_1
        number: 1
        name: University of Leicester
        department: Department of Sociology
        address: University Road, Leicester LE2 1TL, United Kingdom
  - id: Bech-Wysocka20
    number: 20
    name: Katarzyna Bech-Wysocka
    email: kbech@sgh.waw.pl
    phone: +48 888 652 596
    fax: NONE
    orcid: 0000-0001-5302-9526
    degrees: PhD
    attributes:
      corresponding: False
    affiliations:
      - id: Bech-Wysocka20_1
        number: 1
        name: Warsaw School of Economics
        department: Institute of Econometrics
        address: al. Niepodleglosci 162, 02-554 Warsaw, Poland
      - id: Bech-Wysocka20_2
        number: 2
        name:  FAME|GRAPE
        department: NONE
        address: ul. Koszykowa 59/7, 00-660 Warsaw, Poland
  - id: Bennett21
    number: 21
    name: Christopher Troy Bennett
    email: cbennett@rti.org
    phone: 919-949-5343
    fax: NONE
    orcid: 0000-0002-8910-8098
    degrees: PhD
    attributes:
      corresponding: False
    affiliations:
      - id: Bennett21_1
        number: 1
        name: RTI International
        department: NONE
        address: 3040 E. Cornwallis Rd, Research Triangle Park, NC 27709
  - id: Berha22
    number: 22
    name: Andu N. Berha
    email: aberha@ualberta.ca
    phone: 5879262893
    fax: NONE
    orcid: 0000-0003-4985-4990
    degrees: Master's Degree
    attributes:
      corresponding: False
    affiliations:
      - id: Berha22_1
        number: 1
        name: University of Alberta
        department: NONE
        address: Edmonton, Alberta, T6G2H1, Canada
  - id: Berniell23
    number: 23
    name: Inés Berniell
    email: ines.berniell@econo.unlp.edu.ar
    phone: +5491132959784
    fax: NONE
    orcid: 0000-0002-2268-2757
    degrees: PhD
    attributes:
      corresponding: False
    affiliations:
      - id: Berniell23_1
        number: 1
        name: Universidad Nacional de La Plata
        department: Department of Economics
        address: Calle 6 777. La Plata, Buenos Aires, Argentina
      - id: Berniell23_2
        number: 2
        name:  CEDLAS
        department: Department of Economics
        address: NONE
      - id: Berniell23_3
        number: 3
        name:  IIE
        department: Department of Economics
        address: NONE
  - id: Bhai24
    number: 24
    name: Moiz Bhai
    email: mxbhai@ualr.edu
    phone: 501-916-6742
    fax: 501-916-3898
    orcid: 0000-0001-5990-5187
    degrees: PhD
    attributes:
      corresponding: False
    affiliations:
      - id: Bhai24_1
        number: 1
        name: University of Arkansas at Little Rock
        department: Department of Accounting, Economics, and Finance
        address: 2801 S. University Ave, Little Rock AR 72204
      - id: Bhai24_2
        number: 2
        name:  University of Arkansas for Medical Sciences
        department: Department of Accounting, Economics, and Finance
        address: 2801 S. University Ave, Little Rock AR 72204
  - id: Bhattacharya25
    number: 25
    name: Shreya Bhattacharya
    email: sbhattacharya@wm.edu
    phone: 8323986798
    fax: NONE
    orcid: NONE
    degrees: PhD
    attributes:
      corresponding: False
    affiliations:
      - id: Bhattacharya25_1
        number: 1
        name: Digital Inclusion and Governance Lab, Global Research Institute, William & Mary
        department: NONE
        address: 427 Scotland St, Williamsburg, VA 23187
  - id: Bjoerkheim26
    number: 26
    name: Markus Bjoerkheim
    email: mbjoerkh@gmu.edu
    phone: 5404357294
    fax: NONE
    orcid: 0000-0001-8952-6671
    degrees: PhD
    attributes:
      corresponding: False
    affiliations:
      - id: Bjoerkheim26_1
        number: 1
        name: Mercatus Center at George Mason University
        department: Open Health
        address: 3434 Washington Blvd., 4th Floor Arlington, VA 22201
  - id: Bloem27
    number: 27
    name: Jeffrey R. Bloem
    email: j.r.bloem@cgiar.org
    phone: 774-242-2588
    fax: NONE
    orcid: 0000-0002-4995-3043
    degrees: PhD
    attributes:
      corresponding: False
    affiliations:
      - id: Bloem27_1
        number: 1
        name: International Food Policy Research Institute 
        department: NONE
        address: 1201 I St NW, Washington, DC 20005
  - id: Brehm28
    number: 28
    name: Margaret E Brehm
    email: mbrehm@oberlin.edu
    phone: 440-775-8449
    fax: NONE
    orcid: NONE
    degrees: PhD
    attributes:
      corresponding: False
    affiliations:
      - id: Brehm28_1
        number: 1
        name: Oberlin College
        department: Department of Economics
        address: 10 N. Professor Street, Oberlin, OH 44074
  - id: Brun29
    number: 29
    name: Martín Brun
    email: martin.brun@uab.cat
    phone: +34935811680
    fax: NONE
    orcid: 0000-0002-6896-6309
    degrees: Master's Degree
    attributes:
      corresponding: False
    affiliations:
      - id: Brun29_1
        number: 1
        name: Universitat Autónoma de Barcelona
        department: Department of Applied Economics
        address: NONE
  - id: Buisson30
    number: 30
    name: Florent Buisson
    email: fbuisson@cars.com
    phone: 9452437867
    fax: NONE
    orcid: NONE
    degrees: PhD
    attributes:
      corresponding: False
    affiliations:
      - id: Buisson30_1
        number: 1
        name: Independent
        department: NONE
        address: 18800 Lina Street, #1010, Dallas, TX 75287
  - id: Burli31
    number: 31
    name: Pralhad Burli
    email: pralhad.burli@inl.gov
    phone: 7328958736
    fax: NONE
    orcid: 0000-0002-4107-8918
    degrees: PhD
    attributes:
      corresponding: False
    affiliations:
      - id: Burli31_1
        number: 1
        name: Idaho National Laboratory
        department: Decision Sciences
        address: Idaho Falls, Idaho
  - id: Camp32
    number: 32
    name: Andrew M. Camp
    email: ac103@uark.edu
    phone: 402-213-6333
    fax: NONE
    orcid: 0000-0002-9970-5275
    degrees: Master's Degree
    attributes:
      corresponding: False
    affiliations:
      - id: Camp32_1
        number: 1
        name: University of Arkansas
        department: Department of Education Reform
        address: Room 201, Graduate Education Building; University of Arkansas; Fayetteville, AR 72701
  - id: Cerutti33
    number: 33
    name: Nicola Cerutti
    email: nc@nicores.de
    phone: +44 (0) 7774 689143
    fax: NONE
    orcid: 0000-0002-5016-9213
    degrees: PhD
    attributes:
      corresponding: False
    affiliations:
      - id: Cerutti33_1
        number: 1
        name: Oasis Loss Modelling Framework
        department: NONE
        address: NONE
  - id: Chen34
    number: 34
    name: Weiwei Chen
    email: wchen30@kennesaw.edu
    phone: 470-578-3136
    fax: 470-578-9022
    orcid: 0000-0002-2162-0941
    degrees: PhD
    attributes:
      corresponding: False
    affiliations:
      - id: Chen34_1
        number: 1
        name: Kennesaw State University
        department: Department of Economics, Finance and Quantitative Analysis
        address: 560 Parliament Garden Way NW, Kennesaw, GA 30144
  - id: Clement35
    number: 35
    name: Jeffrey Clement
    email: clement@augsburg.edu
    phone: 2023686186
    fax: NONE
    orcid: 0000-0002-4500-7260
    degrees: PhD
    attributes:
      corresponding: False
    affiliations:
      - id: Clement35_1
        number: 1
        name: Augsburg University
        department: School of Business and Economics
        address: 2211 Riverside Ave, CB315, Minneapolis, MN 55454
  - id: Collins36
    number: 36
    name: Matthew Collins
    email: matthew.collins@universityofgalway.ie
    phone: +353(0)91493109
    fax: NONE
    orcid: 0009-0002-8414-023X
    degrees: PhD
    attributes:
      corresponding: False
    affiliations:
      - id: Collins36_1
        number: 1
        name: University of Galway
        department: J.E. Cairnes School of Business and Economics
        address: University of Galway, University Road, Galway, Ireland H91 TK33
  - id: Crawfurd37
    number: 37
    name: Lee Crawfurd
    email: lcrawfurd@cgdev.org
    phone: +447869613735
    fax: NONE
    orcid: 0000-0003-1513-934X
    degrees: PhD
    attributes:
      corresponding: False
    affiliations:
      - id: Crawfurd37_1
        number: 1
        name: Center for Global Development
        department: NONE
        address: Great College St, London SW1P 3SE
  - id: Cullinan38
    number: 38
    name: John Cullinan
    email: john.cullinan@universityofgalway.ie
    phone: 091 493996
    fax: NONE
    orcid: 0000-0003-3509-0635
    degrees: PhD
    attributes:
      corresponding: False
    affiliations:
      - id: Cullinan38_1
        number: 1
        name: University of Galway
        department: School of Business & Economics
        address: University Road, Galway, H91 TK33, Ireland
  - id: Deer39
    number: 39
    name: Lachlan Deer
    email: l.k.deer@tilburguniversity.edu
    phone: NONE
    fax: NONE
    orcid: 0000-0001-8646-6095
    degrees: PhD
    attributes:
      corresponding: False
    affiliations:
      - id: Deer39_1
        number: 1
        name: Tilburg University
        department: Department of Marketing
        address: Warandelaan 2, 5037 AB, Tilburg The Netherlands
  - id: Dorsey-Palmateer40
    number: 40
    name: Reid Dorsey-Palmateer
    email: dorseyr2@wwu.edu
    phone: 360 650 2676
    fax: NONE
    orcid: NONE
    degrees: PhD
    attributes:
      corresponding: False
    affiliations:
      - id: Dorsey-Palmateer40_1
        number: 1
        name: Western Washington University
        department: Department of Economics
        address: 516 High Street MS 9074, Bellingham WA 98225
  - id: Duquette41
    number: 41
    name: Nicolas J. Duquette
    email: nduquett@usc.edu
    phone: 213-821-2236
    fax: NONE
    orcid: 0000-0002-0707-6302
    degrees: PhD
    attributes:
      corresponding: False
    affiliations:
      - id: Duquette41_1
        number: 1
        name: University of Southern California
        department: Sol Price School of Public Policy
        address: 650 Childs Way, Los Angeles, CA 90089
  - id: Fages42
    number: 42
    name: Diego Marino Fages
    email: diego.r.marino-fages@durham.ac.uk
    phone: NONE
    fax: NONE
    orcid: 0000-0002-6233-2292
    degrees: PhD
    attributes:
      corresponding: False
    affiliations:
      - id: Fages42_1
        number: 1
        name: Durham University
        department: Department of Economics
        address: Durham University, Mill Hill Lane, Durham, DH1 3LB, UK
  - id: Falken43
    number: 43
    name: Grace Falken
    email: gfalken@uw.edu
    phone: NONE
    fax: NONE
    orcid: 0009-0002-0355-2305
    degrees: Master's Degree
    attributes:
      corresponding: False
    affiliations:
      - id: Falken43_1
        number: 1
        name: University of Washington
        department: Center for Education Data and Research
        address: 3876 Bridge Way N., Suite 201  Seattle, WA 98103
  - id: Farquharson44
    number: 44
    name: Christine Farquharson
    email: christine_f@ifs.org.uk
    phone: 020 7291 4800
    fax: NONE
    orcid: 0000-0003-2799-5506
    degrees: Master's Degree
    attributes:
      corresponding: False
    affiliations:
      - id: Farquharson44_1
        number: 1
        name: Institute for Fiscal Studies
        department: NONE
        address: 7 Ridgmount Street, London UK, WC1E 7AE
  - id: Feld45
    number: 45
    name: Jan Feld
    email: jan.feld@vuw.ac.nz
    phone: +6444639678 
    fax: NONE
    orcid: 0000-0003-3816-6607
    degrees: PhD
    attributes:
      corresponding: False
    affiliations:
      - id: Feld45_1
        number: 1
        name: Victoria University of Wellington
        department: School of Economics and Finance
        address: 22 Bunny Street, Pipitea, Wellington 6011, New Zealand
  - id: Feyman46
    number: 46
    name: Yevgeniy Feyman
    email: yfeyman@gmail.com
    phone: 646-831-5988
    fax: NONE
    orcid: 0000-0001-7372-7671
    degrees: PhD
    attributes:
      corresponding: False
    affiliations:
      - id: Feyman46_1
        number: 1
        name: Department of Health and Human Services
        department: NONE
        address: 200 Independence Ave SW, Washington, DC 20201
  - id: Fiala47
    number: 47
    name: Nathan Fiala
    email: nathan.fiala@uconn.edu
    phone: 2526268400
    fax: NONE
    orcid: NONE
    degrees: PhD
    attributes:
      corresponding: False
    affiliations:
      - id: Fiala47_1
        number: 1
        name: University of Connecticut
        department: Agricultural and Resource Economics
        address: NONE
  - id: Fitzpatrick48
    number: 48
    name: Anne Fitzpatrick
    email: fitzpatrick.88@osu.edu
    phone: (607)339-9261
    fax: NONE
    orcid: 0000-0002-2055-2350
    degrees: PhD
    attributes:
      corresponding: False
    affiliations:
      - id: Fitzpatrick48_1
        number: 1
        name: The Ohio State University
        department: Department of Agricultural, Environmental, and Development Economics
        address: Agricultural Administration Building, 2120 Fyffe Road, Columbus, OH 43210
  - id: Fradkin49
    number: 49
    name: Andrey Fradkin
    email: fradkin@bu.edu
    phone: 2019216279
    fax: NONE
    orcid: 0000-0002-3238-0592
    degrees: PhD
    attributes:
      corresponding: False
    affiliations:
      - id: Fradkin49_1
        number: 1
        name: Boston University, Questrom School of Business
        department: Marketing
        address: 595 Commonwealth Ave, Boston MA 02215
  - id: French50
    number: 50
    name: Evaewero French
    email: frenceva@oregonstate.edu
    phone: 9739146938
    fax: NONE
    orcid: NONE
    degrees: Master's Degree
    attributes:
      corresponding: False
    affiliations:
      - id: French50_1
        number: 1
        name: Oregon State University
        department: School of Public Policy
        address: 300 Bexell Hall 2251 SW Campus Way Corvallis, OR  97331
  - id: Fu51
    number: 51
    name: Wei Fu
    email: wei.fu@louisville.edu
    phone: 484-767-7515
    fax: NONE
    orcid: NONE
    degrees: PhD
    attributes:
      corresponding: False
    affiliations:
      - id: Fu51_1
        number: 1
        name: University of Louisville 
        department: Health Management and Systems Sciences Department 
        address: Room 105, School of Public Health and Information Sciences  485 E Gray St., Louisville, KY, 40202
  - id: Fumarco52
    number: 52
    name: Luca Fumarco
    email: luca.fumarco@econ.muni.cz
    phone: +393534263696
    fax: NONE
    orcid: 0000-0002-6236-0197
    degrees: PhD
    attributes:
      corresponding: False
    affiliations:
      - id: Fumarco52_1
        number: 1
        name: Masaryk University
        department: Department of Economics
        address: NONE
      - id: Fumarco52_2
        number: 2
        name:  IZA
        department: Department of Economics
        address: NONE
      - id: Fumarco52_3
        number: 3
        name:  GLO
        department: Department of Economics
        address: NONE
  - id: Gallegos53
    number: 53
    name: Sebastian Gallegos
    email: sebastian.gallegos@uai.cl
    phone: +56982876954
    fax: NONE
    orcid: 0000-0003-0437-3982
    degrees: PhD
    attributes:
      corresponding: False
    affiliations:
      - id: Gallegos53_1
        number: 1
        name: Universidad Adolfo Ibanez
        department: Business School
        address: Av. Padre Alberto Hurtado 750, Vina del Mar, Chile.
  - id: Galárraga54
    number: 54
    name: Julio Galárraga
    email: julio.galarraga.bonilla@udla.edu.ec
    phone: +593 2 3981000 ext. 7891
    fax: NONE
    orcid: NONE
    degrees: Master's Degree
    attributes:
      corresponding: False
    affiliations:
      - id: Galárraga54_1
        number: 1
        name: Universidad de las Américas Ecuador
        department: Department of Economics
        address: Redondel del Ciclista, Antigua Vía a Nayón, Quito, Ecuador
  - id: Gamino55
    number: 55
    name: Aaron M. Gamino
    email: aaron.gamino@mtsu.edu
    phone: 3092363734
    fax: NONE
    orcid: 0000-0001-7461-2470
    degrees: PhD
    attributes:
      corresponding: False
    affiliations:
      - id: Gamino55_1
        number: 1
        name: Middle Tennessee State University
        department: Department of Economics and Finance
        address: MTSU Box 27, 1301 E. Main St, Murfreesboro, TN 37132
  - id: Gauriot56
    number: 56
    name: Romain Gauriot
    email: romain.gauriot@deakin.edu.au
    phone: +61403700344
    fax: NONE
    orcid: 0000-0002-7633-7086
    degrees: PhD
    attributes:
      corresponding: False
    affiliations:
      - id: Gauriot56_1
        number: 1
        name: Deakin University
        department: Department of Economics
        address: 221 Burwood Hwy, Burwood VIC 3125, Australia
  - id: Gay57
    number: 57
    name: Victor Gay
    email: victor.gay@tse-fr.eu
    phone: +33622225170
    fax: NONE
    orcid: 0000-0001-9912-3841
    degrees: PhD
    attributes:
      corresponding: False
    affiliations:
      - id: Gay57_1
        number: 1
        name: Toulouse School of Economics
        department: Department of Social and Behavioral Sciences
        address: 1 Esplanade de l'Université, 31000, Toulouse, France
  - id: Gayaker58
    number: 58
    name: Savas Gayaker
    email: savas.gayaker@hbv.edu.tr
    phone: +905412504036
    fax: NONE
    orcid: 0000-0002-7186-1532
    degrees: PhD
    attributes:
      corresponding: False
    affiliations:
      - id: Gayaker58_1
        number: 1
        name: Ankara Hacı Bayram Veli University
        department: Department of Econometrics
        address: Emniyet Mahallesi  Gazeteci Yazar Muammer Yaşar Bostancı Caddesi  No:4 06500 Beşevler/Ankara
  - id: Gazeaud59
    number: 59
    name: Jules Gazeaud
    email: jules.gazeaud@gmail.com
    phone: NONE
    fax: NONE
    orcid: 0000-0002-3222-4573
    degrees: PhD
    attributes:
      corresponding: False
    affiliations:
      - id: Gazeaud59_1
        number: 1
        name: CNRS
        department: NONE
        address: NONE
      - id: Gazeaud59_2
        number: 2
        name:  Université Clermont Auvergne
        department: NONE
        address: NONE
  - id: Gendre60
    number: 60
    name: Alexandra de Gendre
    email: a.degendre@unimelb.edu.au
    phone: +61432493139
    fax: NONE
    orcid: 0000-0001-6409-1982
    degrees: PhD
    attributes:
      corresponding: False
    affiliations:
      - id: Gendre60_1
        number: 1
        name: The University of Melbourne
        department: Department of Economics
        address: Level 4 Department of Economics, Faculty of Business and Economics Building, The University of Melbourne, 111 Barry Street, Carlton VIC 3010 Australia
  - id: Gilpin61
    number: 61
    name: Gregory Gilpin
    email: gregory.gilpin@montana.edu
    phone: (406)-994-5628
    fax: (406) 994-4838
    orcid: 0000-0002-6901-2750
    degrees: PhD
    attributes:
      corresponding: False
    affiliations:
      - id: Gilpin61_1
        number: 1
        name: Montana State University
        department: Department of Agricultural Economics and Economics
        address: 306 Linfield Hall, Bozeman, MT 59717
  - id: Girardi62
    number: 62
    name: Daniele Girardi
    email: daniele.girardi@kcl.ac.uk
    phone: NONE
    fax: NONE
    orcid: 0000-0002-3423-3174
    degrees: PhD
    attributes:
      corresponding: False
    affiliations:
      - id: Girardi62_1
        number: 1
        name: King's College London
        department: Department of Political Economy
        address: Bush House, North East Wing, 30 Aldwych, London, WC2B 4BG, United Kingdom
  - id: Goldhaber63
    number: 63
    name: Dan Goldhaber
    email: dgoldhab@uw.edu
    phone: 2066791867
    fax: NONE
    orcid: 0000-0003-4260-4040
    degrees: PhD
    attributes:
      corresponding: False
    affiliations:
      - id: Goldhaber63_1
        number: 1
        name: University of Washington, American Institutes for Research
        department: Center for Education Data and Research (U. of WA), National Center for Analysis of Longitudinal Data in Education Research (AIR)
        address: 3876 Bridge Way N., Suite 201 Seattle, WA 98103
  - id: Harris64
    number: 64
    name: Mark N. Harris
    email: mark.harris@curtin.edu.au
    phone: +61407575126
    fax: NONE
    orcid: 0000-0002-1804-4357
    degrees: PhD
    attributes:
      corresponding: False
    affiliations:
      - id: Harris64_1
        number: 1
        name: Curtin University
        department: School of Accounting, Econmics and Finance
        address: Perth, Western Australia, Australia
  - id: Heller65
    number: 65
    name: Blake H. Heller
    email: bhheller@uh.edu
    phone: 8184583096
    fax: NONE
    orcid: 0000-0003-2093-8170
    degrees: PhD
    attributes:
      corresponding: False
    affiliations:
      - id: Heller65_1
        number: 1
        name: University of Houston
        department: Hobby School of Public Affairs
        address: Bates Building; 4104 Martin Luther King Boulevard, Room 118; Houston, Texas 77204-5021
  - id: Henderson66
    number: 66
    name: Daniel J. Henderson
    email: daniel.henderson@ua.edu
    phone: 205-348-8991
    fax: NONE
    orcid: 0000-0002-4940-9689
    degrees: PhD
    attributes:
      corresponding: False
    affiliations:
      - id: Henderson66_1
        number: 1
        name: University of Alabama
        department: Department of Economics, Finance and Legal Studies
        address: Box 870224, University of Alabama, Tuscaloosa, AL 35487-0224
  - id: Henningsen67
    number: 67
    name: Arne Henningsen
    email: arne@ifro.ku.dk
    phone: +45-51439618
    fax: NONE
    orcid: 0000-0002-6720-0264
    degrees: PhD
    attributes:
      corresponding: False
    affiliations:
      - id: Henningsen67_1
        number: 1
        name: University of Copenhagen
        department: Department of Food and Resource Economics
        address: Rolighedsvej 23, 1958 Frederiksberg C, Denmark
  - id: Henry68
    number: 68
    name: Junita Henry
    email: Junitahenry@g.harvard.edu
    phone: 6176062044
    fax: NONE
    orcid: 0000-0002-5600-7119
    degrees: Master's Degree
    attributes:
      corresponding: False
    affiliations:
      - id: Henry68_1
        number: 1
        name: Harvard University
        department: Department of Global Health
        address: 677 Huntington Ave, Boston, MA 02115
  - id: Herman69
    number: 69
    name: Clément Herman
    email: cherman@princeton.edu
    phone: 6099339278
    fax: NONE
    orcid: NONE
    degrees: Master's Degree
    attributes:
      corresponding: False
    affiliations:
      - id: Herman69_1
        number: 1
        name: Princeton University
        department: Department of Economics
        address: 20 Washington Rd, Princeton, NJ 08540
  - id: Hernæs70
    number: 70
    name: Øystein Hernæs
    email: o.m.hernas@frisch.uio.no
    phone: 004793652406
    fax: NONE
    orcid: 0000-0002-6113-2985
    degrees: PhD
    attributes:
      corresponding: False
    affiliations:
      - id: Hernæs70_1
        number: 1
        name: The Ragnar Frisch Centre for Economic Research
        department: NONE
        address: Gaustadalleen 21, 0349 Oslo, Norway
  - id: Hill71
    number: 71
    name: Andrew J. Hill
    email: andrew.hill6@montana.edu
    phone: 4069943701
    fax: NONE
    orcid: 0000-0001-7630-6151
    degrees: PhD
    attributes:
      corresponding: False
    affiliations:
      - id: Hill71_1
        number: 1
        name: Montana State University
        department: Department of Agricultural Economics and Economics
        address: P.O. Box 172920, Bozeman, MT 59717-2920
  - id: Holzmeister72
    number: 72
    name: Felix Holzmeister
    email: felix.holzmeister@uibk.ac.at
    phone: +4351250771040
    fax: NONE
    orcid: 0000-0001-9606-0427
    degrees: PhD
    attributes:
      corresponding: False
    affiliations:
      - id: Holzmeister72_1
        number: 1
        name: University of Innsbruck
        department: Department of Economics
        address: Universitätsstraße 15, 6020 Innsbruck, Austria
  - id: Huysmans73
    number: 73
    name: Martijn Huysmans
    email: m.huysmans@uu.nl
    phone: +31613077883
    fax: NONE
    orcid: 0000-0002-8431-1396
    degrees: PhD
    attributes:
      corresponding: False
    affiliations:
      - id: Huysmans73_1
        number: 1
        name: Utrecht University
        department: School of Economics
        address: PO Box 80125, 3508 TC Utrecht, NL
  - id: Imtiaz74
    number: 74
    name: M. Saad Imtiaz
    email: saad.imtiaz@lums.edu.pk
    phone: +12029147170
    fax: NONE
    orcid: NONE
    degrees: Master's Degree
    attributes:
      corresponding: False
    affiliations:
      - id: Imtiaz74_1
        number: 1
        name: Lahore University of Management Sciences
        department: Department of Humanities and Social Sciences
        address: Khayaban-e-Jinnah, opposite Sector U،, Phase 5 D.H.A, Lahore, Punjab 54792
  - id: Jain75
    number: 75
    name: Anil K. Jain
    email: anil.k.jain@frb.gov
    fax: NONE
    orcid: 0000-0001-9607-188X
    degrees: PhD
    attributes:
      corresponding: False
    affiliations:
      - id: Jain75_1
        number: 1
        name: Federal Reserve Board of Governors
        department: International Finance
  - id: Jakobsson76
    number: 76
    name: Niklas Jakobsson
    email: niklas.jakobsson@kau.se
    phone: 0046703939009
    fax: NONE
    orcid: 0000-0002-7143-8793
    degrees: PhD
    attributes:
      corresponding: False
    affiliations:
      - id: Jakobsson76_1
        number: 1
        name: Karlstad University
        department: Karlstad Business School
        address: Karlstad Business School, Karlstad University, 651 88 Karlstad
  - id: Kaire77
    number: 77
    name: José Kaire
    email: kaire@asu.edu
    phone: 7654449960
    fax: NONE
    orcid: 0000-0002-2435-9953
    degrees: PhD
    attributes:
      corresponding: False
    affiliations:
      - id: Kaire77_1
        number: 1
        name: Arizona State University
        department: School of Politics and Global Studies
        address: Lattie F. Coor Hall, 975 S Myrtle Ave, Tempe, AZ 85287
  - id: Kameshwara78
    number: 78
    name: Kalyan Kumar Kameshwara
    email: K.Kameshwara@westminster.ac.uk
    phone: +44 07979682728
    fax: NONE
    orcid: 0000-0001-5615-2378
    degrees: PhD
    attributes:
      corresponding: False
    affiliations:
      - id: Kameshwara78_1
        number: 1
        name: University of Westminster
        department: Westminster Business School 
        address: Centre for Employment Research, 35 Marylebone Rd, London NW1 5LS, United Kingdom
  - id: Karney79
    number: 79
    name: Daniel H Karney
    email: karney@ohio.edu
    phone: 740-597-1254
    fax: NONE
    orcid: 0000-0002-3866-0990
    degrees: PhD
    attributes:
      corresponding: False
    affiliations:
      - id: Karney79_1
        number: 1
        name: Ohio University
        department: Department of Economics
        address: 1 President St., Athens, OH 45701
  - id: Kim80
    number: 80
    name: Sie Won Kim
    email: siewon.kim@ttu.edu
    phone: 806-834-8226
    fax: NONE
    orcid: 0000-0003-4940-4156
    degrees: PhD
    attributes:
      corresponding: False
    affiliations:
      - id: Kim80_1
        number: 1
        name: Texas Tech University
        department: Department of Economics
        address: PO Box 41014, Lubbock, TX 79409
  - id: Klotzbücher81
    number: 81
    name: Valentin Klotzbücher
    email: valentin.klotzbuecher@econ.uni-freiburg.de
    phone: +49 761 203 676 52
    fax: +49 761 203 676 49
    orcid: 0000-0001-9382-6757
    degrees: PhD
    attributes:
      corresponding: False
    affiliations:
      - id: Klotzbücher81_1
        number: 1
        name: University of Freiburg
        department: Department of Economics
        address: Wilhelmstraße 1b, D-79085 Freiburg im Breisgau 
  - id: Kronenberg82
    number: 82
    name: Christoph Kronenberg
    email: christoph.kronenberg@uni-due.de
    phone: +4920118-36460
    fax: +4920118-33716
    orcid: NONE
    degrees: PhD
    attributes:
      corresponding: False
    affiliations:
      - id: Kronenberg82_1
        number: 1
        name: University Duisburg-Essen
        department: CINCH
        address: Berliner Platz 6-8, 45127 Essen, Germany
  - id: LaFave83
    number: 83
    name: Daniel LaFave
    email: drlafave@colby.edu
    phone: 207 859 5243
    fax: NONE
    orcid: NONE
    degrees: PhD
    attributes:
      corresponding: False
    affiliations:
      - id: LaFave83_1
        number: 1
        name: Colby College
        department: Department of Economics
        address: 5243 Mayflower Hill, Waterville, ME, USA 04901
  - id: Lang84
    number: 84
    name: David Lang
    email: dnlang.ucla@gmail.com
    phone: 8186459877
    fax: NONE
    orcid: 0000-0001-5415-0125
    degrees: PhD
    attributes:
      corresponding: False
    affiliations:
      - id: Lang84_1
        number: 1
        name: Stanford University
        department: Department of Political Science
        address: NONE
  - id: Lee85
    number: 85
    name: Ryan Lee
    email: RLEE2@laverne.edu
    phone: 909-448-1490
    fax: NONE
    orcid: 0000-0002-2080-4335
    degrees: PhD
    attributes:
      corresponding: False
    affiliations:
      - id: Lee85_1
        number: 1
        name: University of La Verne
        department: College of Business
        address: 1950 3rd St, La Verne, CA 91750
  - id: Liégey86
    number: 86
    name: Maxime Liégey
    email: mliegey@unistra.fr
    phone: +33 6 48 07 74 90
    fax: NONE
    orcid: 0000-0002-3214-1241
    degrees: PhD
    attributes:
      corresponding: False
    affiliations:
      - id: Liégey86_1
        number: 1
        name: Strasbourg University
        department: FSEG
        address: 61 Avenue de la Forêt Noire, 67085 STRASBOURG CEDEX
  - id: Long87
    number: 87
    name: Dede Long
    email: dlong@hmc.edu
    phone: 5037209537
    fax: NONE
    orcid: 0000-0003-1908-186X
    degrees: PhD
    attributes:
      corresponding: False
    affiliations:
      - id: Long87_1
        number: 1
        name: Harvey Mudd College
        department: Department of Humanities, Social Sciences, and the Arts
        address: 301 Platt Blvd, Claremont, CA, 91711
  - id: Marcus88
    number: 88
    name: Jan Marcus
    email: jan.marcus@fu-berlin.de
    phone: +49 30 838 58549
    fax: NONE
    orcid: 0000-0001-9407-6660
    degrees: PhD
    attributes:
      corresponding: False
    affiliations:
      - id: Marcus88_1
        number: 1
        name: Freie Universität Berlin
        department: School of Business and Economics
        address: Garystraße 21, 14195 Berlin, Germany
  - id: Mari89
    number: 89
    name: Gabriele Mari
    email: mari@essb.eur.nl
    phone: NONE
    fax: NONE
    orcid: 0000-0001-8557-5337
    degrees: PhD
    attributes:
      corresponding: False
    affiliations:
      - id: Mari89_1
        number: 1
        name: Erasmus University Rotterdam
        department: Department of Public Administration and Sociology
        address: NONE
  - id: McCarthy90
    number: 90
    name: Ian McCarthy
    email: ian.mccarthy@emory.edu
    phone: 404-727-8808
    fax: NONE
    orcid: 0000-0001-7942-3468
    degrees: PhD
    attributes:
      corresponding: False
    affiliations:
      - id: McCarthy90_1
        number: 1
        name: Emory University
        department: Department of Economics
        address: 1602 Fishburne Drive, Rich Memorial Building, Room 306, Atlanta, GA 30322
      - id: McCarthy90_2
        number: 2
        name:  NBER
        address: 1050 Massachusetts Avenue, Cambridge, MA 02138
  - id: Meinzen-Dick91
    number: 91
    name: Laura Meinzen-Dick
    email: laura.meinzen-dick@villanova.edu
    phone: 636-675-2557
    fax: NONE
    orcid: NONE
    degrees: PhD
    attributes:
      corresponding: False
    affiliations:
      - id: Meinzen-Dick91_1
        number: 1
        name: Villanova University 
        department: Department of Economics 
        address: 800 E Lancaster Ave, Villanova PA 19085
  - id: Merkus92
    number: 92
    name: Erik Merkus
    email: e_merkus@me.com
    phone: 0046701609700
    fax: NONE
    orcid: 0000-0003-2602-5866
    degrees: PhD
    attributes:
      corresponding: False
    affiliations:
      - id: Merkus92_1
        number: 1
        name: Independent
        department: NONE
        address: NONE
  - id: Miller93
    number: 93
    name: Klaus M. Miller
    email: millerk@hec.fr
    phone: +33 1 39 67 70 88
    fax: NONE
    orcid: 0000-0003-0017-330X
    degrees: PhD
    attributes:
      corresponding: False
    affiliations:
      - id: Miller93_1
        number: 1
        name: HEC Paris
        department: Department of Marketing
        address: 1 Rue de la Libération, 78350 Jouy-en-Josas, France
  - id: Mogge94
    number: 94
    name: Lukas Mogge
    email: lukas.mogge@rwi-essen.de
    phone: +4930202159821
    fax: NONE
    orcid: 0000-0002-1364-5241
    degrees: Dr. rer. oec.
    attributes:
      corresponding: False
    affiliations:
      - id: Mogge94_1
        number: 1
        name: RWI – Leibniz Institute for Economic Research
        department: Economic Policy Lab Climate, Migration and Development
        address: Hohenzollernstrasse 1-3, 45128 Essen, Germany.
  - id: Murad95
    number: 95
    name: S. M. Woahid Murad
    email: s.murad@curtin.edu.au
    phone: +61468583603
    fax: NONE
    orcid: 0000-0002-5886-9759
    degrees: Master's Degree
    attributes:
      corresponding: False
    affiliations:
      - id: Murad95_1
        number: 1
        name: Curtin University
        department: School of Accounting, Economics and Finance
        address: NONE
      - id: Murad95_2
        number: 2
        name:  Noakhali Science and Technology University
        department: Department of Economics
        address: NONE
  - id: Najam96
    number: 96
    name: Rafiuddin Najam
    email: najamr@oregonstate.edu
    phone: 9717199957
    fax: NONE
    orcid: 0000-0002-2943-545X
    degrees: Master's Degree
    attributes:
      corresponding: False
    affiliations:
      - id: Najam96_1
        number: 1
        name: Oregon State University
        department: Public Policy
        address: Corvallis, OR
  - id: Naumann97
    number: 97
    name: Elias Naumann
    email: elias.naumann@gesis.org
    phone: +496211246442
    fax: +496211246100
    orcid: 0000-0003-1415-0678
    degrees: PhD
    attributes:
      corresponding: False
    affiliations:
      - id: Naumann97_1
        number: 1
        name: GESIS Leibniz Institute for the Social Sciences
        department: NONE
        address: B6 4-5, 68159 Mannheim, Germany
  - id: Nmadu98
    number: 98
    name: Job Nda Nmadu
    email: job_nmadu@futminna.edu.ng
    phone: 08035861170
    fax: NONE
    orcid: 0000-0002-1320-8957
    degrees: PhD
    attributes:
      corresponding: False
    affiliations:
      - id: Nmadu98_1
        number: 1
        name: Federal University of Technology, Minna, Nigeria 
        department: Department of Agricultural Economics and Farm Management 
        address: PMB 65, Minna
  - id: Ozer99
    number: 99
    name: Gorkem Turgut Ozer
    email: GT.Ozer@unh.edu
    phone: (603) 862-2709
    fax: NONE
    orcid: 0000-0003-4451-5076
    degrees: PhD
    attributes:
      corresponding: False
    affiliations:
      - id: Ozer99_1
        number: 1
        name: University of New Hampshire
        department: Paul College of Business and Economics
        address: 10 Garrison Ave, Durham, NH 03824
  - id: Paudel100
    number: 100
    name: Jayash Paudel
    email: jayash.paudel@ou.edu
    phone: 12089198931
    fax: NONE
    orcid: 0000-0003-3430-7943
    degrees: PhD
    attributes:
      corresponding: False
    affiliations:
      - id: Paudel100_1
        number: 1
        name: University of Oklahoma
        department: Department of Economics
        address: 308 Cate Center Drive Norman, OK 73019
  - id: Petroulakis101
    number: 101
    name: Filippos Petroulakis
    email: fpetroulakis@bankofgreece.gr
    phone: +306944821586
    fax: +302103233025
    orcid: NONE
    degrees: PhD
    attributes:
      corresponding: False
    affiliations:
      - id: Petroulakis101_1
        number: 1
        name: Bank of Greece
        department: NONE
        address: 21 El. Venizelou Street, 102 50, Athens, Greece
  - id: Peukert102
    number: 102
    name: Christian Peukert
    email: christian.peukert@unil.ch
    phone: +41446324671
    fax: NONE
    orcid: 0000-0003-3997-8850
    degrees: PhD
    attributes:
      corresponding: False
    affiliations:
      - id: Peukert102_1
        number: 1
        name: University of Lausanne, Faculty of Business and Economics (HEC)
        department: Department of Strategy, Globalization and Society
        address: Quartier Chamberonne, CH-1015 Lausanne
  - id: Pitkänen103
    number: 103
    name: Visa Pitkänen
    email: visa.pitkanen@kkv.fi
    phone: +358504098397
    fax: NONE
    orcid: 0000-0002-8727-3831
    degrees: PhD
    attributes:
      corresponding: False
    affiliations:
      - id: Pitkänen103_1
        number: 1
        name: Finnish Competition and Consumer Authority
        department: NONE
        address: Lintulahdenkuja 2 A, 00530 Helsinki, Finland
  - id: Porcher104
    number: 104
    name: Simon Porcher
    email: simon.porcher@u-paris2.fr
    phone: +33617154415
    fax: NONE
    orcid: NONE
    degrees: PhD
    attributes:
      corresponding: False
    affiliations:
      - id: Porcher104_1
        number: 1
        name: Université Paris Panthéon-Assas
        department: Department of Management 
        address: 1 rue Guy de la Brosse 75005 Paris France
  - id: Prakash105
    number: 105
    name: Manab Prakash
    email: manab.prakash@giis.edu.np
    phone: +9779840276721
    fax: NONE
    orcid: 0000-0002-9958-2981
    degrees: Master's Degree
    attributes:
      corresponding: False
    affiliations:
      - id: Prakash105_1
        number: 1
        name: Tribhuvan University
        department: Central Department of Economics
        address: Kritipur, Kathmandu, Nepal
  - id: Pua106
    number: 106
    name: Andrew Adrian Yu Pua
    email: andrewypua@outlook.com
    phone: NONE
    fax: NONE
    orcid: 0000-0002-2225-5245
    degrees: PhD
    attributes:
      corresponding: False
    affiliations:
      - id: Pua106_1
        number: 1
        name: De La Salle University - Manila
        department: School of Economics
        address: 2401 Taft Avenue, Manila 0922, Philippines
  - id: Pugatch107
    number: 107
    name: Todd Pugatch
    email: todd.pugatch@oregonstate.edu
    phone: 5417376628
    fax: NONE
    orcid: 0000-0003-0127-2289
    degrees: PhD
    attributes:
      corresponding: False
    affiliations:
      - id: Pugatch107_1
        number: 1
        name: Oregon State University
        department: Department of Economics, School of Public Policy
        address: 300 Bexell Hall, Corvallis OR 97331
  - id: Putman108
    number: 108
    name: Daniel S. Putman
    email: putmands@sas.upenn.edu
    phone: 530-564-9082
    fax: NONE
    orcid: 0000-0002-2446-0103
    degrees: PhD
    attributes:
      corresponding: False
    affiliations:
      - id: Putman108_1
        number: 1
        name: University of Pennsylvania
        department: Center for Social Norms and Behavioral Dynamics
        address: 3718 Locust Walk, Philadelphia, PA 19104
  - id: Rayamajhee109
    number: 109
    name: Veeshan Rayamajhee
    email: veeshan@nmsu.edu
    phone: (267)-629-9642
    fax: NONE
    orcid: 0000-0002-2117-7337
    degrees: PhD
    attributes:
      corresponding: False
    affiliations:
      - id: Rayamajhee109_1
        number: 1
        name: New Mexico State University
        department: Department of Economics, Applied Statistics, and International Business
        address: Las Cruces, NM 88003
  - id: Rehman110
    number: 110
    name: Obeid Ur Rehman
    email: obeid@torontomu.ca
    phone: +16478640359
    fax: NONE
    orcid: 0000-0002-7357-9717
    degrees: PhD
    attributes:
      corresponding: False
    affiliations:
      - id: Rehman110_1
        number: 1
        name: Toronto Metropolitan University
        department: Department of Economics
        address: 350 Victoria Street, Toronto, ON, M5B 2K3, Canada
  - id: Reimão111
    number: 111
    name: Maira Emy Reimão
    email: maira.reimao@villanova.edu
    phone: 2023683654
    fax: NONE
    orcid: 0000-0001-7143-9668
    degrees: PhD
    attributes:
      corresponding: False
    affiliations:
      - id: Reimão111_1
        number: 1
        name: Villanova University
        department: Department of Economics
        address: 800 E Lancaster Ave, Villanova PA, 19085
  - id: Reuter112
    number: 112
    name: Anna Reuter
    email: anna.reuter@uni-heidelberg.de
    phone: NONE
    fax: NONE
    orcid: 0000-0002-3087-7415
    degrees: PhD
    attributes:
      corresponding: False
    affiliations:
      - id: Reuter112_1
        number: 1
        name: Heidelberg University
        department: Heidelberg Institute of Global Health
        address: Im Neuenheimer Feld 130.3, 69120 Heidelberg, Germany
  - id: Ricks113
    number: 113
    name: Michael David Ricks
    email: mricks4@unl.edu
    phone: 8015027270
    fax: NONE
    orcid: 0000-0003-1220-0862
    degrees: PhD
    attributes:
      corresponding: False
    affiliations:
      - id: Ricks113_1
        number: 1
        name: University of Nebraska - Lincoln
        department: Department of Economics
        address: 730 N. 14th Street P.O. Box 880405 Lincoln, NE 68588-0405
  - id: Rios-Avila114
    number: 114
    name: Fernando Rios-Avila
    email: friosavi@levy.org
    phone: 4049245176
    fax: NONE
    orcid: NONE
    degrees: PhD
    attributes:
      corresponding: False
    affiliations:
      - id: Rios-Avila114_1
        number: 1
        name: Levy Economics Institute
        department: NONE
        address: 30 Campus Rd, Annandale-On-Hudson, NY 12504
  - id: Rodriguez115
    number: 115
    name: Abel Rodriguez
    email: a01595062@tec.mx
    phone: +525530261539
    fax: NONE
    orcid: 0000-0001-9208-6224
    degrees: Master's Degree
    attributes:
      corresponding: False
    affiliations:
      - id: Rodriguez115_1
        number: 1
        name: Tecnológico de Monterrey 
        department: Escuela de Gobierno y Transformación Pública 
        address: NONE
  - id: Roeckert116
    number: 116
    name: Julian Roeckert
    email: julian.roeckert@rwi-essen.de
    phone: +4930202159812
    fax: NONE
    orcid: 0009-0003-7373-4232
    degrees: PhD
    attributes:
      corresponding: False
    affiliations:
      - id: Roeckert116_1
        number: 1
        name: RWI - Leibniz Institute for Economic Research
        department: Policy Lab - Climate Change, Development and Migration
        address: Zinnowitzer Str. 1, 10115 Berlin, Germany
  - id: Ropovik117
    number: 117
    name: Ivan Ropovik
    email: ivan.ropovik@gmail.com
    phone: +421907607829
    fax: NONE
    orcid: 0000-0001-5222-1233
    degrees: PhD
    attributes:
      corresponding: False
    affiliations:
      - id: Ropovik117_1
        number: 1
        name: Charles University
        department: Faculty of Education
        address: Institute for Research and Development of Education, Myslikova 7, 110 00, Praha 1
      - id: Ropovik117_2
        number: 2
        name:  University of Presov
        department: Faculty of Education
        address: Institute for Research and Development of Education, Myslikova 7, 110 00, Praha 1
      - id: Ropovik117_3
        number: 3
        name:  Czech Academy of Sciences
        department: Institute of Psychology
        address: Institute for Research and Development of Education, Myslikova 7, 110 00, Praha 1
  - id: Roy118
    number: 118
    name: Jayjit Roy
    email: royj@appstate.edu
    phone: 8282626242
    fax: NONE
    orcid: 0000-0002-2347-6947
    degrees: PhD
    attributes:
      corresponding: False
    affiliations:
      - id: Roy118_1
        number: 1
        name: Appalachian State University
        department: Department of Economics
        address: Department of Economics, 416 Howard Street Room 3101B, Peacock Hall, Boone, NC 28608
  - id: Salamanca119
    number: 119
    name: Nicolas Salamanca
    email: n.salamanca@unimelb.edu.au
    phone: +61 (3) 8344 2863
    fax: NONE
    orcid: 0000-0002-6596-843X
    degrees: PhD
    attributes:
      corresponding: False
    affiliations:
      - id: Salamanca119_1
        number: 1
        name: The University of Melbourne
        department: Melbourne Institute, Applied Economic & Social Research
        address: Level 5, 111 Barry street, 3053 Calrton, Victoria (Australia)
  - id: Samahita120
    number: 120
    name: Margaret Samahita
    email: margaret.samahita@ucd.ie
    phone: +35317164621
    fax: NONE
    orcid: 0000-0002-8693-1185
    degrees: PhD
    attributes:
      corresponding: False
    affiliations:
      - id: Samahita120_1
        number: 1
        name: University College Dublin
        department: School of Economics
        address: University College Dublin, Belfield Dublin 4, Ireland
  - id: Samudra121
    number: 121
    name: Aparna Samudra
    email: acsamudra@gmail.com
    phone: +919823460210
    fax: NONE
    orcid: 0000-0001-8715-8051
    degrees: PhD
    attributes:
      corresponding: False
    affiliations:
      - id: Samudra121_1
        number: 1
        name:  RTM Nagpur University 
        department: Department of Economics 
        address: Humanities Building, University Campus, Amravati Road, Nagpur, Maharashtra, India 
  - id: Sanogo122
    number: 122
    name: Vassiki Sanogo
    email: vassikisanogo@gmail.com
    phone: 18503390885
    fax: NONE
    orcid: 0000-0003-0250-6649
    degrees: PhD
    attributes:
      corresponding: False
    affiliations:
      - id: Sanogo122_1
        number: 1
        name: Otsuka Pharmaceutical Development & Commercialization, Inc.
        department: Contract Worker, Pharmacoevidence
        address: 700 SW 62nd Blvd, Gainesville Florida 32607
  - id: Sariyev123
    number: 123
    name: Orkhan Sariyev
    email: o.sariyev@uni-hohenheim.de
    phone: +4917643231585
    fax: NONE
    orcid: 0000-0001-5005-2667
    degrees: PhD
    attributes:
      corresponding: False
    affiliations:
      - id: Sariyev123_1
        number: 1
        name: University of Hohenheim
        department: Department of Rural Development Theory and Policy
        address: Wollgrasweg 43, 70599 Stuttgart, Germany
  - id: Schaak124
    number: 124
    name: Henning Schaak
    email: henning.schaak@boku.ac.at
    phone: NONE
    fax: NONE
    orcid: 0000-0002-7659-4795
    degrees: PhD
    attributes:
      corresponding: False
    affiliations:
      - id: Schaak124_1
        number: 1
        name: University of Natural Resources and Life Sciences, Vienna
        department: Department of Economics and Social Sciences
        address: Feistmantelstr. 4., 1180 Vienna, Austria
  - id: Segel125
    number: 125
    name: Joel E. Segel
    email: jes87@psu.edu
    phone: 814-863-8786
    fax: 814-863-2905
    orcid: 0000-0001-8937-0531
    degrees: PhD
    attributes:
      corresponding: False
    affiliations:
      - id: Segel125_1
        number: 1
        name: Penn State University
        department: Department of Health Policy and Administration
        address: 504 Ford Building, University Park, PA 16802
  - id: Sievertsen126
    number: 126
    name: Hans Henrik Sievertsen
    email: hhs@vive.dk
    phone: +4529658475
    fax: NONE
    orcid: 0000-0003-0126-828X
    degrees: PhD
    attributes:
      corresponding: False
    affiliations:
      - id: Sievertsen126_1
        number: 1
        name: VIVE and University of Bristol
        department: School of Economics
        address: Priory Road Complex, Priory Road, Bristol, BS8 1TU, United Kingdom
      - id: Sievertsen126_2
        number: 2
        name:   VIVE
        department: School of Economics
        address: Priory Road Complex, Priory Road, Bristol, BS8 1TU, United Kingdom
  - id: Smet127
    number: 127
    name: Mike Smet
    email: mike.smet@kuleuven.be
    phone: +32 3 201 18 79
    fax: NONE
    orcid: 0000-0002-1304-4809
    degrees: PhD
    attributes:
      corresponding: False
    affiliations:
      - id: Smet127_1
        number: 1
        name: KU Leuven
        department: Department of Work and Organisation Studies
        address: Hendrik Conscienceplein 8; BE-2000 Antwerpen; Belgium
  - id: Smith128
    number: 128
    name: Brock Smith
    email: brock.smith@gmail.com
    phone: 406-589-7210
    fax: NONE
    orcid: 0000-0003-0584-6534
    degrees: PhD
    attributes:
      corresponding: False
    affiliations:
      - id: Smith128_1
        number: 1
        name: Montana State University
        department: Department of Agricultural Economics and Economics
        address: Montana State University, P.O. Box 172920, Bozeman, MT 59717-2920
  - id: Sorensen129
    number: 129
    name: Lucy C. Sorensen
    email: lsorensen@albany.edu
    phone: 5184425235
    fax: NONE
    orcid: 0000-0003-4111-1236
    degrees: PhD
    attributes:
      corresponding: False
    affiliations:
      - id: Sorensen129_1
        number: 1
        name: University at Albany, SUNY
        department: Department of Public Administration and Policy
        address: Milne Hall, 135 Western Avenue, Albany, NY 12203
  - id: Spantig130
    number: 130
    name: Lisa Spantig
    email: lisa.spantig@rwth-aachen.de
    phone: +49 241 80 99402
    fax: NONE
    orcid: 0000-0003-0776-3863
    degrees: PhD
    attributes:
      corresponding: False
    affiliations:
      - id: Spantig130_1
        number: 1
        name: RWTH Aachen University
        department: School of Business and Economics
        address: Templergraben 64, 52062 Aachen, Germany
      - id: Spantig130_2
        number: 2
        name:  University of Essex
        department: School of Business and Economics
        address: Templergraben 64, 52062 Aachen, Germany
  - id: Szczygielski131
    number: 131
    name: Krzysztof Szczygielski
    email: kszczygielski@wne.uw.edu.pl
    phone: +48501248601
    fax: NONE
    orcid: 0000-0002-7599-1115
    degrees: PhD
    attributes:
      corresponding: False
    affiliations:
      - id: Szczygielski131_1
        number: 1
        name: University of Warsaw
        department: Faculty of Economics Sciences
        address: Dluga st. 44/50, 00-241 Warsaw, POLAND
  - id: Tagat132
    number: 132
    name: Anirudh Tagat
    email: at@monkprayogshala.in
    phone: +91 9619814988
    fax: NONE
    orcid: 0000-0002-7707-453X
    degrees: PhD
    attributes:
      corresponding: False
    affiliations:
      - id: Tagat132_1
        number: 1
        name: Monk Prayogshala
        department: Department of Economics
        address: 4114, Oberoi Garden Estates C Wing 4th Floor, Off Saki Vihar Rd., Andheri (East), Mumbai, India
  - id: Tastan133
    number: 133
    name: Huseyin Tastan
    email: tastan@yildiz.edu.tr
    phone: NONE
    fax: NONE
    orcid: 0000-0002-2701-1039
    degrees: PhD
    attributes:
      corresponding: False
    affiliations:
      - id: Tastan133_1
        number: 1
        name: Yildiz Technical University
        department: Department of Economics
        address: Davutpasa Campus, Istanbul, Turkey
  - id: Trombetta134
    number: 134
    name: Martin Trombetta
    email: martintrombetta@gmail.com
    phone: 5491166068372
    fax: NONE
    orcid: 0000-0003-0180-2198
    degrees: PhD
    attributes:
      corresponding: False
    affiliations:
      - id: Trombetta134_1
        number: 1
        name: Universidad Nacional de General Sarmiento
        department: Área de Economía
        address: Juan María Gutiérrez 1150, Los Polvorines, Buenos Aires, Argentina
      - id: Trombetta134_2
        number: 2
        name:  Consejo Nacional de Investigaciones Científicas y Técnicas
  - id: Venkatesan135
    number: 135
    name: Madhavi Venkatesan
    email: m.venkatesan@northeastern.edu
    phone: 917-496-0440
    fax: NONE
    orcid: 0000-0001-9780-5865
    degrees: PhD
    attributes:
      corresponding: False
    affiliations:
      - id: Venkatesan135_1
        number: 1
        name: Northeastern University
        department: Department of Economics
        address: 360 Huntington Avenue, Boston, MA 02115
  - id: Vernet136
    number: 136
    name: Antoine Vernet
    email: a.vernet@ucl.ac.uk
    phone: 00447733223263
    fax: NONE
    orcid: 0000-0002-7546-9829
    degrees: PhD
    attributes:
      corresponding: False
    affiliations:
      - id: Vernet136_1
        number: 1
        name: University College London
        department: The Bartlett School of Sustainable Construction
        address: Gower Street, London WC1E 6BT
  - id: Volkov137
    number: 137
    name: Eden Volkov
    email: eden.volkov@hhs.gov
    phone: 9173916184
    fax: NONE
    orcid: 0000-0003-1992-7052
    degrees: PhD
    attributes:
      corresponding: False
    affiliations:
      - id: Volkov137_1
        number: 1
        name: Department of Health and Human Services
        department: Office of the Assistant Secretary for Policy and Evaluation
        address: 200 Independence Ave SW, Washington, DC 20201
  - id: Wagner138
    number: 138
    name: Gary A. Wagner
    email: gary.wagner@louisiana.edu
    phone: 337-482-5381
    fax: NONE
    orcid: 0000-0002-7493-8419
    degrees: PhD
    attributes:
      corresponding: False
    affiliations:
      - id: Wagner138_1
        number: 1
        name: University of Louisiana at Lafayette
        department: Department of Economics & Finance
        address: 104 E. University Ave, Lafayette, LA 70504
  - id: Wang139
    number: 139
    name: Yue Wang
    email: april.wang@pg.canterbury.ac.nz
    phone: 0278660008
    fax: NONE
    orcid: NONE
    degrees: Master's Degree
    attributes:
      corresponding: False
    affiliations:
      - id: Wang139_1
        number: 1
        name: University of Canterbury
        department: Department of Economics and Finance
        address: UC Business School, University of Canterbury, 22 Kirkwood Avenue, Ilam, Christchurch 8140, New Zealand
  - id: Ward140
    number: 140
    name: Zachary Ward
    email: Zachary_Ward@baylor.edu
    phone: 2542142694
    fax: NONE
    orcid: NONE
    degrees: PhD
    attributes:
      corresponding: False
    affiliations:
      - id: Ward140_1
        number: 1
        name: Baylor University
        department: Department of Economics
        address: 1621 S 3rd St, Waco TX, 76706
  - id: Waters141
    number: 141
    name: Tom Waters
    email: tom_w@ifs.org.uk
    phone: 020 7291 4800
    fax: NONE
    orcid: 0000-0003-0299-1576
    degrees: Master's Degree
    attributes:
      corresponding: False
    affiliations:
      - id: Waters141_1
        number: 1
        name: Institute for Fiscal Studies
        department: NONE
        address: 7 Ridgmount Street, London, WC1E 7AE
      - id: Waters141_2
        number: 2
        name: University College London 
        department: Institute of Education 
        address: 20 Bedford Way, London WC1H 0AL
  - id: Weber142
    number: 142
    name: Ellerie Weber
    email: ellerie.weber@mountsinai.org
    phone: NONE
    fax: NONE
    orcid: 0000-0003-3179-7035
    degrees: PhD
    attributes:
      corresponding: False
    affiliations:
      - id: Weber142_1
        number: 1
        name: Icahn School of Medicine at Mount Sinai
        department: Department of Population Health Science and Policy
        address: One Gustave L. Levy Place Box 1077 New York, NY 10029
  - id: Weinberg143
    number: 143
    name: Stephen E Weinberg
    email: stephen.weinberg2@health.ny.gov
    phone: 19014855145
    fax: NONE
    orcid: 0000-0002-7676-4862
    degrees: PhD
    attributes:
      corresponding: False
    affiliations:
      - id: Weinberg143_1
        number: 1
        name: Health Research, Inc
        department: NONE
        address: NONE
  - id: Weißmüller144
    number: 144
    name: Kristina S. Weißmüller
    email: k.s.weissmueller@vu.nl
    phone: +31205988398
    fax: NONE
    orcid: 0000-0001-7697-6550
    degrees: PhD
    attributes:
      corresponding: False
    affiliations:
      - id: Weißmüller144_1
        number: 1
        name: Vrije Universiteit Amsterdam
        department: Department of Political Science and Public Administration
        address: De Boelelaan 1105, 1081 HV Amsterdam
  - id: Westheide145
    number: 145
    name: Christian Westheide
    email: christian.westheide@univie.ac.at
    phone: +43-1-4277-37505
    fax: NONE
    orcid: 0000-0002-7871-7998
    degrees: PhD
    attributes:
      corresponding: False
    affiliations:
      - id: Westheide145_1
        number: 1
        name: University of Vienna
        department: Department of Finance
        address: Department of Finance, Faculty of Business, Economics and Statistics, University of Vienna, Oskar-Morgenstern-Platz 1, 1090 Vienna, Austria
  - id: Williams146
    number: 146
    name: Kevin M. Williams
    email: KevinW@oxy.edu
    phone: 5107103947
    fax: NONE
    orcid: NONE
    degrees: PhD
    attributes:
      corresponding: False
    affiliations:
      - id: Williams146_1
        number: 1
        name: Occidental College
        department: Department of Economics
        address: 1600 Campus Road, Los Angeles CA 90041
  - id: Ye147
    number: 147
    name: Xiaoyang Ye
    email: xiaoyang.ye@brown.edu
    phone: 4257535168
    fax: NONE
    orcid: 0000-0003-2872-824X
    degrees: PhD
    attributes:
      corresponding: False
    affiliations:
      - id: Ye147_1
        number: 1
        name: Brown University
        department: Annenberg Institute for School Reform
        address: Box 1985, Providence, RI 02912
  - id: Yu148
    number: 148
    name: Jisang Yu
    email: jisangyu@ksu.edu
    phone: 5309023610
    fax: NONE
    orcid: 0000-0003-3936-1877
    degrees: PhD
    attributes:
      corresponding: False
    affiliations:
      - id: Yu148_1
        number: 1
        name: Kansas State University
        department: Department of Agricultural Economics
        address: 342 Waters Hall 1603 Old Claflin Pl Kansas State University Manhattan, KS 66506
  - id: Zahid149
    number: 149
    name: Muhammad Umer Zahid
    email: umerzahid@uconn.edu
    phone: NONE
    fax: NONE
    orcid: NONE
    degrees: NONE
    attributes:
      corresponding: False
    affiliations:
      - id: Zahid149_1
        number: 1
        name: University of Connecticut
        department: Agricultural and Resource Economics
        address: NONE
  - id: Zanoli150
    number: 150
    name: Raffaele Zanoli
    email: r.zanoli@univpm.it
    phone: +390712204929
    fax: NONE
    orcid: 0000-0002-7108-397X
    degrees: PhD
    attributes:
      corresponding: False
    affiliations:
      - id: Zanoli150_1
        number: 1
        name: Università Politecnica delle Marche (Marche Polytechnic University)
        department: Department of Agricultural, Food & Environmental Sciences
        address: Via Brecce Bianche 60131 ANCONA, Italy
editor: source
format: 
  pdf:
    keep-tex: true
    cite-method: biblatex
    pdf-engine: xelatex
bibliography: References.bib
number-sections: true
execute:
  warning: false
  message: false
  echo: false
abstract: |
  Abstract: We use a rigorous three-stage many-analysts design to assess how different researcher decisions---specifically data cleaning, research design, and the interpretation of a policy question---affect the variation in estimated treatment effects. A total of 146 research teams each completed the same causal inference task three times each: first with few constraints, then using a shared research design, and finally with pre-cleaned data in addition to a specified design. We find that even when analyzing the same data, teams reach different conclusions. In the first stage, the interquartile range (IQR) of the reported policy effect was 3.1 percentage points, with substantial outliers. Surprisingly, the second stage, which restricted research design choices, exhibited slightly higher IQR (4.0 percentage points), largely attributable to imperfect adherence to the prescribed protocol. By contrast, the final stage, featuring standardized data cleaning, narrowed variation in estimated effects, achieving an IQR of 2.4 percentage points. Reported sample sizes also displayed significant convergence under more restrictive conditions, with the IQR dropping from 295,187 in the first stage to 29,144 in the second, and effectively zero by the third. Our findings underscore the critical importance of data cleaning in shaping applied microeconomic results and highlight avenues for future replication efforts.
include-in-header:
  text:
    \usepackage{booktabs}
    \usepackage{longtable}
    \usepackage{placeins}
    \usepackage{setspace}
    \doublespacing
    \usepackage[backend=biber, style=authoryear, citestyle=authoryear]{biblatex}
    \addbibresource{References.bib}
    \usepackage{hyperref}
    \hypersetup{
      colorlinks=true,
      linkcolor=blue,
      citecolor=blue,
      urlcolor=blue
    }
output: 
  rticles::arxiv_article:
    keep_tex: true
---

```{r libraries and data import}
{
  library(rio)
  library(data.table)
  library(ggplot2)
  library(nicksshorts) # remotes::install_github('NickCH-K/nicksshorts')
  library(stringr)
  library(scales)
  library(vtable)
  library(fixest)
  library(modelsummary)
  library(here)
  library(patchwork)
  library(kableExtra)
  library(tidyverse)
}

dat = import(here("data", "cleaned_survey_post_corrections.parquet"), setclass = 'data.table')
dat[, Revision_of_Q14 := str_replace_all(Revision_of_Q14, '‚Äì','-')]
dat[, Revision_of_Q17 := str_replace_all(Revision_of_Q17, '‚Äì','-')]
dat[, Revision_of_Q20 := str_replace_all(Revision_of_Q20, '‚Äì','-')]

# CHANGE THIS COLOR PALETTE TO CHANGE ALL GRAPHS, except peer_review.R, where it
# is coded directly
colorpal = palette.colors(palette = 'Paired')
```

# Introduction

Skepticism about empirical results in economics is not new, but has received increasing attention over the last decade with concerns about replicability, publication bias, and p-hacking [@leamer1983let; @Brodeur2020].
Even in journals with data availability policies, code and data are, more often than not, either not available or do not reproduce the published results, and "policing replications" that test sensitivity of published results are rare [@herbert2021reproducibility; @ankel2023economists].
Even experimental economics results are not immune; a high percentage of studies cannot be replicated when tested using new data [@camerer2016evaluating].[^open-replication]

[^open-replication]: Experiments in social psychology, and psychology more broadly, perform even worse, leading to discussions about an ongoing "replication crisis" [@open2015estimating].

A broader issue is that researchers face myriad choices on data collection, data cleaning, variable selection, and estimation method, each of which can affect published results.
For example, researchers are more likely to present marginally significant results over marginally insignificant results [@Brodeur2016; @Brodeur2020].
Even without conscious manipulation, the numerous "researcher degrees of freedom" can lead equally competent researchers to substantially different conclusions [@simmons2011false].
At least in psychology, the variation introduced by researcher choices might outweigh the population variation we typically consider when estimating standard errors [@holzmeister2023heterogeneity].

Our goal is to understand the relative importance of the various researcher degrees of freedom in explaining estimate variation.[^compare-replication-studies]
We use a "many-analysts" design, where researchers independently perform the same research task.
We additionally have those researchers perform the task multiple times, under progressively stricter restrictions on their choices.
Our chosen task, common in applied econometrics, is to estimate the causal effect of a policy implemented at a specific time and affecting only some individuals. 
We isolate researcher degrees of freedom at each stage of the research process to examine where researcher choices vary most and where they most strongly impact results. 
We also examine whether differences in researchers' characteristics and their analytic and data cleaning choices can explain the variation in results.

[^compare-replication-studies]: Traditional replication work asks whether a study’s results are robust to re-evaluation, whereas researcher degrees of freedom focuses on whether different researchers would perform the same study differently.
These fields intersect when replication failures arise because both the original and replication analyses made reasonable but divergent choices [@bryan2019replicator].

The three main contributions of this paper are: first, we introduce multiple iterations of the research task, second, the initial stage provides researchers with more freedom in relation to data processing than is common in many-analyst studies, and, finally, we have a substantially larger number of researchers who complete the project than most prior many-analysts efforts.
By introducing multiple iterations of the task, each time restricting the amount of choice that researchers can make and so reducing researcher degrees of freedom, we can both observe the overall amount of variation in estimates between researchers, as is common in many-analysts designs, and separately evaluate the influence of choice in research design and in data cleaning.

In a "many-analysts" design, organizers provide multiple teams of researchers with the same data and have them independently try to answer the same research question [@silberzahn2018many].
Many-analysts studies have been conducted in microeconomics [@huntington2021influence; @Borjas2024], finance [@Menkveld2024], religion [@hoogeveen2023many], neuroimaging [@botvinik2020variability], political science [@breznau2021observing], machine learning [@chen2024subjectivity], ecology and evolutionary biology [@gould2023same], psychology [@boehm2018estimating; @bastiaansen2020time; @schweinsberg2021same], and medical informatics [@ostropolets2023reproducible], among others.[^magnus]

[^magnus]: See also @Magnus1997 for an early example in the same vein in applied econometrics.

Most many-analysts studies find meaningful variation in both methods and conclusions across researchers.
However, participation in a many-analysts study takes considerable time and effort, which limits the size of most prior studies and prevents them from going beyond demonstrating that variation exists to exploring its causes and potential remedies.[^finance] 
To achieve sufficient power to both show that variation exists *and* explain its sources, our goal was to have at least 90 researchers complete all the steps of the project and we had 146 research teams finish all tasks.
Moreover, many-analysts findings may not necessarily imply a problem if the research question is unclear or if standard meta-analytic practices are not followed, which can inflate apparent variation [@auspurg2021has; @auspurg2023social].

[^finance]: A notable exception is @Menkveld2024, which had 164 teams test the same hypotheses on the same data.

Three common explanations for researcher variation are task difficulty, researcher experience or characteristics, and peer review. 
The more complex or difficult-to-analyze scenarios are, the less researcher agreement [@Menkveld2024; @ortloff2023different]. 
Higher-quality or more experienced teams tend to agree more and draw more abstract codebooks and conclusions, and replicators with more coding skill find more errors [@Menkveld2024; @ortloff2023different; @broderick2020automatic].
Researcher political orientation and personality also affect findings, both in many-analysts work and outside [@Borjas2024; @jelveh2024political; @sulik2023scientists]. 
However, some many-analysts studies show that researcher characteristics explain only a small share of the variation [@breznau2021observing]. 
Finally, peer review may increase agreement if there is an option to revise, although if instead outside evaluation is used as a measure of researcher quality, peer review scores do not necessarily predict outlier results [@Menkveld2024; @gould2023same].

Other work uses simulation to explore numerous analytical or data-cleaning combinations and measure resulting estimate variation.
Like many-analysts studies, the aim of these simulations is to identify how different choices influence results, but they are necessarily limited to decisions identified by the organizers and treat all combinations equally.
One particularly relevant example examines the sensitivity of results in an observational psychological data set to various preprocessing and modeling choices and finds significant variation [@klau2023comparing]. 
A similar attempt to separate researcher variation into modeling and preprocessing components is also done in a many-analysts design in @huntington2021influence, although in a limited way.

We employ three-staged design to evaluate multiple sources of variation: data preparation, research design, and the interpretation of the research question.
Each stage allows a narrowing degree of researcher choice, with randomized peer reviews in between stages.
The first stage allows researchers substantial freedom in answering the research question, while the second stage specified the research design more precisely, and the third round in addition provided a pre-cleaned data set.
The goal is to incorporate the mechanisms proposed by the literature and responding to the critique of prior studies [@auspurg2021has]. 
We also collect researcher characteristics to explore their role in estimate variation, although not in a controlled way.
We do not address the difficulty of the research task as a potential source of researcher variation here.

Our results show that while researchers varied considerably in their data preparation and modeling choices, the reported policy effects were relatively similar to each other, at least in the center of the distribution. 
The IQR of policy impacts in the first stage, where researchers had full freedom, was only 3.1 percentage points, although there were substantial outlier estimates. 
The second stage showed *less* agreement than the first, with an IQR of 4.0 percentage points, with the reduction in agreement driven by some researchers not fully adhering to the specified research design. 
In the final stage, where data was pre-cleaned to eliminate errors in data preparation, the IQR fell to its lowest level at 2.4 percentage points.
We considered this a meaningful improvement in agreement, although the reduction in the variance of estimated effects was not statistically significant. 
Specifying a research design considerably improved agreement in reported sample sizes, with the IQR of sample sizes falling from 295,187 originally to 29,144 in the second stage to effectively 0 for the final stage. 
In contrast to these changes, we found no impact of peer review or researcher background or experience on reported effects.

Some of the observed differences stem from decisions that are typically scrutinized, such as research design and control variables. 
Other arise in less examined areas, like functional form, data cleaning, and sample limitation decisions. 
When researchers are required to use the same design, their results became more similar, especially when that shared design is adhered to. 
Agreement rose sharply when data was pre-cleaned, suggesting that data cleaning decisions are a major source of variation. 
More standardized data-cleaning procedure and greater transparency in cleaning code could substantially improve consistency and credibility in applied microeconomics.

The rest of the paper is organized as follows.
We first present the research design in Section @sec-design.
This is followed by a description of the collected data and characteristics of the participating research teams.
Section @sec-results presents the results.
Finally, we discuss the implications of our results and suggest areas of future research.

# Design {#sec-design}

We have the same set of researchers complete the same research task at least three times to isolate the influence of different sources of researcher variation. 
The research task is to estimate the effect of the Deferred Action for Childhood Arrivals (DACA) program on the probability that those affected by the program work full-time.
The details and restrictions differ between the three main rounds, which we will refer to as Task 1, Task 2, and Task 3. 
The intuition behind this design is that if the removal of a specific kind of researcher freedom meaningfully reduces the variation in results between researchers, then that degree of freedom is a meaningful contributor to researcher variation.
Following each task, a subset of researchers are randomized into peer reviews, and given the opportunity to revise their work.

The following goals and instructions are shared across all tasks:

-   Estimate the causal effect of the DACA policy on the probability of working full-time, among the group affected by that policy (see Appendix @sec-research-task below for more details).

-   Use American Community Survey (ACS) data to estimate the effect, using data no older than 2006 and no newer than 2016.

-   Procure ACS data from IPUMS [@ruggles2024ipums], selecting only one-year files and using harmonized variables.

-   Optionally, combine the ACS data with a data set on the presence or absence of other relevant policies, provided by the organizers.

-   Use a statistics package or language that allows results to be immediately replicated.

Researchers were also given background information on DACA and its eligibility criteria, guidance on how to use the IPUMS website, instructed to use assistants for any work they would normally use assistants for, and to complete their analysis as though it had been their own idea, rather than attempting to match or not-match other researchers, or asking the project organizers how they would like the analysis to be performed.

Task 1 gives researchers a large amount of freedom in how they complete the research task, with the instructions above comprising the entirety of the limitations on researchers in Task 1. 
Each successive task removes a degree of freedom from the researcher and further specifies how the analysis is to be performed. 

Task 2 specified the research design more precisely, with the goal of examining whether researcher variation arise from an imprecise statement of the research question, as in @auspurg2021has, is due to differences in research design choices.
Instead of allowing any research design to identify the causal effect of interest, Task 2 gave specific definitions for which individuals comprised a "treated" group and which comprised an "untreated" comparison group.[^3] 
Researchers are then instructed to estimate the effect by comparing how outcomes for the "treated" group changed from before DACA was implemented to afterwards against how outcome for the "untreated" group changed. 
This can be thought of as a difference-in-differences style design, although the phrase "difference-in-differences" was not used in the instructions.

[^3]: Although eligibility criteria for DACA were explicitly given in Task 1, Task 2 further limits the treated group by narrowing the acceptable age range. 
The limitation was more impactful for defining the untreated comparison group, though. 
Many researchers did use a treated/untreated group approach in Task 1 before it was specified in Task 2, but researchers defined the untreated group in highly diverse ways, as will be shown in the Results section.

To show the researcher variation introduced by decisions made in the data cleaning and variable definition process, Task 3 provides a pre-cleaned data set, prepared by the organizers, while maintaining the same research design limitations as in Task 2.
In principle, a researcher following the Task 2 instructions should arrive at the same sample size, number of treated individuals, and number of untreated individuals as in Task 3, as well as the same definition for the outcome variable.[^4] 
Hence, differences in the data set and in the results between Task 2 and Task 3 should be a result of differences in the data cleaning and preparation process.
The data set offered a pre-prepared treated/untreated-group indicator as specified in Task 2, limited the data set only to the treated and untreated group, prepared and cleaned all variables in the data set that did not already come pre-cleaned, handled missing-data flags, merged in state policy data, and offered standardized simplified recodings of demographic variables. 
Researchers were instructed to not further clean the data or limit the sample.

[^4]: The Task 2 instructions do leave some leeway for definition of some variables, in particular control variables like education or race, which have a specific recoded version available in Task 3 that are not specified in the Task 2 instructions. 
However, the definitions of the treated and untreated comparison groups should be the same between Task 2 and Task 3.

Following each of the research tasks, 2/3 of the researchers are randomly assigned to peer review and 1/3 not assigned to peer review. 
Those in peer review are randomly assigned in pairs. 
Those pairs were given work performed by the other member of their pair: the other person's response to the research survey (see below) as well as a brief write-up representing their work, usually including a regression table. Each member performed a blind review of the provided work, and provided a written assessment of that work, which was shared with the original researcher. 
Reviewers were instructed to produce a review "as though (they) were the reviewer of a journal article," and to judge the work as though they were reviewing for a journal where a study of this kind "could be published if the work was of high quality."
Following peer review, researchers have an opportunity to revise their work in light of the peer review (or for any other reason). 
Importantly, revision is not mandatory, nor is satisfying one's peer reviewer, and the majority of researchers choose not to submit revisions.

Notably, this form of peer review does not match what is typically done in peer review work for journal publications. 
In particular, revision is not mandatory, all reviewers have themselves completed a study with the same goal and data and so have extensive background information, and all reviewers are themselves also reviewed by the same person. 
These features will all affect interpretation of the peer review results. 
In particular, the non-mandatory nature of the peer review means that the between-round revision work is only visible for a small subset of the researchers, and the paired nature of the reviews means we cannot separate the effect of being reviewed from the effect of reviewing someone else.

Following each research task and revision, researchers filled out a survey about their work.[^5] 
This survey asked them to report their findings, additional information like sample size and standard errors, and choices made in the process of doing the analysis like sample restrictions, treated-group definitions, estimator, and standard error adjustments. 
Researchers were also asked to justify why they had made these choices.

[^5]: Note that the design of this study, and this survey, predates @sarafoglou2024subjective. 
We, therefore, do not include questions related to researchers' subjective assessments of topics such as methodology choices and consistency of results.

There are several papers that use the same ACS data set to identify the effect of DACA on various outcomes, although, to the best of our knowledge, no prior work has been done on the effect of DACA on the probability of working full-time.
The design used in Tasks 2 and 3 was most directly inspired by @amuedo2016can, although the designs do not match exactly, and the outcomes of interest are not the same. 
There are also prior research on topics such as educational and economic attainment, health care use and outcomes, and marriage-partner decisions [@Jones2020;@Giuntella2020;@Amuedo-Dorantes2024].
Researchers are informed that such previous studies exist and that they can optionally look into previous studies for background as they would normally do when performing research, although no specific previous study is listed. 
The instructions emphasize that any previous study does not constitute a "right answer" that researchers should be trying to match.

More detailed instructions for the research task and description of the limitation between task rounds are in Appendix @sec-research-task, and 
full instructions for each task, as well as post-task survey text and the peer-reviewing instructions, are available in the online at \url{https://osf.io/9p7j6/}.
This research design and analysis plan has been preregistered [@portner_huntington-klein_2022].
Analyses that were not preregistered will be noted in the results section as they are performed. 
Data processing and analysis as well as table and figure creation for this paper were performed using R.[^r-packages]

[^r-packages]: We used the following R packages **data.table**, **tidyverse**, **rio**, **fixest**, **car**, **modelsummary**, and **vtable** [@R-data-table; @tidyverse2019; @R-rio; @fixest2018; @car2019; @modelsummary2022; @R-vtable]. 


# Recruitment and Descriptive Statistics {#sec-recruitment-descriptive}

In a many-analysts study, researchers who carry out the research task are the subject of inquiry, so their recruitment is a key feature of the study.
The goal of the project organizers was to make the set of researchers representative of those who produce the applied microeconomics literature. 
As such, recruitment criteria focused on identifying people who have produced applied microeconomic research, including non-academic applied microeconomics research.
Researchers qualified for the project if they satisfied any of the following criteria: they are academic faculty working in applied microeconomics; they are a graduate student *and* have a published or forthcoming paper in applied microeconomics; or they hold a PhD *and* work in a job where they write non-academic reports using tools from applied microeconomics to estimate causal effects.[^10]
Participation was not limited on the basis of country, career stage, or demographics such as sex, race, or sexual or gender identity.

[^10]: This qualification allow those employed in, for example, central banks, the World Bank, and private sector research, to participate.

For our simulation-based power analysis, we assumed that each research task would have 5% smaller between-researcher variation in effects than the previous round and determined the statistical power needed to detect a linear relationship between task number and the squared deviation of effects (variance of estimated effects across researchers). 
With 90 researchers finishing all tasks, we would have 90% power to detect this effect. 
For comparisons of only two different research tasks, 90 researchers would give 85% power to detect a decline in variance from one stage to the next of 15% or more, a reasonable effect size given previous many-analyst studies.
We further assumed that attrition rates would be roughly 50%, which would suggest recruiting 180 eligible researchers to achieve adequate power. 
We revised that goal to 200 to account for our assumptions potentially being optimistic and obtained funding to support payments to 200 researchers.

The project was advertised to potential researchers through three avenues: (1) social media posts on Twitter and LinkedIn, (2) emails to professional organizations, and (3) emails to United States economics department chairs. 
For emails to departments heads, we gathered the list of all 286 economics departments listed in the U.S. News and World Report. 
We emailed the 264 departments for which we could locate email addresses for a front desk or (preferably) department chair, asking for the message to be passed on to all relevant faculty.
The recruitment message described the project and its goals, and provided a link to a website (<https://nickch-k.github.io/ManyEconomists/>) with further detail on project expectations and incentives for participation and a link to a survey to determine eligibility for the project.
As incentives for participation we offered, upon completion of all three tasks, a \$2,000 payment for up to 200 of the participants and authorship on the eventual paper.

## Participation and Attrition

```{r Participation and Attrition Code}
source('../code/participation_and_attrition.R')
```

A total of `r justcount[1,Participants]` people submitted applications for the project (Table \ref{tbl-attrition} shows the participation and attrition).
Of those, `r justcount[1, Attrition]` were ineligible for the project, with most ineligible people graduate students without a forthcoming paper.
This left `r justcount[2,Participants]` eligible participants, which was in excess of the 200 the available budget allowed for. 
We, therefore, randomly listed the 282 participants who had signed up by the original due date, and added the 13 late signups at the end of this list.
The first 200 on the list were told that they would be paid if they completed all stages of the project, but were not told their order.
Everyone with a number above 200 were given their place in the list, and informed that they would be paid if they completed all stages of the project and sufficient numbers of those below them did not complete all steps.
For example, if someone was number 206, payment was conditional on at least six participants with a lower number did not complete all steps.

```{r Attrition Table}
justcount |> 
  kable(
    booktabs = TRUE,
    caption = 'Participation and Attrition\\label{tbl-attrition}',
    format = "latex"
    ) |>
  column_spec(1:3, latex_column_spec = "lrr")
```

Our initial assumptions that attrition rates would be near 50% were almost exactly correct, with `r percent(justcount[5,Participants]/justcount[2,Participants],.01)` of these initial `r justcount[2,Participants]` eligible researchers completing all three stages.
Nearly all of the attrition occurred by the completion of Task 1. 
After `r justcount[2,Participants]-justcount[3,Participants]` eligible researchers failed to complete Task 1, only a further `r justcount[3,Participants]-justcount[5,Participants]` failed to complete Task 3. 
This means we have `r justcount[5,Participants]` researchers who completed all three research tasks, well above the goal of 90, and that we were able to pay all participants who completed all steps.

[Next two paragraphs not edited; waiting for new results from Nick; potentially drop or move to Appendix given that we were able to pay everyone]

The high recruitment numbers and the fact that nearly all attrition occurs before Task 1 is complete allows us to evaluate the impact of the payment incentive.[^decline-pay] 
One potential concern with our incentive design is that payment and authorship are offered to anyone who completes all tasks, regardless of the quality of their work. 
We evaluate whether being guaranteed payment affects the probability of completing Task 1 using a regression discontinuity design. 
Someone randomly assigned to position 199 in the ordering is guaranteed payment if they complete all the tasks, while someone in position 201 may think they are likely to receive payment, but they are not guaranteed it.

[^decline-pay]: Seven researchers indicated that they did not want payment on their consent form.
Of those, three finished the project, while the other four did not. 

We do not find that completion rates are significantly lower just above the cutoff relative to just below it. 
Appendix @fig-rdd and Table \ref{tab-rdd-reg} show that immediately above the cutoff, completion rates are no different, although they drop as researchers get further from the cutoff before becoming higher again. 
Regression discontinuity effect estimates vary. Using either a local-polynomial regression with a triangular kernel bandwidth or an OLS regression discontinuity estimate with a quadratic specification and the full range of the data (not including late signups) show meaningfully large effects of being above the cutoff of -.2 on completion rates, but this is very noisy and statistically insignificant. 
Using a linear specification, linear regression, and the full range of the data instead to maximize statistical power shows an insignificant and small result of .01.[^13] 
This is not strong evidence that participants were simply signing up in an attempt to get a \$2,000 payment for little effort.

[^13]: Use of the full range, rather than a bandwidth, is justified given that the running variable is randomly assigned aside from the late sign-ups. We also find no effect if we drop the late sign-ups from the regression discontinuity analysis.

## Researcher Characteristics {#sec-researcher-characteristics}

Tables \ref{tab-samp1} and \ref{tab-samp2} show the characteristics of the recruited sample, and how those characteristics changed with eligibility and attrition. 
Task 2 is omitted as an attrition stage since so few people dropped out between Task 1 and Task 2.
One researcher completed all three research tasks, and appears in the above tables, but their work has been removed from the results in the rest of the paper, because a misunderstanding of the instructions meant that their work did not attempt to estimate the effect of DACA on the probability of employment.

```{r Reseacher Recruitment Table}
# Generate the summary data frame
table_2 <- sumtable(alldemog,
         vars = c('Researcher_Q11', 'Researcher_Q12_1', 'Researcher_Q12_2'),
         labels = c('Recruitment Source', 'Certainty to Finish Task 1', 'Certainty to Finish Task 3'),
         group = 'Round',
         out = 'return' 
) 

# Sumtable places the group variable as the first row, so we remove it
table_2 <- table_2[-1, ]
row.names(table_2) <- NULL

table_2 |>
  kbl(
    format = "latex",
    caption = "Researcher Recruitment Source and Completion Confidence\\label{tab-samp1}",
    booktabs = TRUE
  ) |>
  add_header_above(c(" " = 1, "Signup" = 3, "Task 1" = 3, 
                     "Task 1" = 3, "Task 3" = 3)) |>
  add_header_above(c(" " = 1, "Original" = 3, "Assigned" = 3, 
                     "Finished" = 3, "Finished" = 3), line = FALSE) |>
  add_header_above(c(" " = 1, "Round" = 12), line = FALSE) |> 
  kable_styling(
    latex_options = "scale_down"
  ) |>
  column_spec(1:12, latex_column_spec = "lrrrrrrrrrrr") |>
  footnote(
    general  = c("\\\\footnotesize{Results for Tasks 2 are omitted because very few researchers dropped out between Task 1 and Task 2. Full results are available upon request.}"),
    general_title = "\\\\footnotesize{Note:}\\\\hspace{-0.5cm}",
    escape = FALSE,
    footnote_as_chunk = TRUE,
    threeparttable = TRUE
  )
```

```{r Researcher Professional Experience Table}
linesep<-function(x,y=character()){
  if(!length(x))
    return(y)
  linesep(x[-length(x)], c(rep('',x[length(x)]-1),'\\addlinespace',y))  
}
alldemog[Researcher_Q13 %like% 'Labor', Researcher_Cats := 'Labor']
alldemog[Researcher_Q13 %like% 'Immigration', Researcher_Cats := 'Immigration']
alldemog[Researcher_Q13 %like% 'Labor' & Researcher_Q13 %like% 'Immigration', Researcher_Cats := 'Immigration & Labor']
table_3 <- sumtable(alldemog, 
         vars = c(
           'Researcher_Q10', 'Researcher_Q6', 'Q8Recode', 'Researcher_Cats',
           'Researcher_Q15', 'RaceRecode', 'Researcher_Q17'
           ), 
         labels = c(
           'Degree', 'Occupation', 'Research Experience', 'Field', 
           'Gender', 'Race', 'LGBTQ+'
           ), 
         group = 'Round',
         out = 'return'
)

# Sumtable places the group variable as the first row, so we remove it
table_3 <- table_3[-1, ] 
row.names(table_3) <- NULL

table_3 |>
  kbl(
    format = "latex",
    caption = "Researcher Professional Experience and Demographics\\label{tab-samp2}",
    booktabs = TRUE,
    linesep = linesep(c(6, 5, 5, 4, 6))
  ) |>
  add_header_above(c(" " = 1, "Signup" = 2, "Task 1" = 2, 
                     "Task 1" = 2, "Task 3" = 2)) |>
  add_header_above(c(" " = 1, "Original" = 2, "Assigned" = 2, 
                     "Finished" = 2, "Finished" = 2), line = FALSE) |>
  add_header_above(c(" " = 1, "Round" = 8), line = FALSE) |>
  pack_rows(
    index = c("Professional Experience" = 21, "Demographics" = 15),
    bold = FALSE,
    hline_after = TRUE,
    latex_gap_space = "0.5em",
    latex_align = "c"
  ) |>
  kable_styling(
    latex_options = "scale_down"
    ) |>
  column_spec(1:9, latex_column_spec = "lrrrrrrrr") |>
  footnote(
    general  = c("\\\\footnotesize{Results for Tasks 2 are omitted because only four researchers dropped out between Task 1 and Task 2. Full results are available upon request.}"),
    general_title = "\\\\footnotesize{Note:}\\\\hspace{-0.5cm}",
    escape = FALSE,
    footnote_as_chunk = TRUE,
    threeparttable = TRUE
  )

```

The majority of researchers were recruited via social media.
Upon signup, researchers were about 90% confident of their ability to finish all three tasks. 
Those recruited from social media reported a higher expectation of finishing all three tasks. 
More-confident researchers were slightly more likely to actually finish with the average confidence rates of those who did finish about 92%.

The majority of eligible researchers (`r alldemog[Round == 'Assigned task 1',percent(mean(Researcher_Q10 %in% c('PhD','Prof. Degree')),1)]`) had PhDs. 
PhD holders were also more likely than other eligible researchers to complete all three tasks.
These PhDs are split across faculty (`r alldemog[Round == 'Assigned task 1',percent(mean(Researcher_Q6 %in% c('Faculty')),1)]`) and other non-faculty researchers (`r alldemog[Round == 'Assigned task 1',percent(mean(Researcher_Q6 %in% c('Other Researcher')),1)]`), both of which were more likely than graduate students to finish all three rounds. 
Most of the researchers had at least one published paper.[^15] 
About a third of initial researchers, and 40% of the final set of researchers, had done work in either immigration or labor economics, the fields closest to the research task at hand, with 5% having done work in both, although all researchers had done work in applied microeconomics generally.

[^15]: Researchers in the "faculty" or "non-faculty researchers" categories who do not hold PhDs were either people who had been hired to faculty roles without holding PhDs (such as ABDs, or people in a faculty position requiring only a Master's degree), or people with Master's degrees in non-faculty research positions who had published academic papers (some of whom were still graduate students). 
Researchers with "No Academic Papers" are non-academic researchers who produce work not intended for academic journal publication. 
Those with "No Published Academic Papers" have papers that are forthcoming, or are faculty who only have working papers and no publications.

The original enrollment was just under 80% male and more than 55% white, with the white share growing to 66% by the end of Task 3. 
The 80% male figure is similar to the share male found for faculty at a selected set of top economics departments in 2017 by @lundberg2019women, and among all actively publishing economists in 2019 by @card2022gender. 
About half of the sample was situated in the United States, and about half was from another country. 
The representativeness of the racial mixture is difficult to assess for this reason; 66% white would be low if the entire sample were from the United States [@stansbury2023economics], but it is unclear what the population rate is in a 50% US/50% other location sample.
Aside from being skewed towards the United States, the sample largely reflects the group of people who publish work in applied microeconomics. 
The US overrepresentation is likely driven by the emails sent to US economics departments, that the project was advertised and carried out in English, and that the project organizers are in the United States and advertised the project using their own social media.


```{r Researcher Demographics Table}
# table_4 <- sumtable(alldemog, 
#          vars = c('Researcher_Q15',
#                             'RaceRecode',
#                             'Researcher_Q17'), 
#          labels = c('Gender', 'Race', 'LGBTQ+'), 
#          group = 'Round',
#          out = 'return',
# ) 
# 
# # Sumtable places the group variable as the first row, so we remove it
# table_4 <- table_4[-1, ]
# row.names(table_4) <- NULL
# 
# table_4 |>
#   kbl(
#     format = "latex",
#     caption = "Researcher Demographics\\label{tab-samp3}",
#     booktabs = TRUE,
#     linesep = linesep(c(5,6))
#   ) |>
#   add_header_above(c(" " = 1, "Signup" = 2, "Task 1" = 2, 
#                      "Task 1" = 2, "Task 3" = 2)) |>
#   add_header_above(c(" " = 1, "Original" = 2, "Assigned" = 2, 
#                      "Finished" = 2, "Finished" = 2), line = FALSE) |>
#   add_header_above(c(" " = 1, "Round" = 8), line = FALSE) |>
#   kable_styling(
#     latex_options = "scale_down"
#     ) |>
#   column_spec(1:9, latex_column_spec = "lrrrrrrrr") |>
#   footnote(
#     general  = c("\\\\footnotesize{Results for Tasks 2 are omitted because only four researchers dropped out between Task 1 and Task 2. Full results are available upon # request.}"),
#     general_title = "\\\\footnotesize{Note:}\\\\hspace{-0.5cm}",
#     escape = FALSE,
#     footnote_as_chunk = TRUE,
#     threeparttable = TRUE
#   )

```

```{r}
# OMIT THIS TABLE, BUT FROM IT WE GET 1 completed Python, 1 SPSS, 1 R/Stata, 33 R, 109 Stata in completed
# alldemog[Q2 == 'Finished task 3'] |>
#   sumtable(vars =  c('Researcher_Q10','Researcher_Q6', 'Q8Recode','Researcher_Q15',
#                             'RaceRecode',
#                             'Researcher_Q17',
#                      'Researcher_Q11',
#                      'Researcher_Cats',
#                      'Language'), 
#          labels = c('Degree','Occupation', 'Research Experience','Gender','Race','LGBTQ+','Recruitment Source','Field',
#                     'Coding Language'),
#          col.breaks = 4,
#          out = 'latex',
#          fit.page = '\\textwidth',
#          anchor = 'tab-samp4')

```

# Results {#sec-results}

This section examines the variation in effects, samples, and methods across researchers and conditions.
We demonstrate that such variation exists and evaluate explanations for it.
The preregistered hypotheses and analyses are shown in Appendix @sec-preregistration.
[should we discuss briefly what those hypotheses are here? Alternatively, we should have some discussion of what we will be doing in this section.]

Importantly, the results are based on survey responses provided by researchers regarding their findings and the decisions they made. 
The project organizers did not cross-check these survey responses against the researchers' actual coding, which means there is no guarantee of consistency between the two.[^except] 
Therefore, the variation presented here reflects what readers might find in the published descriptions of studies. 
Any discrepancies that arise from coding errors or misrepresentations in research reports will not be addressed here but could be the focus of future investigations.

[^except]: The exception is a small number of cases where the survey response could not be interpreted.

The distribution of estimated effects, reported standard errors, and the size of the sample used, both overall and for the treated group are in Table \ref{tab-effectdist}. 
The effect distributions are shown in two ways: unweighted and using inverse-standard-error weights.[^16] 
Several data points are dropped from the weighted analysis for researchers who did not report standard errors or reported zero. 
Other missing values are researchers who did not repond to a given question.
The lower number of responses for the treated-group sample size question in Task 3 is due to researchers who skipped it because they assumed the answer was obvious.

[^16]: The use of inverse-standard-error weights is not preregistered but follows meta-analytic standards, reducing the influence of estimates that may be outliers due to being estimated with a highly-noisy method, under the suggestion of @auspurg2023social. 
Weights are truncated at the 95th percentile (200, or a standard error of .005) so as to avoid any single researcher having too much influence on results. 
Not using the truncation leads to more agreement because a few researchers with very small standard errors make up a significant share of the weighted sample.


```{r Main Scripts}
# Ensure the proper analytic sample for all following code
dat = dat[Q1 != 972]
dat = dat[Q1 %in% Q1[Q2 == "The third replication task"]]

source('../code/variation_in_effects_and_sample_sizes.R')
source('../code/variance_tests.R')
source('../code/researcher_characteristics_and_effects.R')
source('../code/researcher_characteristics_and_effects_b.R')
source('../code/analytic_choices.R')
source('../code/clean_controls.R')
source('../code/post_handcoding_sample_limitations.R')
source('../code/round_2_bimodality.R')
source('../code/sd_i_regress_hypothesis_2.R')
```

```{r Peer Review Code, results='hide', echo=FALSE, fig.show='hide'}

# This code generated the sample_restrictions_handcoded file that was then corrected by hand
#source('../code/sample_limitations.R')
source('../code/peer_review.R')
source('../code/peer_review_sample_size.R')

# Generate ordering for spot checks

# generate a random order for spot checks
# set.seed(1000)
# spot_checks = copy(sampdat)
# spot_checks = spot_checks[Round %in% c('Task 1','Task 2')]
# spot_checks[, random_order := sample(1:nrow(spot_checks), nrow(spot_checks))]
# setorder(spot_checks, random_order)
# export(spot_checks, 'spot_checks_no_revisions.xlsx')
```

```{r Distribution of Reported Effects and Samples Sizes Table}
effect_sum_tab |>
  # remove 1st, 7th, and 13th rows
  slice(-1) |>
  slice(-6) |>
  slice(-11) |>
  kable(
    caption = 'Distribution of Reported Effects and Sample Sizes\\label{tab-effectdist}',
    booktabs = TRUE,
    format = "latex"
    ) |>
  pack_rows(
    index = c("Round: Task 1" = 5, "Round: Task 2" = 5, "Round: Task 3" = 5),
    bold = FALSE
  ) |>
  kable_styling(
    latex_options = "scale_down"
    ) |>
  column_spec(1:9, latex_column_spec = "lrrrrrrrr")
```


## Variation Across Researchers {#sec-variation}

The average effects are relatively similar across the three Tasks, but there is a particularly strong increase in researcher agreement measured by the inter-quartile range (IQR) when we provided pre-cleaned data in Tasks 3.
In Task 1, the mean unweighted estimated effect of DACA eligibility on the probability of working full-time was .053, which was above the 75th percentile because of high top-end estimates, with the unweighted median estimate .030. 
However, even with substantial researcher freedom, there was a reasonable amount of agreement outside the tails.
The 25th to 75th percentile range of the unweighted effect was .014 to .051, an IQR of .037, or 3.7 percentage points in the effect.[^weights]
Task 2 shows less agreement than Task 1, despite giving researchers less freedom, with the unweighted IQRs increasing to .043 and the coefficient of variation (CV) increasing from 1.7 to 2.3. 
For Task 3, agreement increases between researchers, with the 25th and 75th percentile unweighted effects .031 and .058 (IQR .027 with a median of 0.05), although the CV only declines from 2.3 to 2.2. 
Hence, from Round 1 to Round 3 we see considerable increases in agreement between researchers, although there are still substantial outliers.

[^weights]: The use of weights narrows the distribution of effects across all tasks: researchers reporting smaller standard errors also reported estimates that were more similar to each other.

The changes in sample and treated-group sizes across tasks reflect, to a large extent, the same pattern as for effect size.
For tasks 1, the 25th and 75th sample size percentiles ranged from 61,600 to 356,787, with some researchers using millions of observations.
In the absence of a specified control group, some researchers appear to have used the entire ACS sample, including people very unlike the DACA-eligible group.
Opposite the effect size, the IQR did reduce considerably in Task 2, where the instructions specified a treated and comparison group, although the 75th percentile (48,125) is still double the 25th (18,981) and some researchers still used millions of observations, resulting in an increase in the CV from 3.7 in Tasks 1 to 6.8. 

The imposition of a shared definition for the treated group reduced the treated-group IQR from 34,631 in Taks 1 to 9,879 in Task 2. 
Theoretically, since there was a shared definition of the treated group in Task 2, variation in the treated-group should be similar in Tasks 2 and 3.[^treated-variation]
That they are not indicates that not all instructions were implemented in the same way across researchers, which will be explored further in @sec-sample-limitations. 
Despite a shared understanding of who was eligible for DACA and who should be in the treated group, only a shared data preparation that implemented these rules for people led to sharp agreement in the size of the treated-groups sample.

[^treated-variation]: Variation in the treated-group size is affected by researcher confusion in responding to the survey question. 
The survey question instructed researchers to not count individuals eligible for DACA as treated for the purposes of this question if they were in a pre-DACA year. 
However, many researchers counted these individuals as treated anyway, leading to variation in the Task 3 distribution, even though every researcher is at this point working with the same eligibility indicator.

With the conflicting changes between the first two tasks and the substantial number of outliers in both effect and sample sizes, @fig-effect-distributions and @fig-sample-size-distributions show the distributions of effects and sample sizes, respectively, across the three tasks.[^task-3]
For Task 2, both the the effect and sample sizes distributions are somewhat bimodal; for the effect size especially when weighted. 
One of these modes appears to be researchers reporting effect estimates and sample size of a similar level to those in Task 1, and others reporting effect estimates similar to what would later be found in Task 3.
The bimodality is still present in Tasks 3, but with much more agreement and density at the higher mode. 
The decline in agreement and the bimodal result for Task 2 will be investigated further in @sec-bimodal.

[^task-3]: Note that for the sample sizes, the x-axes are on a log scale and that Task 3 is not shown in the graph because the sample is pre-specified. 

```{r Distribution of Reported Effect Sizes Figure}
#| fig-width: 8
#| fig-height: 8
#| label: fig-effect-distributions
#| fig-cap: Distributions of Reported Effect Sizes by Task With the Weighted Distributions Using Inverse-Standard-Error Weights
p_effect_distribution_task_on_y_axis
```

```{r Combined Sample size figures}
#| label: fig-sample-size-distributions
#| fig-cap: Distributions of Reported Sample Sizes and Treated-Group Sizes
#| fig-width: 8
#| fig-height: 8
(p_sample_size_distributions + ggtitle("(a) Distributions of Reported Sample Sizes")) /
(p_treated_group_sample_size + ggtitle("(b) Distributions of Reported Treated-Group Sizes"))
```

Reported standard errors increase substantially from round to round despite relatively minor changes in average effects, which was driven primarily by the research design specification considerably narrowing the samples used.[^nick-ratios]
@fig-full-effect-distribution shows the reported effect sizes ranked from smallest to largest for each round, together with the calculated confidence intervals for each effect size based on the reported standard error.
The distribution of effects narrows across rounds as shown by the flatter specification curve, but confidence intervals increase considerably across rounds and there are fewer statistically significant effects.
Throughout, while there is general agreement on effect size in the middle of the distribution, researchers vary in whether the reported effect is statistically significant, with `r viol[Round == 'Task 1' & Type == 'Weighted', percent(mean(sig, na.rm = TRUE))]`, `r viol[Round == 'Task 2' & Type == 'Weighted', percent(mean(sig, na.rm = TRUE))]`, and `r viol[Round == 'Task 3' & Type == 'Weighted', percent(mean(sig, na.rm = TRUE))]` reporting results that were statistically significantly different from 0 in Tasks 1, 2, and 3, respectively.
Those effects that are away from the modal effects are substantially more likely to have very large confidence intervals in Tasks 2 and 3, while there are relatively few studies with very large confidence intervals in Task 1.

[^nick-ratios]: Comparing average standard errors to the variation in reported effects, as in @huntington2021influence and @Menkveld2024, suggests that reported standard errors alone substantially understate total uncertainty.
However, the ratios decline across tasks partly because smaller shared samples in later rounds inflate the standard errors (increasing the denominator).
Hence, more generally, because researcher variation need not scale in parallel with standard errors, using these ratios to capture researcher-induced uncertainty can be misleading. 

```{r Specification Curve for All Reported Estimates Figure}
#| fig-width: 8
#| fig-height: 8
#| label: fig-full-effect-distribution
#| fig-cap: Specification Curve for All Reported Estimates by Task with Estimates Ordered From Smallest to Largest (X axis is number in order within tasks)
p_full_effect_distribution_individual
```

The increasing agreement in effect size is necessarily driven by individual researchers changing their reported effects in subsequent rounds, but researchers were effectively unbound by their previous estimates as @fig-effects-compare-rounds shows. 
There is little visible or linear statistical relationship between a researcher's reported effects in one task and the next.
Only between Tasks 1 and 2 is there a statistically significant correlation, and that correlation is less than 0.2. 

```{r Same-Researcher Effect Sizes Figure}
#| fig-width: 9
#| fig-height: 4
#| label: fig-effects-compare-rounds
#| fig-cap: Same-Researcher Effect Sizes Across Tasks
p_compare_rounds
```

In addition to the preregistered descriptive analysis above, we preregistered a set of tests on effect and sample sizes.
For effect size, we do not reject any of the preregistered Levene tests for the variation at the 95% level, where the null hypothesis is no change in variance from any stage to any later stage (including a comparison of each task to its revision stage, and comparing each main task to later main tasks). 
The lowest p-value of `r number(levene_test_results$pval[1],.001)` comes from the comparison of `r levene_test_results$TaskA[1]` to `r levene_test_results$TaskB[1]`.
We do, however, reject the null hypothesis of equal variance across Task 1 and Task 2 at the 0.05 level for the sample size variance, consistent with the expected reduction when we specify the treated and comparison groups.

Furthermore, we preregistered regressing the squared difference to the round means against the round number.
The squared differences to the mean in each round which provide us with a measure of the variance in effect and samples sizes across researchers.
None of the coefficients on round are statistically significant, although the coefficients for sample sizes are negative as expected (See Appendix Table \ref{hypothesis-2}).
Finally, as shown in Appendix Section @sec-peer-review, there is no statistically significant difference in variance between the reviewed and non-reviewed groups, nor is there a consistent effect in one direction.
Similarly, there are no statistically significant differences in the variance of sample sizes between the peer-reviewed and non-peer-reviewed groups in the follow-up tasks. 

## ## Researchers' Analytic and Sample Choices {#sec-choices}

This sections examines to what extent the different choices that researchers made in analytical and sample choices can explain the variation in effects and sample sizes.


Table \ref{tab-estimation-methods} shows the different choices made in estimating the effect of DACA on the probability of employment across all three tasks, in particular the estimator chosen, the use of ACS sampling weights provided by IPUMS, and the choice of standard error adjustment.[^20] The dependent variable of interest, working full-time or not, is binary. However, as is generally standard in applied microeconomics, linear regression was the most common estimator used, with 82% of entries. 13% used logit or probit regression instead. Notably, many reserachers used linear regression as a means of implementing a fully saturated (or nearly fully saturated) difference-in-differences design, in which case the downsides of linear probability models are muted. Other researchers mostly used a matching estimator (sometimes combined with linear regression) or one of several newly-introduced estimators for difference-in-differences designs, like @callaway2021difference.

[^20]: For most researchers, these choices did not change over the tasks, and so we just present the overall view.

The use of sample weights was relatively uncommon, despite their use being advised with survey data like ACS. Only 25% of task completions mentioned the use of weights or any of the standard ACS weight variables.

There was considerable variation across researchers in the selection of standard error adjustment. A slim majority of researchers applied clustered standard errors in some way, but clustered at different levels: state, state/year, or according to a survey clustering indicator like Strata or some other variable. A further 17% of submissions used heteroskedasticity-robust but not cluster-robust standard errors.

```{r Estimation Methods}
base %>%
  mutate(se_adjustment = factor(se_adjustment, levels = c(
    'Cluster (State)',
    'Cluster (State & Year)',
    'Cluster (ID/Strata/Other)',
    'Het-Robust',
    'Other/Bootstrap',
    'None'
  ))) %>%
  filter(!(round %like% 'Revision')) %>%
  sumtable(vars = c('method','Weights','se_adjustment'), 
         labels = c("Method",'Weights','S.E. Adjustment'),
         col.breaks = 2,
         note = '\\begin{tabular}[x]{@{}r@{}}This table shows details on estimation, not research design. "Difference-in-differences" \\\\ implemented with linear regression, for example, counts here as linear regression.\\end{tabular}',
         out = 'return',
         ) |>
  kbl(
    format = "latex",
    booktabs = T,
    caption = "Estimation Methods\\label{tab-estimation-methods}",
    linesep = ""
  ) |>
  add_footnote(
    "Notes: This table shows details on estimation, not research design. \"Difference-in-differences\" implemented with linear regression, for example, counts here as linear regression.",
    threeparttable = TRUE,
    notation = "none"
    ) |>
  # right justify columns
  column_spec(1:6, latex_column_spec = "lrrlrr")
```

Table \ref{tab-controls-across-rounds} shows the average rate of inclusion of covariates across all three tasks, as well as the estimated effects among analyses including those controls, shown in the order of average effect size. The average rate of inclusion can be read as the share of researchers who included the covariate, with the exception of "Other", which allows each researcher to have multiple "Other" controls. The most common covariates included are shown, with the exception of indicators for "eligible for DACA" or "in a post-DACA period", as these are considered part of the core research design rather than covariates. Variables are included here regardless of the functional form used to include them.

The most common included controls were for state, year, age, and sex, which were included as covariates for more than 50% of researchers in all three tasks. However, there was a large amount of variation in the sets of included covariates. In Task 1, for example, there are ten covariates with rates between .2 and .8, meaning that at least 20% of the researchers made a different decision on inclusion of the covariate than the majority. There are four covariates in the 40-60% range, meaning that the researchers were almost evenly split on whether or not to include the covariate. These rates did not change much by Task 3.

Across all rounds, in which there were `r 3*145` submitted research tasks, there were `r exact_matches[, .N]` different unique sets of included covariates after "Other" covariates are excluded. `r percent(exact_matches[numpairs == 1, sum(numpairs)]/sum(exact_matches$numpairs))` of submissions had a set of covariates that was unique for the task. `r percent(exact_matches[numpairs == 2, sum(numpairs)]/sum(exact_matches$numpairs))` shared a covariate set with one other person in that task, `r percent(exact_matches[numpairs %in% c(3,4), sum(numpairs)]/sum(exact_matches$numpairs))` shared with two or three other people, and only the those with no controls shared with more than three other people.

```{r Controls Across Rounds}
# Average appearances across rounds
controls_across_rounds[, .(Control, `Task 1`, `Task 2`, `Task 3`)] |>
  merge(effects_by_controls[, .(Control, Size = Effect, `SD` = `Effect SD`, Mean = `Mean SE`)], by = 'Control') |>
  setorder(-Size) |>
  kable(
    booktabs = TRUE, 
    caption = 'Covariate Inclusion Across Rounds and Estimated Effects \\label{tab-controls-across-rounds}',
    linesep = "",
    format = "latex"
) |>
  add_header_above(c(" " = 1, "Rate in" = 3, "Effect" = 2, "SE" = 1)) |>
  kable_styling(latex_options = "scale_down") |>
  footnote(
    general = "Nick: can you add a note about mean SE and SD of effects here to explain what they measure and how calculated?",
    threeparttable = TRUE,
    footnote_as_chunk = TRUE,
    general_title = "Notes:"
  ) |>
  column_spec(2:7, latex_column_spec = "r")
```

Did this lack of agreement across researchers on the exact set of appropriate controls, or the inclusion or exclusion of any given control, impact the effect estimates? 
Not by much; the mean reported effects differ by only .023 percentage points when we compare the covariate with the highest average effect estimates (Continuous Years in the USA) against the lowest (Race). 
What is more, this comparison likely overstates the impact of covariate selection.
Selecting the highest versus the lowest after estimates are known will lead to bias towards a larger difference from noise alone.

There do not appear to be major differences in the average reported standard errors either, or in the standard deviation of the effect distribution among reserachers including that covariate.

While the inclusion of a given common control variable does not strongly predict an estimated effect, in Table \ref{tab-effects-by-functional-form} we look at the most common covariates and examine whether their functional form meaningfully affects the estimated effect. The selection of functional form explained more variation in average estimated effects than the inclusion of covariates did, at least in this context. For both age and the State/Year controls, the difference between the highest-average-effect functional form variants and the lowest, in both cases comparing a linear control against a fixed effect, was greater than the difference between highest and lowest among covariates included.

```{r Effects by Functional Form}
trans_con[, .(N = uniqueN(paste0(Q1,Round)),
                `Mean` = number(mean(Effect, na.rm = TRUE), .001),
                `SD` = number(sd(Effect, na.rm = TRUE), .001),
                `Mean` = number(mean(SE, na.rm = TRUE), .001)
              ),
            by = .(Category = category, Control = Relabel)][order(Control)] |>
  kable(
    booktabs = TRUE,
    caption = 'Estimated Effects by Functional Form of Control Variable \\label{tab-effects-by-functional-form}',
    linesep = "",
    format = "latex"
)  |>
  add_header_above(c(" " = 3, "Effect" = 2, "SE" = 1)) |>
  kable_styling(latex_options = "scale_down") |>
  column_spec(3:6, latex_column_spec = "r") |>
  footnote(
    c("Nick: can you add a note about mean SE and SD of effects here to explain what they measure and how calculated?"),
    threeparttable = TRUE,
    footnote_as_chunk = TRUE
  )
```

These specific findings about the impact of choices on effects - that the inclusion of different covariates did not have a major impact on estimated effects, or that the choice of functional form had a greater impact than the selection of covariates - should not be expected to generalize, and is specific to this research task. 
However, what we can take from this section is that there is substantial variation across researchers in what they believe the appropriate set of covariates to be and, for a given covariate, what the appropriate functional form is. 
We can also see that, in the case of this particular study, these decisions, while varied, did not fully explain the variation in effects between researchers.

Table \ref{tab-number-of-sample-limitations} uses researcher survey responses about their sample definitions and looks purely at the number of distinct variables referenced in the sample limitations, regardless of what they are. In Task 1, the typical researcher used five variables to define their analytic sample, and an additional four to define their treated group. In Task 2, where inclusion criteria were shared, both of these numbers increased, but there was still considerable variation, with the 25th and 75th percentiles using 3 and 10 variables to define their full sample. Definition of the treated group was more shared, with the 25th and 75th percentiles using 9 and 12 variables, respectively.

```{r Number of Sample Limitations}
# Basic sample limitations table
sumtable(
  basic_samp_limitations, 
  vars = c('Whole Sample','Treated Group','Untreated Group'), 
  add.median = TRUE, 
  group = 'Round', 
  group.long = TRUE, 
  out = 'return', 
  numformat = formatfunc(digits=2, nsmall = 1)
  ) |>
  kbl(
    format = "latex",
    booktabs = T,
    caption = "Number of Variables Referred to in Sample Limitations\\label{tab-number-of-sample-limitations}",
    linesep = ""
  ) |>
  column_spec(2:8, latex_column_spec = "r")
```

Table \ref{tab-sample-limitations-extensive} shows how these variables were implemented as sample restrictions, based on actual researcher code. This is the only section of the paper where the data do not rely on researcher responses to the survey. For each researcher's Task 1 and Task 2 code, organizers read the code directly and recorded some aspects of the sample definitions used for the overall analytic sample and for the definition of the treated group, including definitions that appeared to be the result of coding errors.

XXX NOTE FOR CLAUS: SHOULD WE DROP MULTISTEP CONDITION ALTOGETHER AND JUST GROUP THEM IN WITH OTHER? I think we should group them in with "Other"


The coding does not cover the full set of possible variables used to define samples, which vary beyond the list presented in the table. 
Some common limitations used by some researchers and not others include filtering out people living in group quarters or those out of the labor force, or dropping anyone with a recorded year of immigration before their recorded year of birth. 
Many researchers also chose to limit the sample based on current age as of the year of their inclusion in the ACS (as opposed to their age in 2012, which is shown), choosing many different acceptable age ranges. 
Table \ref{tab-sample-limitations-extensive} looks only at limitations based on variables for which there is a "right answer" in the Task 2 instructions. 

We see a large amount of variety in the ways these variables were used, including in Task 2, where there is a correct answer according to the instructions (and similarly a correct answer for some variables in the Task 1 treated-group definition).[^22] For each variable, the most-common option, listed at the top, is the "correct" answer for defining the treated group, with two exceptions: (a) for Citizenship, there is a second justifiable answer in "Non-Citizen or Naturalized After 2012." These immigrants would have been eligible for DACA in 2012, but would not be eligible for DACA as of the time they were surveyed, so they would have received a partial "dose" of DACA, which could justifiably be included or excluded, and (b) for Years Continuous in USA, where DACA guidelines require that the immigrant have lived *continuously* in the United States for five years as of 2012. Most researchers used only year of immigration being before 2007 to satisfy this criterion, but others used the YRSUSA set of variables which specifically track living continuously in the country.

[^22]: Keep in mind that the table allows for coding errors. For example the individuals reporting that they used only high school graduates or *non-veterans,* instead of veterans as per the instructions, likely did not intentionally choose to use non-veterans but rather coded "VETSTAT == 1," which indicates "non-veteran", perhaps based on a misunderstanding of the IPUMS documentation (veterans are VETSTAT == 2). However, an earlier version of this paper relied on researcher self-reports of sample limitations in the survey, and found similar rates at which Task 2 choices did not match the "correct answer", so coding errors alone do not account for these results.

For all other variables besides Years Continuous in USA, the option matching the instructions was the most common, but we also see plenty of variation. We also see considerable variation for the columns in which there is not a clear "correct" option, like the analytic sample definition. No single way of applying any variable was used by more than 84% of the sample in any case. One interesting feature is the use of both "\< 16" and "\<= 16" for age at migration, and "\< 2007" and "\<= 2007" for year of migation. For year of migration, the two are similarly popular. Also interesting is the distinction between researchers using age defined in years to determine eligibility vs. age defined in quarters, which makes a difference given that eligibility is based on age specifically in June 2012.

```{r Sample Limitations Extensive}
# Variables used in limitations
table_14 <- sumtable(
  r12samp, 
  titles, 
  group = 'Round/Sample',
  out = 'return'
) 

table_14 <- table_14[-1, ]
rownames(table_14) <- NULL

table_14 |>
  kbl(
    format = "latex",
    booktabs = T,
    caption = "Sample Restriction Methods\\label{tab-sample-limitations-extensive}",
    linesep = linesep(c(6, 6, 7, 5, 5, 9, 7))
  ) |>
  add_header_above(c(" " = 1, "All" = 2, "Treated" = 2, "All" = 2, "Treated" = 2)) |>
  add_header_above(c(" " = 1, "Task 1" = 4, "Task 2" = 4), line = FALSE) |>
  kable_styling(
    latex_options = "scale_down",
    font_size = 8
    ) |>
  column_spec(2:9, latex_column_spec = "r") |>
  footnote(
    c("Multistep condition means the variable is one part of a complex boolean involving many different variables."),
    threeparttable = TRUE,
    footnote_as_chunk = TRUE
  ) 
```

Showing the impact of these choices on estimated effects is difficult since, aside from the most-common option, any specific alternative does not have enough people using it to make a reasonable comparison. However, we show estimated effects and, for analytic-sample restrictions, analytic sample size by sample limitation choice in Appendix Tables \ref{tab-task1effectsample-full} for Task 1 and Table \ref{tab-task2effectsample-full} for Task 2. There are large differences in estimated effects and sample sizes across many of these different sample restriction choices, but in many cases these comparisons are based on very small samples.

The two comparisons for which an alternative was common enough to compare are for the YRSUSA inclusion and the use of "\< 2007" vs. "\<= 2007" for year of migration, which are shown in \ref{tab-task1effectsample}. For both tasks, the relationship between these choices on effects varies from negligible to a several percentage-point difference associated with a single sample restriction change, a fairly minor one in particular for "\< 2007" vs. "\<= 2007". Effect differences are larger in Task 2. However, in Task 1, even though estimated effects are similar, sample sizes are considerably larger for the less-restrictive option, and so reported standard errors would be lower, and statistical significance more likely.

```{r Effect and Sample Table}
# sample limitations and effects/samples, task 1
t1efftab = make_efftab(r12samp[Round == 'Task 1'])[Variable %in% c('HEADERROW', 'Year of Immigration','... < 2007','... <= 2007','Years Continuous in USA','... Used YRSUSA','... No YRSUSA')]
t2efftab = make_efftab(r12samp[Round == 'Task 2'])[Variable %in% c('HEADERROW', 'Year of Immigration','... < 2007','... <= 2007','Years Continuous in USA','... Used YRSUSA','... No YRSUSA')]

t1efftable <- rbindlist(
  list(t1efftab[1],
       t1efftab[2:.N],
       t2efftab[2:.N]
       )
) 

t1efftable <- t1efftable[-1, ]
rownames(t1efftable) <- NULL

setnames(
  t1efftable, 
  c("Variable", "25", "50", "75", "25", "50", "75", "25", "50", "75")
)

t1efftable |>
  kbl(
    format = "latex",
    caption = "Effect and Samples by Sample Definitions\\label{tab-task1effectsample}",
    booktabs = TRUE
  ) |>
  pack_rows(
    index = c("Task 1" = 6, "Task 2" = 6),
    bold = FALSE
  ) |>
  add_header_above(
    c(" " = 1, "Effect Percentile" = 3, "Effect Percentile" = 3, "Sample Size Percentile" = 3),
    line = FALSE
  ) |>
  add_header_above(
    c(" " = 1, "Restrictions" = 3, "Restrictions" = 6)
  ) |>
  add_header_above(
    c(" " = 1, "Treated-Group" = 3, "All-Sample" = 6),
    line = FALSE
  ) |>
  kable_styling(
    latex_options = "scale_down"
  ) |>
  column_spec(2:10, latex_column_spec = "r")

```

## Researcher Characteristics and Effects {#sec-researcher-chars}

In this section we evaluate the relationship between researcher characteristics and the effects they reported. 
As listed in our preregistration, the analyses in this section were performed in a muliple-analysts style, with the two project organizers taking the same data and research question and performing independent analyses.[^23]
Full results from each project organizer can be found in Appendix B.

[^23]: From the preregistration: "Both primary authors will, independently, analyze the relationship between (a) researcher characteristics and reported research results in earlier stages, and (b) attrition from the study and reported research results in later stages." Because there was so little attrition from the study after Task 1, part b was dropped from the analysis. 

The two project organizers took very different approaches to the question of how researcher characteristics affected results, selecting different dependent variables and methods of analysis, and different sets of researcher characteristics.
Both organizers found, however, that researcher characteristics were not strong predictors of estimated effects. 
Across researcher demographics, occupation, and professional experience, there was no strong relationship between researcher background and either the level of the effect estimate they reported, the deviation of their estimate from the mean, or changes in their estimate from task to task. 
The only relevant difference we found is that the minority of researchers who used the R programming language were more likely to report outlier estimates than researchers who used Stata.

## Bimodality in the Task 2 Effect Estimates {#sec-bimodal}

One of the surprising results in @sec-variation was the effect distribution in Task 2. In designing the study, we had expected that each task would show a narrower distribution of effects than the previous task. While we see this pattern for sample sizes and some researcher choices, the distribution of effects became wider going from Task 1 to Task 2. We also saw emerging bimodality, where the larger part of the sample reported estimates that reflected the distribution of effects already seen in Task 1, while a smaller group of researchers reported larger effects that were more like those found in Task 3. In this section we look for an explanation of the unexpected findings in Task 2.[^18]

[^18]: This section is entirely un-preregistered, as we did not anticipate this finding.

Several anticipated correlates did not explain the bimodal outcomes of Task 2. @fig-effect-vs-sample and @fig-effect-vs-se in the Appendix show that the Task 2 reported sample sizes and standard errors do not strongly explain the effects reported. @fig-effects-compare-rounds in @sec-variation shows that bimodality is not a feature of some researchers trying to make their Task 2 results consistent with their Task 1.

Instead, we find that a major contributing factor to Task 2 bimodality is the ability to precisely implement the treated-group definition given in the instructions. Task 2 gave a very precise definition of who should be included as a part of the treated group. We examine whether a given researcher followed the full set of treated-group definition instructions exactly or not. The mismatch could be small, such as using "\<= 16" instead of "\< 16" for age at migration, or large, such as omitting that eligible people must be non-citizens. In @fig-match-vs-mismatch we show their distribution of effects against researchers who had a mismatch in their criteria in any way. The graph shows that the bimodality heavily driven by the group that precisely matched the treated-group definition. This implies that the bimodality in Task 2 may be explained in large part by a split between researchers who exactly followed the instructions, and so effectively matched what a typical researcher found in Task 3, and those who did not.

```{r Match vs Mismatch Figure}
#| fig-width: 8
#| fig-height: 4
#| label: fig-match-vs-mismatch
#| fig-cap: Task 2 Effect Distributions Among Those with Exact Treated-Group Definition Matchs vs. Those with Some Mismatch
p_match_vs_mismatch_distribution
```

This does not fully explain researcher behavior: note that there is also a weight of researchers with higher results who did not match perfectly, and also that much of the density of the perfect-match group is at Task 1 effect levels, but keep in mind that there are many other decisions in analysis to be made, and this captures only one angle where determining the correct decision is easiest.

Further, Table \ref{tab-match-by-field} shows that the share of researchers matching exactly is fairly low, between 20-25% by field, keeping in mind that even very minor mismatches are counted as mismatches. Further, perfect-match rates were slightly higher among researchers whose work was closest to the field that the research task was in, immigration and labor, although this difference was not statistically significant at the 95% level.

```{r Match by Field Table}
rfield |>
  kable(
    booktabs = TRUE,
    caption = 'Share of Researchers Matching Treated-Group Definition Exactly by Field\\label{tab-match-by-field}',
    format = "latex"
    ) |>
  kable_styling(
    latex_options = "scale_down"
    ) |>
  column_spec(1:5, latex_column_spec = "lrrrr")

# our t-test
# d = data.table(field = c(rep(TRUE,1+3+12+35),rep(FALSE,c(18+76))), out = c(rep(TRUE,13),rep(FALSE,3+35),rep(TRUE,18),rep(FALSE,76)))
# t.test(d[field == FALSE, out], d[field == TRUE, out])
```



# Conclusion {#sec-conclusion}

## Recommendations for Improved Practice

What do these results imply should change about the practice of applied microeconomic research?

To some degree, the findings of this paper do not reflect a problem to be solved. The fact that different researchers approach a problem differently is not in itself a problem, as long as any points of disagreement are visible to the reader and subject to scrutiny and disagreement, and the reader understands that a given study or set of research decisions is not the last word.

However, there is a problem to be solved to the extent that researcher variation reflects either (a) error, or (b) choices that are unexamined or invisible while also being something that researchers would choose differently.

In this study, we found considerable variation across researchers in the approaches taken to answering the main question in Task 1, which most closely reflects actual practice. While the distribution of effects did not considerably narrow from Task 1 to Task 2, the sample sizes did, as did the treated and comparison group definitions. Although we generally did not reject Levene tests of equal variance across rounds, descriptively there was an obvious narrowing of the distribution of effects. There was, in both rounds, a lot of variation in the set of covariates included, as well.

To the extent that these choices reflect research design and modeling choices, the problem is somewhat already addressed. Researchers are used to critiquing research design and modeling choices in public work. Because of this, we would expect that all of these choices would be reported in a writeup of research, where they could be critiqued. What would not typically occur is someone actually testing whether many of these alternate choices actually lead to different results, especially for seemingly more innocuous choices like covariate functional form, which was found in this study to be more consequential than the set of covariates included.

On the part of researcher practice, this set of results suggests the use of multiverse analysis [@steegen2016increasing], where the researcher considers every combination of reasonable modeling decisions and demonstrates their effects on estimated effects, or even many-analysts approaches to producing original work, as we did in @sec-researcher-chars. On the part of journals, this suggests that journals should consider accepting work that is a variation in the approach to a published work, even if that variation is not framed as a replication or rejection of the original study, currently a barrier to the publication of replications [@galiani2017incentives].

However, this study did not find that research design and modeling choices were the majority of explained researcher variation. Instead, this came in the form of data cleaning and preprocessing, including the selection of sample and the creation of variables indicating the treated group. Some of this variation could be classified as error, for example researchers in @sec-bimodal whose treated-group definition in Task 2 did not match the instructions. Other parts of this variation could be reasonable disagreement.

That much of the relevant variation seems to come along the lines of data cleaning and preprocessing is possibly unsurprising, given how this task is currently handled in economics. 
Relative to modeling and research design, data cleaning and preprocessing receive little attention. 
It is common for minor, or even important, details of data processing to be left off the description of methods in published papers. 
Data cleaning is also not formally taught in most graduate programs. 
A professor who would never allow a research assistant to decide their research design or model might be happy passing along the data cleaning task to an assistant, even though, as this paper shows, the task may be just as relevant to the results and just as prone to arbitrary choice-making.

Because data cleaning gets so little attention, it is perhaps to be expected that we saw the most variation here. 
Without formal training in PhD programs, or a culture of reviewing and critiquing data cleaning and preprocessing in research papers, there is little opportunity for researchers to *learn to do the "correct" thing*, and so we see heavy variation. 
Contrast this to the popular use of linear probability models in Table \ref{tab-estimation-methods}, for example, which is common in applied microeconomics, especially in difference-in-differences designs. 
Because its use is very visible, researchers can see that it is the standard in the field. 
Whether or not it is actually the best method to use here, researchers know that this method has gained wide acceptance in the field. 
We see a similar story play out with standard error adjustments in the same table. 
The standard method by which economists learn data processing is on a much narrower scale, often from one's advisor or from others on a small research team.

Among broader system-wide changes, the introduction of data cleaning and preprocessing classes teaching methods and best practices in the standard PhD applied economics curriculum would likely improve the quality of economics research as well as reduce researcher variability. 
This presumes the existence of a set of best practices; otherwise, we might end up with less variability around the wrong answers. 
So, an attempt should be made to codify and popularize a set of data-cleaning best practices, similar to how applied economists routinely learn about modeling best practices (for example any number of econometrics textbooks, or in the applied literature papers like @abadie2023should). 
Other fields have already made strides in this direction [e.g. @osborne2012best; @jafari2022hands] so this effort would not need to start from scratch, but would be improved by designing recommendations most relevant to an applied microeconomics context.
That at least one recent textbook include a discussion of best-practices in data cleaning is one step in that direction [@Bekes2021].

Those recommendations may not be in the control of any one researcher, though. 
The policy that this paper implies for individual researchers and journal editors or reviewers is that economics as a field should consider data cleaning and preprocessing to be just as much a part of the methods as the choice of model. Researchers should fully describe their data cleaning processes in their papers to the same level of detail that they describe their modeling choices. 
They should also perhaps subject any arbitrary data-cleaning decisions to multiverse analysis as well (note that this is also a suggestion of @steegen2016increasing). 
Further, an increasingly common requirement of journal submissions is to provide a replication package of the code used to perform a paper's analyses (for example @aeaguidelines). 
However, these replication packages often begin from an already-prepared data set, and only include the code necessary to run models. 
It would be advisable to include data preprocessing code in these replication packages.

## Discussion

This paper describes the results of a large many-analysts project in applied microeconomics. We found large amounts of variation in the choices made by researchers, especially in regards to data cleaning and processing, research design, the definition of treated and comparison groups, and the selection and functional form of controls. Some of this variation appears to be from researcher data cleaning processes that do not match the instructions, derived from policy realities, for constructing the treated group. Variation was not strongly constrained by the influence of peer review or a shared research design, but there was a (descriptive if not statistically significant) reduction of variation when researchers were provided with pre-cleaned data.

Interestingly, we do not find substantial amounts of variation in actual estimated effects of the policy. 
There were some outliers, and statistical significance varied between researchers. 
However, the central range of estimated effects of DACA on the probability of working full time effects generally was not very wide, with the difference between the 25th and 75th percentiles typically only 2-3 percentage points. 
However, the fact that widely different sample definitions and modeling choices led to a narrow range of effects is not guaranteed to generalize to other contexts.
[Discuss Goldhaber's comment: That there's relatively more variation around sample, design, etc. compared to findings is surprising and could probably use more discussion. Do you think it's just related to the DACA problem, maybe because the answers aren't super sensitive to issues like sample? I don't know that there's more to dig into in terms of the analysis, but I'd surface the issue of the sensitivity of these results to the project/problem we were asked to address.]

[Goldhaber comment: That there's relatively more variation around sample, design, etc. compared to findings is surprising and could probably use more discussion. Do you think it's just related to the DACA problem, maybe because the answers aren't super sensitive to issues like sample? I don't know that there's more to dig into in terms of the analysis, but I'd surface the issue of the sensitivity of these results to the project/problem we were asked to address.]

There were also parts where researchers behaved very similarly. The use of linear regression modeling was very popular, and very few researchers used unadjusted standard errors, although the specific adjustment or clustering level varied.

What we might learn from this study, and perhaps the wider world of studies on researcher variation, is perhaps obvious: in cases where there were well-acknowledged "standard" ways of doing something, like using linear modeling in a difference-in-differences-type setting with a binary outcome, or adjusting one's standard errors, researchers tended to do that thing. And where there was no well-acknowledged standard, like in the choice of clustering level, the selection of covariates in this particular setting, or in data cleaning, researchers behaved differently, sometimes to consequence and sometimes without it mattering much.

While researcher error also plays a part, the impact of the absence of standards is an emergent result from this study. Readers and practitioners of research should expect arbitrary variation in parts of research, like data cleaning, that do not have standards.

The development of best-practice standards in areas where we currently do not acknowledge them would be likely to improve applied microeconomics towards being a more mature, sophisticated, and believable field than it is today. We have highlighted data-cleaning practices as being an especially fruitful place to develop these standards, but the same applies in other areas as well like the level of clustering (an example of a place where development of consensus guidance is already underway in @abadie2023should). The optimal level of researcher variation is not zero, as individual researchers often have good reasons not to match the methods and practices used by others. But when this occurs, it should be because there *is* a good reason to deviate from the template, rather than because we have no template to begin with.

# References {.unnumbered}

::: {#refs}
:::

\FloatBarrier

\newpage
\appendix
\renewcommand{\thesection}{\Alph{section}}
\setcounter{section}{0}
\counterwithin{figure}{section}
\counterwithin{table}{section}

\renewcommand{\section}[1]{\refstepcounter{section}%
\begin{Large}\bfseries Appendix \thesection: #1\end{Large}}

\renewcommand{\subsection}[1]{\refstepcounter{subsection}%
\begin{large}\bfseries \thesubsection: #1\end{large}}

# Research Task Description {#sec-research-task}

This section outlines the detail of the research tasks and the differences between Tasks 1, 2, and 3.
Full instructions are available in the online appendix/pre-registration at \url{https://osf.io/9p7j6/}.

In all research tasks, the specific goal given to researchers was:

> Among ethnically Hispanic-Mexican Mexican-born people living in the United States, what was the causal impact of eligibility for the Deferred Action for Childhood Arrivals (DACA) program (treatment) on the probability that the eligible person is employed full-time (outcome), defined as usually working 35 hours per week or more?
>
> DACA was implemented in 2012. Examine the effects on full-time employment in the years 2013-2016.

In simple terms, this asks researchers to estimate the impact of the DACA program on the probability that those eligible for the program usually work 35 hours per week or more in the years 2013-2016.

Researchers, many of whom are not from the United States and so may not be familiar with DACA, are given further background information about the DACA program:

-   DACA allowed undocumented immigrants who were accepted into the program to have legal work authorization for two years without fear of deportation, and also allowed them to apply for drivers' licenses or other forms of identification. 
People could reapply after the two years expired, and many did.

-   Applications for the program opened on August 15, 2012, and over the first four years of the program's existence, over 900,000 applications were received, about 90% of which were approved.[@citservices2016]

-   While the program was not specific to immigrants from any origin country, because of the structure of undocumented immigration to the United States, the great majority of eligible people were from Mexico.

Researchers were also given information on the eligibility criteria for DACA, which was intended to apply only to a specific subset of undocumented immigants who arrived in the United States as children, and not to all undocumented immigrants. 
Eligible people must:

-   Have arrived in the United States before their 16th birthday.

-   Not have had their 31st birthday as of June 15, 2012.

-   Have lived continuously in the United States since June 15, 2007.

-   Were present in the United States on June 15, 2012 and did not yet have legal status (either citizenship or legal residency) during that time.

An additional eligibility requirement was mistakenly omitted from the Task 1 instructions, but was included for Tasks 2 and 3:

-   Eligible people must have completed at least high school (12th grade) or be a veteran of the military.

In addition to this information about the policy itself and the effect that researchers are supposed to identify, researchers were also given instructions about the data set to use and how to procure it, as well as some details on usage of the data:

-   Data should come from the American Community Survey (ACS), using data no older than 2006, and no newer than 2016.

-   In addition, a file of state/year-level data was provided including labor market data and the presence or absence of different immigration policies in different years. Immigration policy data comes from @urbaninstdata.[^8]

    ACS data should be procured from the IPUMS website [@ruggles2024ipums], specifically selecting one-year ACS files and harmonized variables. Written and video instructions were included showing how to select data samples and variables on the IPUMS website.

-   Researchers were not told which specific variables to use to determine eligibility status, but they were given guidance onto how to find relevant variables (like looking at the Person $\rightarrow$ Race, Ethnicity, and Nativity page to find variables relevant to ethnicity, birthplace, citizenship, and year of immigration).

-   Several relevant features of the ACS that may affect analysis were emphasized: (a) ACS is a repeated cross-section, not a year-to-year panel data set, and (b) ACS does not list the month that data was collected in, so it is not possible to distinguish whether a given observation in 2012 is from before or after the policy was implemented, and (c) we do not actually observe in ACS whether a given person is enrolled in DACA, so we assume that all eligible people who are ethnically Mexican and Mexican-born are treated.

[^8]: This file included the state/year-level unemployment rate and labor force participation rate. 
Immigration policy flags were for policies for undocumented immigrants to get state drivers' licenses, to get college financial aid, to be banned from state public colleges, or to follow Omnibus immigation legislation that serves to increase the surveillance of immigation documentation. 
Additional indicators were for participation in E-Verify laws that require employers to verify immigration authorization, to limit E-Verify participation, participation in Secure Communities, and for participation in task-force or jail based 287(g) policies.

Finally, researchers were instructed to keep track of any variables used to limit their sample download on IPUMS, and to review the survey where they would be reporting their results before beginning their analysis.

From there, researchers were given free reign to complete the analysis as they thought most appropriate, including their own choice of statistical software, an instruction to use assistants for any work that they might normally use assistants for, and asking them to complete the analysis as they thought best, as though the research task had been their own idea, not trying to match or not-match other researchers or guess what analyses the project organizers wanted to see. 
Once finished, they uploaded all of their code and data to a Sharepoint website, wrote a short description and interpretation of their results focusing on a single "headline" result, and filled out the research survey to report their results.

For Task 2, all of the previous instructions remained in place, but several were added to further specify the research design:

-   There is a "treated" group that is comprised of all ethnically Mexican and Mexican-born non-citizen individuals who are aged 26-30 on June 15, 2012 (recall that individuals must not have had their 31st birthday as of June 15, 2012 to be eligible for DACA).

-   There is an "untreated" group that is comprised of people who would have been eligible for DACA, except that they were aged 31-35 on June 15, 2012.

-   Researchers should estimate the effect of treatment by seeing how the 26-30 group changed from before treatment to after relative to how the 31-35 group changed (keeping in mind this is a repeated cross-section and not panel data).

-   Researchers should attempt to estimate the effect for all individuals in the "treated" group and not, for example, estimate the effect only for men or only for women.

-   The instructions specifically mention that researchers can, if they like, use covariates or account for differing trends to improve the comparability of the treated and untreated groups.

The task is otherwise unchanged for Task 2.

In Task 3, the instructions remain unchanged from Task 2, except that the data is provided directly instead of having researchers download data from IPUMS, omitting data from the year of 2012. In Task 3, project organizers cleaned the data, merged in the state policy data, created a variable indiciating whether a given individual was in the "treated" or "untreated" group, limited the sample only to individuals in "treated" or "untreated," and created simplified versions of variables like education. Researchers were instructed not to further limit the sample from this prepared data set, or to perform further extensive data cleaning.[^9]

[^9]: There were three observations in the final cleaned data set that were missing values of the education variable. 
The final used sample in Task 3 sometimes differs by 3 across researchers, based on whether the analysis uses education and thus drops these individuals.



# Hypotheses and Analysis Preregistration {#sec-preregistration}

This Appendix Section shows only the the preregistrated hypotheses and the associated analysis plan.
Both are edited for clarity.
For the full preregistration, see \url{https://doi.org/10.17605/OSF.IO/CJ9YX}.

## Hypotheses

In each case, $SD_i$ refers to the standard deviation of effect sizes across replicators reported in the $i$th round of the study:

- Round 1: Initial replication task
- Round 2: Results after peer review and revision
- Round 3: Second replication task
- Round 4: Results after second peer review and revision
- Round 5: Third replication task
- Round 6: Results after third peer review and revision

Hypotheses:

1. $SD_1$ will be greater than the mean reported standard error of effect sizes, among studies for which a standard error and single effect size can be derived.
2. $SD_i$ will have a negative linear or quadratic relationship with $i$.
3. For $i$ from 1 to 5, $SD_{i+1} < SD_i$.
4. Respondents assigned to the peer review condition in round $i$ will have a smaller $SD_i$ than respondents not assigned to peer review, where the round $i$ results for anyone who does not submit a revision in round $i$ is their round $i-1$ result.
5. Respondents assigned to the peer review condition in round $i$ will have a smaller $SD_{i+1}$ than respondents not assigned to peer review.    
6. a. For a given peer review pair assigned to review each other in round $i$, the difference between their results in round $i$ will be smaller than the difference between their results in round $i-1$.  
   b. For a given peer review pair assigned to review each other in round $i$, the difference between their results in round $i$ will be smaller than if they had not been assigned to each other.
7. The hypotheses 2 through 6 will also apply to the analytic sample size, using only rounds 1--4.
8. The hypotheses 2 through 6 will also apply to the number of observations determined to be eligible for DACA and in the analysis, using only rounds 1--4.
9. The hypotheses 2 through 6 will also apply to the number of observations determined to be ineligible for DACA and in the analysis, using only rounds 1--4.

## Analysis Plan


1. $SD_1$ will be greater than the mean reported standard error of effect sizes, among studies for which a standard error and single effect size can be derived.

    We will calculate the standard deviation of the reported effect sizes in the first stage, and the mean of the reported standard errors in the first stage, and compare them.

2. $SD_i$ will have a negative linear or quadratic relationship with $i$.

    We will take the reported effect sizes from the set of researchers who completed all stages of analysis, and subtract the mean. 
    Then, we will use ordinary least squares to regress the square of this variable on a linear term representing the round of analysis, or a quadratic for round, depending on the apparent best-fit relationship in the data. 
    If using a quadratic, the hypothesis is supported only if the effect is negative for all values of $i$ in the data.

3. 3a-3e. For $i$ from 1 to 5, $SD_{i+1} < SD_i$

    We will use Levene's test, with a median center, to compare the variance of the effect sizes in each round to the variance of effect sizes in the following round.

4. Respondents assigned to the peer review condition in round $i$ will have a smaller $SD_i$ than respondents not assigned to peer review, where the round $i$ results for anyone who does not submit a revision in round $i$ is their round $i-1$ result.

    We will use Levene's test, with a median center, to compare the variance of the effect sizes in round $i$ among those who were assigned to peer review in round $i$ against those who were not assigned to peer review in round $i$. This will be repeated for rounds 2, 4, and 6, and also for these three rounds pooled together.

5. Respondents assigned to the peer review condition in round $i$ will have a smaller $SD_{i+1}$ than respondents not assigned to peer review

    We will use Levene's test, with a median center, to compare the variance of the effect sizes in round $i+1$ among those who were assigned to peer review in round $i$ against those who were not assigned to peer review in round $i$. 
    This will be repeated for rounds 2, 4, and 6, and also for these three rounds pooled together.

6. a. For a given peer review pair assigned to review each other in round $i$, the difference between their results in round $i$ will be smaller than the difference between their results in round $i-1$.

      We will calculate the absolute difference in effect sizes between each member of a peer review pair in their round $i$ and round $i-1$ results. 
      Then, we will compare the means of these absolute differences across rounds using a paired t-test. 
      This analysis will be repeated in rounds 2, 4, and 6, and also for these three rounds pooled together.

   b. For a given peer review pair assigned to review each other in stage $i$, the difference between their results in stage $i$ will be smaller than if they had not been assigned to each other.

      We will calculate the absolute difference in effect sizes between each member of a peer review pair in their round $i$ results. 
    Then, we will construct a null distribution of effect size differences by randomly assigning an equal number of fake peer review partnerships and calculating their average within-partnership differences in their round $i$ results (where anyone who did not submit a revision in round $i$ uses their round $i-1$ results).
    We will repeat this fake-partnership process 3,000 times and calculate the distribution of the mean absolute difference across these 3,000 iterations. 
    We will then calculate the actual absolute difference's percentile $pct$ of the null distribution. 
    The p-value will be $2*pct$ if $pct < 0.5$, and $2*(1-pct)$ if $pct >= 0.5$. 
    This analysis will be repeated in rounds 2, 4, and 6, and also for all three rounds pooled together.

7. The hypotheses 2 through 6 will also apply to the analytic sample size, using only rounds 1-4.
8. The hypotheses 2 through 6 will also apply to the number of observations determined to be eligible for DACA and in the anlaysis, using only rounds 1-4.
9. The hypotheses 2 through 6 will also apply to the number of observations determined to be ineligible for DACA and in the analysis, using only rounds 1-4.

    The analysis will be the exact same as for analyses 2-6, except using overall analytic sample size, the number of observations included and eligible for DACA, and the number of observations included and ineligible for DACA instead of effect sizes, respectively, and limiting analysis only to rounds 1-4.


# Additional Figures and Tables

```{r RDD on completion figure}
#| label: fig-rdd
#| fig-cap: Impact of Guaranteed Payment on Probability of Task 1 Completion

rdplot(moneyatt$Finished,moneyatt$order,200,
       x.label = 'Order',y.label = 'Prob. Completed First Task',
       title = '', p = 2, binselect = 'espr')
```

```{r RDD on completion table}
lin_rdd = feols(
  Finished ~ I(order-200)*I(order>200), 
  data = moneyatt[Stage != 'Late']
  )
sq_rdd = feols(
  Finished ~ (I(order-200)+I((order-200)^2))*I(order>200), 
  data = moneyatt[Stage != 'Late']
  )

modelsummary(
  list('Linear' = lin_rdd, 'Quadratic' = sq_rdd),
  estimate = "{estimate}{stars}",
  stars = c('*' = .1, '**' = .05, '***' = .01),
  align = 'ldd',
  gof_omit = c('IC|R2|RMSE|Err|AIC|BIC'),
  coef_map = c('(Intercept)' = 'Intercept',
               'I(order > 200)' = 'Order above 200',
               'I(order - 200)' = 'Linear order - 200',
               'I((order-200)^2))' = 'Squared (order - 200)',
               'I(order - 200):I(order > 200)' = 'Linear x Above',
               'I((order - 200)^2):I(order > 200)' = 'Squared x Above'),
  title = 'Linear and Quadratic Regression Discontinuity Estimates\\label{tab-rdd-reg}', 
  escape = FALSE,
  output = "kableExtra"
) |>
  footnote(
    general = 
      c("\\\\footnotesize{* $p < 0.1$, ** $p < 0.05$, *** $p < 0.01$}"),
    general_title = "\\\\footnotesize{Note:}",
    escape = FALSE,
    threeparttable = TRUE,
    footnote_as_chunk = TRUE
  ) 
```

```{r Hypothesis 2 Table}
results_hypo_2 |> 
  kable(
    booktabs = TRUE,
    caption = 'Squared Difference to Round Mean\\linebreak against Round number\\label{hypothesis-2}',
    format = 'latex'
    ) |>
  column_spec(1:4, latex_column_spec = "lrrr")
```


```{r Task 2 Effect Size and Sample Size}
#| label: fig-effect-vs-sample
#| fig-cap: Task 2 Effect Size and Sample Size
p_sample_size_scatter
```

```{r Task 2 Effect Size and Standard Error}
#| label: fig-effect-vs-se
#| fig-cap: Task 2 Effect Size and Standard Error
p_standard_error_scatter
```

```{r}
#| label: tab-share-above-p5-by-control
# shtask |>
#   knitr::kable(booktabs = TRUE,
#                caption = 'Share of Effects Above .05 by Covariate Included')

```

```{r Task 1 Effect and Sample Size by Sample Definitions}
# sample limitations and effects/samples, task 1
efftab_full <- make_efftab(r12samp[Round == 'Task 1'])


efftab_full <- efftab_full[-1, ]
rownames(efftab_full) <- NULL

setnames(
  efftab_full, 
  c("Variable", "25", "50", "75", "25", "50", "75", "25", "50", "75")
)


efftab_full |>
  kbl(
    format = "latex",
    caption = "Task 1 Effect and Samples by Sample Definitions, Full View\\label{tab-task1effectsample-full}",
    booktabs = TRUE,
    linesep = ""
  ) |>
  add_header_above(
    c(" " = 1, "Effect Percentile" = 3, "Effect Percentile" = 3, "Sample Size Percentile" = 3),
    line = FALSE
  ) |>
  add_header_above(
    c(" " = 1, "Restrictions" = 3, "Restrictions" = 6)
  ) |>
  add_header_above(
    c(" " = 1, "Treated-Group" = 3, "All-Sample" = 6),
    line = FALSE
  ) |>
  kable_styling(
    latex_options = "scale_down"
  ) |>
  column_spec(2:10, latex_column_spec = "r")



```

```{r Task 2 Effect and Sample Size by Sample Definitions}
# sample limitationsand effects/samples, task 2
efftable_2 <- make_efftab(r12samp[Round == 'Task 2'])

efftable_2 <- efftable_2[-1, ]
rownames(efftable_2) <- NULL

setnames(
  efftable_2, 
  c("Variable", "25", "50", "75", "25", "50", "75", "25", "50", "75")
)

efftable_2 |>
  kbl(
    format = "latex",
    caption = "Task 2 Effect and Samples by Sample Definitions, Full View\\label{tab-task2effectsample-full}",
    booktabs = TRUE,
    linesep = ""
  ) |>
  add_header_above(
    c(" " = 1, "Effect Percentile" = 3, "Effect Percentile" = 3, "Sample Size Percentile" = 3),
    line = FALSE
  ) |>
  add_header_above(
    c(" " = 1, "Restrictions" = 3, "Restrictions" = 6)
  ) |>
  add_header_above(
    c(" " = 1, "Treated-Group" = 3, "All-Sample" = 6),
    line = FALSE
  ) |>
  kable_styling(
    latex_options = "scale_down"
  ) |>
  column_spec(2:10, latex_column_spec = "r")

```





\clearpage

# Peer Review {#sec-peer-review}

This section evaluates the impact of peer review on the later work performed by a researcher. 
The structure of peer review in this study is that, following each main task, 2/3 of the researchers are randomized into pairs that produce a peer review report of the other's work, while the remaining 1/3 do not receive or perform peer review. 
Then, researchers have an opportunity to revise their work.

Revision is optional, and relatively few researchers (fewer than 30 per task) chose to revise their work after receiving peer review. 
As such, we mostly look at the impact of peer review on the work performed in subsequent main tasks. 
The mechanisms by which peer review might be expected to change a researcher's work in normal journal submissions include both that researchers might find peer review comments helpful and incorporate them into their work, and that researchers are required by the journal submission process to incorporate most reviewer comments. 
In this study, our peer review process can only capture the first of these mechanisms, and in effect may be closer to comments received, for example, during seminar presentations.

In Appendix Table \ref{tab-variance-after-revision}, we incorporate revisions and show the variance of the entire sample of reported effects post-revision, replacing each researcher's reported task effect with its revision, if they revised their work. 
There is no statistically significant difference in variance between the reviewed and non-reviewed groups, nor is there a consistent effect in one direction.
Similarly, as shown in Appendix Table \ref{tab-variance-after-revision-sample} there are no statistically significant differences in the variance of sample sizes between the peer-reviewed and non-peer-reviewed groups in the follow-up tasks. 


```{r Variance in Effect after Revision table}
#| label: Levene test - effect size
# variance_tests.R - effect size tests
peer_review_levene |>
  knitr::kable(
    booktabs = TRUE, 
    caption = 'Post-Revision Variance in Effect Sizes by Peer Review \\label{tab-variance-after-revision}',
    format = "latex"
    ) |>
  kable_styling(
    latex_options = "scale_down"
    ) |>
  column_spec(1:5, latex_column_spec = "lrrrr")
```


```{r Variance in Sample Sizes after Revision table}
#| label: Levene test - sample size
# variance_test.R - sample size tests
peer_review_levene_sample <- peer_review_levene_sample %>%
  mutate(
    across(where(is.numeric) & !matches("Levene Test p-value"), ~ formatC(., format = "e", digits = 3)),  # Format non-p-value numeric columns in scientific notation
    `Levene Test p-value` = round(`Levene Test p-value`, 3)  # Format p-value column with standard notation
  )

peer_review_levene_sample |>
  select(-2) |>
  kable(
    booktabs = TRUE, 
    caption = 'Post-Revision Variance in Sample Sizes by Peer Review \\label{tab-variance-after-revision-sample}',
    digits = 3,
    format = "latex"
    ) |>
  pack_rows(
    index = c("Overall Sample Size" = 3, "DACA Eligible Sample Size" = 3, "DACA Non-Eligible Sample Size" = 3),
    bold = FALSE
  ) |>
  kable_styling(
    latex_options = "scale_down"
    ) |>
  column_spec(1:5, latex_column_spec = "lrrrr")
```


Appendix @fig-peer-review-effect-distributions shows the distribution of effect sizes estimated by those who did, and did not, engage in peer review in each round. 
The left column of graphs shows the effects reported in each task before researchers were assigned to peer review, and the right column shows the effects reported in the follow-up task. 
As is expected given randomization, effect distributions are fairly similar pre-review between the review and non-review groups. 
No differences emerge between these groups in the follow-up task. 
Levene test p-values comparing effect size variance of peer-reviewed and non-peer-reviewed groups in follow-up tasks show p-values of `r number(levene_peer_vs_next_round$levene_p[1], .001)` and `r number(levene_peer_vs_next_round$levene_p[2], .001)` in Tasks 2 and 3, respectively, or `r number(levene_result_pooled[['Pr(>F)']][1], .001)` when pooling the two tasks. 
This is not strong evidence in favor of the idea that peer review might drive agreement between researchers due to the receipt of feedback.
Similar results are found when comparing the variance of analytic, treatment, or control sample sizes between the peer-reviewed and non-peer-reviewed groups in the follow-up tasks.


```{r Distribution of Reported Effect Sizes Figure}
#| fig-width: 8
#| fig-height: 5
#| label: fig-peer-review-effect-distributions
#| fig-cap: Distributions of Reported Effect Sizes
p_peer_review_effect_distributions
```


```{r Distribution of Reported Sample Sizes Figure}
#| fig-width: 8
#| fig-height: 4
#| label: fig-peer-review-distributions-sample
#| fig-cap: Distributions of Reported Sample Sizes
p_peer_review_distributions[["Revision_of_Q12"]]
```


```{r Distribution of Reported DACA Eligible Sample Sizes Figure}
#| fig-width: 8
#| fig-height: 4
#| label: fig-peer-review-distributions-daca
#| fig-cap: Distributions of Reported DACA Eligible Sample Sizes
p_peer_review_distributions[["Revision_of_Q18"]]
```


```{r Distribution of Reported DACA Non-Eligible Sample Sizes Figure}
#| fig-width: 8
#| fig-height: 4
#| label: fig-peer-review-distributions-non-daca
#| fig-cap: Distributions of Reported DACA Non-Eligible Sample Sizes
p_peer_review_distributions[["Revision_of_Q21"]]
```

@fig-like-your-reviewer explores the possibility that peer review might not make the peer-reviewed group as a whole more similar, but rather just make someone more similar to their specific reviewer. 
We calculate the absolute difference in effects between each reviewer pair, in the task they perform before reviewing (left column), in the follow-up task (middle column) and comparing your follow-up task against your reviewer's result this round (right column), with the right column representing the possibility that a researcher may select an analysis so as to produce a result more similar to the one they saw in the previous round.[^19]

[^19]: The distributions of absolute differences for non-reviewed researchers are generated as a null distribution by matching every non-reviewed researcher to every other non-reviewed researcher and calculating all absolute differences. 
This null distribution represents the distribution of absolute differences among people who did not actually experience peer review. 
Notably, each non-reviewer is matched multiple times in this approach, instead of just once for reviewers. 
However, matching the non-reviewers only once to a single random pair just produces a noisier version of this all-matches null distribution. 
Averaging the single-random-match approach over many random single matches produces the same null distribution.

In @fig-like-your-reviewer we see inconsistent evidence in favor of peer review. 
Task 1 review pairs became more similar in Task 2, while unreviewed pairs did not change. 
The change in average absolute effect differences from Task 1 to Task 2 was a statistically significant .051 greater for review pairs than non-review pairs (see Appendix Table \ref{tab-peer-review-reg}). 
However, this finding does not replicate in Task 2, where from Task 2 to Task 3, average absolute effect differences shrunk by a statistically significant .029 more for unreviewed than reviewed pairs. 
This is not consistent strong evidence of peer review making a researcher more like their reviewer as the result of feedback.

```{r Comparisons of Effect Sizes vs. Reviewer Figure}
#| label: fig-like-your-reviewer
#| fig-cap: Comparisons of Effect Sizes vs. One's Reviewer
#| fig-width: 8
#| fig-height: 5
p_more_like_reviewer
```

```{r Comparisons of Sample Sizes vs. Reviewer Figure}
#| label: fig-like-your-reviewer-sample
#| fig-cap: Comparisons of Sample Sizes vs. One's Reviewer
#| fig-width: 8
#| fig-height: 5
plots_more_like_reviewer[["Revision_of_Q12"]]
```


```{r Comparisons of DACA Eligible Sample Sizes vs. Reviewer Figure}
#| label: fig-like-your-reviewer-data
#| fig-cap: Comparisons of DACA Eligible Sample Sizes vs. One's Reviewer
#| fig-width: 8
#| fig-height: 5
plots_more_like_reviewer[["Revision_of_Q18"]]
```


```{r Comparisons of DACA Non-Eligible Sample Sizes vs. Reviewer Figure}
#| label: fig-like-your-reviewer-non-data
#| fig-cap: Comparisons of DACA Non-Eligible Sample Sizes vs. One's Reviewer
#| fig-width: 8
#| fig-height: 5
plots_more_like_reviewer[["Revision_of_Q21"]]
```

```{r Peer Review Regression}
names(peer_review_reg) = c('Task 1','Task 2')
peer_review_reg |>
  modelsummary(
    estimate = "{estimate}{stars}",
    stars = c('*' = .1, '**' = .05, '***' = .01),
    align = 'ldd',
    gof_omit = c('IC|R2|RMSE|Err'),
    coef_rename = c('Intercept',
                    'Comparison: Next Round',
                    'Comparison: Next Round vs. This Round',
                    'Unreviewed',
                    'Next Round x Unreviewed',
                    'Next vs. This x Unreviewed'),
    title = 'Paired Absolute Effect Differences and Peer Review \\label{tab-peer-review-reg}',
    escape = FALSE,
    output = 'kableExtra'
  ) |>
  footnote(
    general = 
      c("\\\\footnotesize{* $p < 0.1$, ** $p < 0.05$, *** $p < 0.01$}"),
    general_title = "\\\\footnotesize{Note:}",
    escape = FALSE,
    threeparttable = TRUE,
    footnote_as_chunk = TRUE
  ) 
```



\clearpage

# Multi-Analyst Evaluation of Researcher Characteristics 

## Analysis by Project Organizer A

Table \ref{tab-orga-effects} shows the F-statistic from a regression of the reported effect estimate on a set of indicators for that characteristic, as well as the associated $p$-value and $R^2$ from that regression.
The indicators include each categorical researcher characteristic specified in @sec-sample-characteristics, as well as an indicator for the use of R or Stata as a programming language. 
For all indicators, categories with 5 or fewer researchers in them were omitted before performing the analysis. 
This table allows us to see whether researchers with different characteristics reported different effect levels. 
Table \ref{tab-orga-deviation} does the same, but uses absolute deviation from the sample mean as the dependent variable, which allows us to see whether researchers with different characteristics showed greater agreement on effect levels with the group as a whole.

Tables \ref{tab-orga-effects} and \ref{tab-orga-deviation} show that researcher characteristics hold basically no explanatory power for estimated effects either in level or deviation from the mean. 
Nearly all $p$-values are well above .05. In \ref{tab-orga-deviation}, the $p$-value for race as an explanatory variable in Task 1 had a $p$-value below .1, but given how many comparisons there are here, this is likely to just be noise.


```{r Organizer A effect level}

colnames(res_tab_effect) <- c(
  "",
  "Stat.", "$p$", "$R^2$",
  "Stat.", "$p$", "$R^2$",
  "Stat.", "$p$", "$R^2$"
)

res_tab_effect |>
  kable(
    booktabs = TRUE,
    caption = 'Predicting Effect Level with Researcher Characteristics\\label{tab-orga-effects}',
    format = "latex",
    linesep = "",
    escape = FALSE
    ) |>
  add_header_above(
    c(" " = 1, 
      "$F$ test" = 2, " " = 1, 
      "$F$ test" = 2, " " = 1,
      "$F$ test" = 2, " " = 1),
    line = FALSE,
    escape = FALSE
  ) |>
  add_header_above(
    c(" " = 1, "Task 1" = 3, "Task 2" = 3, "Task 3" = 3)
  ) |>
  footnote(
    general = 
      c("\\\\footnotesize{Each line shows the results for a separate regression by task number. The dependent variable is the reported effect estimate and the independent variables are indicators capturing the researcher characteristics listed in the first column. The $F$-statistic and associated $p$-value are for a null hypothesis of no differences in effect size across indicators for the particular researcher characteristics. In addition, the $R^2$ value is reported for each regression.}"),
    general_title = "\\\\footnotesize{Note:}",
    escape = FALSE,
    threeparttable = TRUE,
    footnote_as_chunk = TRUE
  ) |>
  kable_styling(
    latex_options = "scale_down"
    ) |>
  column_spec(1:10, latex_column_spec = "lrrrrrrrrrr")
```

```{r Organizer A effect deviation}

colnames(res_tab_deviation) <- c(
  "",
  "Stat.", "$p$", "$R^2$",
  "Stat.", "$p$", "$R^2$",
  "Stat.", "$p$", "$R^2$"
)

res_tab_deviation |>
  kable(
    booktabs = TRUE,
    caption = 'Predicting Effect Deviation with Researcher Characteristics\\label{tab-orga-deviation}',
    format = "latex",
    linesep = "",
    escape = FALSE
  ) |>
  add_header_above(
    c(" " = 1, 
      "$F$ test" = 2, " " = 1, 
      "$F$ test" = 2, " " = 1,
      "$F$ test" = 2, " " = 1),
    line = FALSE,
    escape = FALSE
  ) |>
  add_header_above(
    c(" " = 1, "Task 1" = 3, "Task 2" = 3, "Task 3" = 3)
  ) |>
  footnote(
    general = 
      c("\\\\footnotesize{Each line shows the results for a separate regression by task number. The dependent variable is the absolute deviation from the sample mean of the reported effect estimate and the independent variables are indicators capturing the researcher characteristics listed in the first column. The $F$-statistic and associated $p$-value are for a null hypothesis of no differences in deviation from the sample mean across indicators for the particular researcher characteristics. In addition, the $R^2$ value is reported for each regression.}"),
    general_title = "\\\\footnotesize{Note:}",
    escape = FALSE,
    threeparttable = TRUE,
    footnote_as_chunk = TRUE
  ) |>
  kable_styling(
    latex_options = "scale_down"
    ) |>
  column_spec(1:10, latex_column_spec = "lrrrrrrrrrr")
```


The only researcher characteristic that did seem to matter was the choice of programming language, which only weakly predicted effect level, but was a statistically significant predictor of being close to the mean effect in all three rounds.

```{r Organizer A effect level deviation by language}
#| fig-cap: Deviation from Sample Mean of Reported Effect by Language
#| label: fig-deviations-by-language
#| fig-width: 8
#| fig-height: 6
p_deviations_by_language

# NOTE FOR WRITEUP: Of the big R outliers two people were in that category every round, and everyone else was only in there once.
```

@fig-deviations-by-language goes further into the split by language. We see that, of the two languages, Stata users were more likely to report effect estimates near the sample mean. 6.4%, 1.8%, and 0.9% of Stata users were more than .1 in absolute distance from the sample mean in Tasks 1, 2, and 3, respectively, while for R those values are 15.6%, 9.4%, and 12.5%. The number of R users is relatively low at 32,[^24] and so these numbers are sensitive to any researchers who were consistently outliers. There were two R users who had an absolute deviation from the mean of .1 or more every round, while all other R researchers with deviations of .1 or more only had deviations that large in a single round. If we omit those two consistently-high-deviation R users, the percentages are 10%, 3.3%, and 6.7% for R users, which are still higher than the percentages for Stata users.

[^24]: This is one lower than the value reported in @sec-sample-characteristics because the researcher who was dropped from analysis, mentioned later in @sec-sample-characteristics, was an R user.

Overall, there is little role for researcher professional or demographic characteristics in predicting either the level of the effects they reported, or the deviation of those effects from the mean. There is some explanatory power for the choice of programming language. R users were more likely than Stata users to report estimates far from average of what other users reported.

## Analysis By Project Organizer B

Table \ref{tab-researcher-characteristics-regs-b} looks at within-researcher variation in effect estimates across tasks. In the first three columns, the dependent variable is the absolute difference in effects for a given researcher across two tasks, while in the fourth column, the dependent variable is a researcher's maximum estimated effect minus their minimum.

```{r Organizer B}
modelsummary(researcher_characteristics_models_b, 
             estimate = "{estimate}{stars}",
             stars = c('*' = .1, '**' = .05, '***' = .01),
             align = 'ldddd',
             coef_map = c(
               '(Intercept)' = 'Intercept',
               'factor(position)Faculty' = 'Faculty',
               'factor(position)Grad student' = 'Grad student',
               'factor(position)Uni researcher' = 'Uni researcher',
               'factor(position)Other' = 'Other',
               'factor(position)Private researcher' = 'Private researcher',
               'factor(position)Public researcher' = 'Public researcher',
               'factor(degree)PhD' = 'PhD',
               'factor(degree)Not PhD' = 'Not PhD',
               'factor(experience)6+ papers' = '6+ papers',
               'factor(experience)1-5 papers' = '1-5 papers',
               'factor(experience)0 papers' = '0 papers'
             ),
             title = "Model Coefficients and Standard Errors for Task Comparisons\\label{tab-researcher-characteristics-regs-b}",
             gof_omit = '^(?!R2|Num.Obs)',
             escape = FALSE,
             output = 'kableExtra'
) |>
  footnote(
    general = 
      c("\\\\footnotesize{* $p < 0.1$, ** $p < 0.05$, *** $p < 0.01$}"),
    general_title = "\\\\footnotesize{Note:}",
    escape = FALSE,
    threeparttable = TRUE,
    footnote_as_chunk = TRUE
  ) 
```

Most researcher characteristics do not predict absolute within-researcher variation. Career stage, occupation, and number of published papers do not predict absolute differences in estimates across tasks to a statistically significant degree, with few exceptions.

One exception is that private researchers saw larger absolute changes between Task 1 and Task 3, and also more absolute variation overall, although the latter is only significant at the $\alpha = .1$ level. Probably the most interesting is that inexperience was related to smaller changes from Task 1 to Task 3: those who do not have a PhD showed a smaller change between Task 1 and Task 3 (significant at $\alpha = .1$), and those with fewer papers also showed smaller absolute changes than those with 6+ papers (insignificant).
