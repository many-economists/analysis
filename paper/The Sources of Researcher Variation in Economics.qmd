---
title: "The Sources of Researcher Variation in Economics\\thanks{Corresponding author Nick Huntington-Klein, nhuntington-klein@seattleu.edu, +1 (206) 296-5815. Department of Economics, Seattle University, 901 12th Ave., Seattle, WA, 98122. Huntington-Klein and Pörtner are the project organizers. This project was supported by the Alfred P. Sloan foundation grant G-2022-19377. The Seattle University IRB determined this study to be exempt from IRB review in accordance with federal regulation criteria. We would like to thank Kian Farzaneh, Amrapali Samanta, and Erica Long for research assistance and seminar participants at the Center for Education data and Research (CEDR)/Center for Analysis of Longitudinal Data in Education Research (CALDER) at the University of Washington, Institut national de recherche en sciences et technologies du numérique (INRIA), La Universidad de las Americas, Ludwig-Maximilians-Universität München (LMU Munich), Western Washington University, and the 2024 Annual Meeting of WEAI for helpful comments and suggestions. [tk provided valuable comments and suggestions on an earlier draft] We would also like to thank the researchers Mira Chaskes, Jennifer A. Heissel, Elaine L. Hill, Rajius Idzalika, Joshua D. Merfeld, and Ethan Sawyer, who contributed but did not want an authorship slot, the researchers who wished to remain anonymous, and the researchers who enlisted in the study but were not eligible or were not able to complete all three rounds of the project. Data and code for this project are available at \\url{https://github.com/many-economists/analysis}.}"
author:
  - id: HK1
    number: 1
    name: Nick Huntington-Klein
    email: nhuntington-klein@seattleu.edu
    phone: 1-206-296-5815
    fax: NONE
    orcid: 0000-0002-7352-3991
    degrees: PhD
    attributes:
      corresponding: True
    affiliations:
      - id: NHK1_1
        number: 1
        name: Seattle University
        department: Department of Economics
        address: 901 12th Ave, Seattle, WA, 98122
  - id: CP2
    number: 2
    name: Claus C. Pörtner
    email: cportner@seattleu.edu
    phone: 1-206-296-2593
    fax: NONE
    orcid: 0000-0001-8052-9462
    degrees: PhD
    attributes:
      corresponding: True
    affiliations:
      - id: CP1_1
        number: 1
        name: Seattle University
        department: Department of Economics
        address: 901 12th Ave, Seattle, WA, 98122
      - id: CP1_2
        number: 2
        name: Center for Studies in Demography and Ecology 
        address: University of Washington, Seattle, WA, 98195
  - id: Acharya3
    number: 3
    name: Yubraj Acharya
    email: yua36@psu.edu
    phone: 8148656898
    fax: NONE
    orcid: 0000-0002-9003-636X 
    degrees: PhD
    attributes:
      corresponding: False
    affiliations:
      - id: Acharya3_1
        number: 1
        name: The Pennsylvania State University
        department: Department of Health Policy and Administration
        address: 601 Ford Building, University Park, PA 16801
  - id: Adamkovic4
    number: 4
    name: Matus Adamkovic
    email: matus.m.adamkovic@jyu.fi
    phone: +421908330003
    fax: NONE
    orcid: 0000-0002-9648-9108
    degrees: PhD
    attributes:
      corresponding: False
    affiliations:
      - id: Adamkovic4_1
        number: 1
        name: Slovak Academy of Sciences
        department: Centre of Social and Psychological Sciences
        address: Šancová 56, 81105 Bratislava, Slovakia
      - id: Adamkovic4_2
        number: 2
        name:  University of Jyväskylä
        department: Faculty of Humanities and Social Sciences
        address: Seminaarinkatu 15, 40014 Jyväskylän yliopisto, Finland
      - id: Adamkovic4_3
        number: 3
        name:  Charles University
        department: Faculty of Education
        address: Magdalény Rettigové 4, 11000 Prague, Czech Republic
  - id: Adema5
    number: 5
    name: Joop Adema
    email: adema@ifo.de
    phone: +31623877422
    fax: NONE
    orcid: NONE
    degrees: Master's Degree
    attributes:
      corresponding: False
    affiliations:
      - id: Adema5_1
        number: 1
        name: ifo Institute
        department: NONE
        address: Poschingerstrasse 5,  81679 München, Germany
  - id: Agasa6
    number: 6
    name: Lameck Ondieki Agasa
    email: lagasa@kisiiuniversity.ac.ke
    phone: +254721570048
    fax: NONE
    orcid: 0000-0002-3740-8865
    degrees: Master's Degree
    attributes:
      corresponding: False
    affiliations:
      - id: Agasa6_1
        number: 1
        name: Kisii University
        department: Department of Mathematics and Actuarial Sciences
        address: P.O. Box 408-40200, Kisii University
  - id: Ahmad7
    number: 7
    name: Imtiaz Ahmad
    email: imtiaz.ahmad@s3h.nust.edu.pk
    phone: +92 3334747147
    fax: NONE
    orcid: 0000-0002-6329-5964
    degrees: PhD
    attributes:
      corresponding: False
    affiliations:
      - id: Ahmad7_1
        number: 1
        name: National University of Sciences and Technology
        department: Department of Economics
        address: NONE
  - id: Akbulut-Yuksel8
    number: 8
    name: Mevlude Akbulut-Yuksel
    email: mevlude@dal.ca
    phone: +1-902-499-2567
    fax: NONE
    orcid: NONE
    degrees: PhD
    attributes:
      corresponding: False
    affiliations:
      - id: Akbulut-Yuksel8_1
        number: 1
        name: Dalhousie University; IZA
        department: Department of Economics
        address: 6214 University Avenue Halifax, Nova Scotia B3H 4R2 CANADA
  - id: Andresen9
    number: 9
    name: Martin Eckhoff Andresen
    email: m.e.andresen@econ.uio.no
    phone: +4740239166
    fax: NONE
    orcid: 0000-0002-5230-1580
    degrees: PhD
    attributes:
      corresponding: False
    affiliations:
      - id: Andresen9_1
        number: 1
        name: University of Oslo
        department: Department of Economics
        address: Moltke Moes vei 31, 0851 Oslo, Norway
  - id: Angenendt10
    number: 10
    name: David Angenendt
    email: david.angenendt@tum.de
    phone: +498928925394
    fax: NONE
    orcid: 0000-0001-9583-6289
    degrees: PhD
    attributes:
      corresponding: False
    affiliations:
      - id: Angenendt10_1
        number: 1
        name: Technical University of Munich
        department: TUM School of Management
        address: Arcisstr. 21, 80333 Munich, Germany
      - id: Angenendt10_2
        number: 2
        name:  University of Cambridge
        department: Centre for Business Research
        address: 11-12 Trumpington Street, Cambridge, CB2 1AG, UK
  - id: Antón11
    number: 11
    name: José-Ignacio Antón
    email: janton@usal.es
    phone: 0034645758310
    fax: NONE
    orcid: 0000-0001-9623-3121
    degrees: PhD
    attributes:
      corresponding: False
    affiliations:
      - id: Antón11_1
        number: 1
        name: University of Salamanca
        department: Department of Applied Economics
        address: Departamento de Economía Aplicada, Facultad de Derecho, Campus Miguel de Unamuno, s/n, 37007 Salamanca (Spain)
  - id: Arenas12
    number: 12
    name: Andreu Arenas
    email: andreu.arenas@ub.edu
    phone: +34650513478
    fax: NONE
    orcid: 0000-0002-0185-6017
    degrees: PhD
    attributes:
      corresponding: False
    affiliations:
      - id: Arenas12_1
        number: 1
        name: University of Barcelona
        department: Economics Department and Institut d'Economia de Barcelona
        address: J.M. Keynes 1-11, 08034 Barcelona (Spain)
  - id: Aslim13
    number: 13
    name: Erkmen Giray Aslim
    email: aslime@gvsu.edu
    phone: 603-205-3708
    fax: NONE
    orcid: NONE
    degrees: PhD
    attributes:
      corresponding: False
    affiliations:
      - id: Aslim13_1
        number: 1
        name: Grand Valley State University
        department: Department of Economics
        address: 3120 L. William Seidman Center, 50 Front Avenue SW, Grand Rapids, MI 49504
  - id: Avdeev14
    number: 14
    name: Stanislav Avdeev
    email: stnavdeev@gmail.com
    phone: +31651865403
    fax: NONE
    orcid: 0000-0002-3130-1418
    degrees: Master's Degree
    attributes:
      corresponding: False
    affiliations:
      - id: Avdeev14_1
        number: 1
        name: University of Amsterdam
        department: Amsterdam School of Economics
        address: Roetersstraat 11, 1018 WB Amsterdam, the Netherlands
  - id: Bacher-Hicks15
    number: 15
    name: Andrew Bacher-Hicks
    email: abhicks@bu.edu
    phone: 617-358-1388
    fax: NONE
    orcid: NONE
    degrees: PhD
    attributes:
      corresponding: False
    affiliations:
      - id: Bacher-Hicks15_1
        number: 1
        name: Boston University
        department: Wheelock College of Education and Human Development
        address: 2 Silber Way, Boston, MA 02215
  - id: Baker16
    number: 16
    name: Bradley J. Baker
    email: bradley.baker@temple.edu
    phone: 215.204.6163
    fax: NONE
    orcid: 0000-0002-1697-4198
    degrees: PhD
    attributes:
      corresponding: False
    affiliations:
      - id: Baker16_1
        number: 1
        name: Temple University
        department: Department of Sport, Tourism and Hospitality Management
        address: 1810 N. 13th St. Speakman Hall 111 Philadelphia, PA 19122 USA
  - id: Bandara17
    number: 17
    name: Imesh Nuwan Bandara
    email: imeshnu1@gmail.com
    phone: 8572891428
    fax: NONE
    orcid: NONE
    degrees: Master's Degree
    attributes:
      corresponding: False
    affiliations:
      - id: Bandara17_1
        number: 1
        name: Independent
        department: NONE
        address: NONE
  - id: Bansal18
    number: 18
    name: Avijit Bansal
    email: avijit@iimcal.ac.in
    phone: +91 8976-37-2927
    fax: NONE
    orcid: 0000-0002-8873-9373
    degrees: PhD
    attributes:
      corresponding: False
    affiliations:
      - id: Bansal18_1
        number: 1
        name: Indian Institute of Management Calcutta
        department: Finance & Control Area
        address: Indian Institute of Management Calcutta, DH road, Kolkata, India - 700104
  - id: Bartram19
    number: 19
    name: David Bartram
    email: d.bartram@le.ac.uk
    phone: +447909734199
    fax: NONE
    orcid: 0000-0002-7278-2270
    degrees: PhD
    attributes:
      corresponding: False
    affiliations:
      - id: Bartram19_1
        number: 1
        name: University of Leicester
        department: Department of Sociology
        address: University Road, Leicester LE2 1TL, United Kingdom
  - id: Bech-Wysocka20
    number: 20
    name: Katarzyna Bech-Wysocka
    email: kbech@sgh.waw.pl
    phone: +48 888 652 596
    fax: NONE
    orcid: 0000-0001-5302-9526
    degrees: PhD
    attributes:
      corresponding: False
    affiliations:
      - id: Bech-Wysocka20_1
        number: 1
        name: Warsaw School of Economics
        department: Institute of Econometrics
        address: al. Niepodleglosci 162, 02-554 Warsaw, Poland
      - id: Bech-Wysocka20_2
        number: 2
        name:  FAME|GRAPE
        department: NONE
        address: ul. Koszykowa 59/7, 00-660 Warsaw, Poland
  - id: Bennett21
    number: 21
    name: Christopher Troy Bennett
    email: cbennett@rti.org
    phone: 919-949-5343
    fax: NONE
    orcid: 0000-0002-8910-8098
    degrees: PhD
    attributes:
      corresponding: False
    affiliations:
      - id: Bennett21_1
        number: 1
        name: RTI International
        department: NONE
        address: 3040 E. Cornwallis Rd, Research Triangle Park, NC 27709
  - id: Berha22
    number: 22
    name: Andu N. Berha
    email: aberha@ualberta.ca
    phone: 5879262893
    fax: NONE
    orcid: 0000-0003-4985-4990
    degrees: Master's Degree
    attributes:
      corresponding: False
    affiliations:
      - id: Berha22_1
        number: 1
        name: University of Alberta
        department: NONE
        address: Edmonton, Alberta, T6G2H1, Canada
  - id: Berniell23
    number: 23
    name: Inés Berniell
    email: ines.berniell@econo.unlp.edu.ar
    phone: +5491132959784
    fax: NONE
    orcid: 0000-0002-2268-2757
    degrees: PhD
    attributes:
      corresponding: False
    affiliations:
      - id: Berniell23_1
        number: 1
        name: Universidad Nacional de La Plata
        department: Department of Economics
        address: Calle 6 777. La Plata, Buenos Aires, Argentina
      - id: Berniell23_2
        number: 2
        name:  CEDLAS
        department: Department of Economics
        address: NONE
      - id: Berniell23_3
        number: 3
        name:  IIE
        department: Department of Economics
        address: NONE
  - id: Bhai24
    number: 24
    name: Moiz Bhai
    email: mxbhai@ualr.edu
    phone: 501-916-6742
    fax: 501-916-3898
    orcid: 0000-0001-5990-5187
    degrees: PhD
    attributes:
      corresponding: False
    affiliations:
      - id: Bhai24_1
        number: 1
        name: University of Arkansas at Little Rock
        department: Department of Accounting, Economics, and Finance
        address: 2801 S. University Ave, Little Rock AR 72204
      - id: Bhai24_2
        number: 2
        name:  University of Arkansas for Medical Sciences
        department: Department of Accounting, Economics, and Finance
        address: 2801 S. University Ave, Little Rock AR 72204
  - id: Bhattacharya25
    number: 25
    name: Shreya Bhattacharya
    email: sbhattacharya@wm.edu
    phone: 8323986798
    fax: NONE
    orcid: NONE
    degrees: PhD
    attributes:
      corresponding: False
    affiliations:
      - id: Bhattacharya25_1
        number: 1
        name: Digital Inclusion and Governance Lab, Global Research Institute, William & Mary
        department: NONE
        address: 427 Scotland St, Williamsburg, VA 23187
  - id: Bjoerkheim26
    number: 26
    name: Markus Bjoerkheim
    email: mbjoerkh@gmu.edu
    phone: 5404357294
    fax: NONE
    orcid: 0000-0001-8952-6671
    degrees: PhD
    attributes:
      corresponding: False
    affiliations:
      - id: Bjoerkheim26_1
        number: 1
        name: Mercatus Center at George Mason University
        department: Open Health
        address: 3434 Washington Blvd., 4th Floor Arlington, VA 22201
  - id: Bloem27
    number: 27
    name: Jeffrey R. Bloem
    email: j.r.bloem@cgiar.org
    phone: 774-242-2588
    fax: NONE
    orcid: 0000-0002-4995-3043
    degrees: PhD
    attributes:
      corresponding: False
    affiliations:
      - id: Bloem27_1
        number: 1
        name: International Food Policy Research Institute 
        department: NONE
        address: 1201 I St NW, Washington, DC 20005
  - id: Brehm28
    number: 28
    name: Margaret E Brehm
    email: mbrehm@oberlin.edu
    phone: 440-775-8449
    fax: NONE
    orcid: NONE
    degrees: PhD
    attributes:
      corresponding: False
    affiliations:
      - id: Brehm28_1
        number: 1
        name: Oberlin College
        department: Department of Economics
        address: 10 N. Professor Street, Oberlin, OH 44074
  - id: Brun29
    number: 29
    name: Martín Brun
    email: martin.brun@uab.cat
    phone: +34935811680
    fax: NONE
    orcid: 0000-0002-6896-6309
    degrees: Master's Degree
    attributes:
      corresponding: False
    affiliations:
      - id: Brun29_1
        number: 1
        name: Universitat Autónoma de Barcelona
        department: Department of Applied Economics
        address: NONE
  - id: Buisson30
    number: 30
    name: Florent Buisson
    email: fbuisson@cars.com
    phone: 9452437867
    fax: NONE
    orcid: NONE
    degrees: PhD
    attributes:
      corresponding: False
    affiliations:
      - id: Buisson30_1
        number: 1
        name: Independent
        department: NONE
        address: 18800 Lina Street, #1010, Dallas, TX 75287
  - id: Burli31
    number: 31
    name: Pralhad Burli
    email: pralhad.burli@inl.gov
    phone: 7328958736
    fax: NONE
    orcid: 0000-0002-4107-8918
    degrees: PhD
    attributes:
      corresponding: False
    affiliations:
      - id: Burli31_1
        number: 1
        name: Idaho National Laboratory
        department: Decision Sciences
        address: Idaho Falls, Idaho
  - id: Camp32
    number: 32
    name: Andrew M. Camp
    email: ac103@uark.edu
    phone: 402-213-6333
    fax: NONE
    orcid: 0000-0002-9970-5275
    degrees: Master's Degree
    attributes:
      corresponding: False
    affiliations:
      - id: Camp32_1
        number: 1
        name: University of Arkansas
        department: Department of Education Reform
        address: Room 201, Graduate Education Building; University of Arkansas; Fayetteville, AR 72701
  - id: Cerutti33
    number: 33
    name: Nicola Cerutti
    email: nc@nicores.de
    phone: +44 (0) 7774 689143
    fax: NONE
    orcid: 0000-0002-5016-9213
    degrees: PhD
    attributes:
      corresponding: False
    affiliations:
      - id: Cerutti33_1
        number: 1
        name: Oasis Loss Modelling Framework
        department: NONE
        address: NONE
  - id: Chen34
    number: 34
    name: Weiwei Chen
    email: wchen30@kennesaw.edu
    phone: 470-578-3136
    fax: 470-578-9022
    orcid: 0000-0002-2162-0941
    degrees: PhD
    attributes:
      corresponding: False
    affiliations:
      - id: Chen34_1
        number: 1
        name: Kennesaw State University
        department: Department of Economics, Finance and Quantitative Analysis
        address: 560 Parliament Garden Way NW, Kennesaw, GA 30144
  - id: Clement35
    number: 35
    name: Jeffrey Clement
    email: clement@augsburg.edu
    phone: 2023686186
    fax: NONE
    orcid: 0000-0002-4500-7260
    degrees: PhD
    attributes:
      corresponding: False
    affiliations:
      - id: Clement35_1
        number: 1
        name: Augsburg University
        department: School of Business and Economics
        address: 2211 Riverside Ave, CB315, Minneapolis, MN 55454
  - id: Collins36
    number: 36
    name: Matthew Collins
    email: matthew.collins@universityofgalway.ie
    phone: +353(0)91493109
    fax: NONE
    orcid: 0009-0002-8414-023X
    degrees: PhD
    attributes:
      corresponding: False
    affiliations:
      - id: Collins36_1
        number: 1
        name: University of Galway
        department: J.E. Cairnes School of Business and Economics
        address: University of Galway, University Road, Galway, Ireland H91 TK33
  - id: Crawfurd37
    number: 37
    name: Lee Crawfurd
    email: lcrawfurd@cgdev.org
    phone: +447869613735
    fax: NONE
    orcid: 0000-0003-1513-934X
    degrees: PhD
    attributes:
      corresponding: False
    affiliations:
      - id: Crawfurd37_1
        number: 1
        name: Center for Global Development
        department: NONE
        address: Great College St, London SW1P 3SE
  - id: Cullinan38
    number: 38
    name: John Cullinan
    email: john.cullinan@universityofgalway.ie
    phone: 091 493996
    fax: NONE
    orcid: 0000-0003-3509-0635
    degrees: PhD
    attributes:
      corresponding: False
    affiliations:
      - id: Cullinan38_1
        number: 1
        name: University of Galway
        department: School of Business & Economics
        address: University Road, Galway, H91 TK33, Ireland
  - id: Deer39
    number: 39
    name: Lachlan Deer
    email: l.k.deer@tilburguniversity.edu
    phone: NONE
    fax: NONE
    orcid: 0000-0001-8646-6095
    degrees: PhD
    attributes:
      corresponding: False
    affiliations:
      - id: Deer39_1
        number: 1
        name: Tilburg University
        department: Department of Marketing
        address: Warandelaan 2, 5037 AB, Tilburg The Netherlands
  - id: Dorsey-Palmateer40
    number: 40
    name: Reid Dorsey-Palmateer
    email: dorseyr2@wwu.edu
    phone: 360 650 2676
    fax: NONE
    orcid: NONE
    degrees: PhD
    attributes:
      corresponding: False
    affiliations:
      - id: Dorsey-Palmateer40_1
        number: 1
        name: Western Washington University
        department: Department of Economics
        address: 516 High Street MS 9074, Bellingham WA 98225
  - id: Duquette41
    number: 41
    name: Nicolas J. Duquette
    email: nduquett@usc.edu
    phone: 213-821-2236
    fax: NONE
    orcid: 0000-0002-0707-6302
    degrees: PhD
    attributes:
      corresponding: False
    affiliations:
      - id: Duquette41_1
        number: 1
        name: University of Southern California
        department: Sol Price School of Public Policy
        address: 650 Childs Way, Los Angeles, CA 90089
  - id: Fages42
    number: 42
    name: Diego Marino Fages
    email: diego.r.marino-fages@durham.ac.uk
    phone: NONE
    fax: NONE
    orcid: 0000-0002-6233-2292
    degrees: PhD
    attributes:
      corresponding: False
    affiliations:
      - id: Fages42_1
        number: 1
        name: Durham University
        department: Department of Economics
        address: Durham University, Mill Hill Lane, Durham, DH1 3LB, UK
  - id: Falken43
    number: 43
    name: Grace Falken
    email: gfalken@uw.edu
    phone: NONE
    fax: NONE
    orcid: 0009-0002-0355-2305
    degrees: Master's Degree
    attributes:
      corresponding: False
    affiliations:
      - id: Falken43_1
        number: 1
        name: University of Washington
        department: Center for Education Data and Research
        address: 3876 Bridge Way N., Suite 201  Seattle, WA 98103
  - id: Farquharson44
    number: 44
    name: Christine Farquharson
    email: christine_f@ifs.org.uk
    phone: 020 7291 4800
    fax: NONE
    orcid: 0000-0003-2799-5506
    degrees: Master's Degree
    attributes:
      corresponding: False
    affiliations:
      - id: Farquharson44_1
        number: 1
        name: Institute for Fiscal Studies
        department: NONE
        address: 7 Ridgmount Street, London UK, WC1E 7AE
  - id: Feld45
    number: 45
    name: Jan Feld
    email: jan.feld@vuw.ac.nz
    phone: +6444639678 
    fax: NONE
    orcid: 0000-0003-3816-6607
    degrees: PhD
    attributes:
      corresponding: False
    affiliations:
      - id: Feld45_1
        number: 1
        name: Victoria University of Wellington
        department: School of Economics and Finance
        address: 22 Bunny Street, Pipitea, Wellington 6011, New Zealand
  - id: Feyman46
    number: 46
    name: Yevgeniy Feyman
    email: yfeyman@gmail.com
    phone: 646-831-5988
    fax: NONE
    orcid: 0000-0001-7372-7671
    degrees: PhD
    attributes:
      corresponding: False
    affiliations:
      - id: Feyman46_1
        number: 1
        name: Department of Health and Human Services
        department: NONE
        address: 200 Independence Ave SW, Washington, DC 20201
  - id: Fiala47
    number: 47
    name: Nathan Fiala
    email: nathan.fiala@uconn.edu
    phone: 2526268400
    fax: NONE
    orcid: NONE
    degrees: PhD
    attributes:
      corresponding: False
    affiliations:
      - id: Fiala47_1
        number: 1
        name: University of Connecticut
        department: Agricultural and Resource Economics
        address: NONE
  - id: Fitzpatrick48
    number: 48
    name: Anne Fitzpatrick
    email: fitzpatrick.88@osu.edu
    phone: (607)339-9261
    fax: NONE
    orcid: 0000-0002-2055-2350
    degrees: PhD
    attributes:
      corresponding: False
    affiliations:
      - id: Fitzpatrick48_1
        number: 1
        name: The Ohio State University
        department: Department of Agricultural, Environmental, and Development Economics
        address: Agricultural Administration Building, 2120 Fyffe Road, Columbus, OH 43210
  - id: Fradkin49
    number: 49
    name: Andrey Fradkin
    email: fradkin@bu.edu
    phone: 2019216279
    fax: NONE
    orcid: 0000-0002-3238-0592
    degrees: PhD
    attributes:
      corresponding: False
    affiliations:
      - id: Fradkin49_1
        number: 1
        name: Boston University, Questrom School of Business
        department: Marketing
        address: 595 Commonwealth Ave, Boston MA 02215
  - id: French50
    number: 50
    name: Evaewero French
    email: frenceva@oregonstate.edu
    phone: 9739146938
    fax: NONE
    orcid: NONE
    degrees: Master's Degree
    attributes:
      corresponding: False
    affiliations:
      - id: French50_1
        number: 1
        name: Oregon State University
        department: School of Public Policy
        address: 300 Bexell Hall 2251 SW Campus Way Corvallis, OR  97331
  - id: Fu51
    number: 51
    name: Wei Fu
    email: wei.fu@louisville.edu
    phone: 484-767-7515
    fax: NONE
    orcid: NONE
    degrees: PhD
    attributes:
      corresponding: False
    affiliations:
      - id: Fu51_1
        number: 1
        name: University of Louisville 
        department: Health Management and Systems Sciences Department 
        address: Room 105, School of Public Health and Information Sciences  485 E Gray St., Louisville, KY, 40202
  - id: Fumarco52
    number: 52
    name: Luca Fumarco
    email: luca.fumarco@econ.muni.cz
    phone: +393534263696
    fax: NONE
    orcid: 0000-0002-6236-0197
    degrees: PhD
    attributes:
      corresponding: False
    affiliations:
      - id: Fumarco52_1
        number: 1
        name: Masaryk University
        department: Department of Economics
        address: NONE
      - id: Fumarco52_2
        number: 2
        name:  IZA
        department: Department of Economics
        address: NONE
      - id: Fumarco52_3
        number: 3
        name:  GLO
        department: Department of Economics
        address: NONE
  - id: Gallegos53
    number: 53
    name: Sebastian Gallegos
    email: sebastian.gallegos@uai.cl
    phone: +56982876954
    fax: NONE
    orcid: 0000-0003-0437-3982
    degrees: PhD
    attributes:
      corresponding: False
    affiliations:
      - id: Gallegos53_1
        number: 1
        name: Universidad Adolfo Ibanez
        department: Business School
        address: Av. Padre Alberto Hurtado 750, Vina del Mar, Chile.
  - id: Galárraga54
    number: 54
    name: Julio Galárraga
    email: julio.galarraga.bonilla@udla.edu.ec
    phone: +593 2 3981000 ext. 7891
    fax: NONE
    orcid: NONE
    degrees: Master's Degree
    attributes:
      corresponding: False
    affiliations:
      - id: Galárraga54_1
        number: 1
        name: Universidad de las Américas Ecuador
        department: Department of Economics
        address: Redondel del Ciclista, Antigua Vía a Nayón, Quito, Ecuador
  - id: Gamino55
    number: 55
    name: Aaron M. Gamino
    email: aaron.gamino@mtsu.edu
    phone: 3092363734
    fax: NONE
    orcid: 0000-0001-7461-2470
    degrees: PhD
    attributes:
      corresponding: False
    affiliations:
      - id: Gamino55_1
        number: 1
        name: Middle Tennessee State University
        department: Department of Economics and Finance
        address: MTSU Box 27, 1301 E. Main St, Murfreesboro, TN 37132
  - id: Gauriot56
    number: 56
    name: Romain Gauriot
    email: romain.gauriot@deakin.edu.au
    phone: +61403700344
    fax: NONE
    orcid: 0000-0002-7633-7086
    degrees: PhD
    attributes:
      corresponding: False
    affiliations:
      - id: Gauriot56_1
        number: 1
        name: Deakin University
        department: Department of Economics
        address: 221 Burwood Hwy, Burwood VIC 3125, Australia
  - id: Gay57
    number: 57
    name: Victor Gay
    email: victor.gay@tse-fr.eu
    phone: +33622225170
    fax: NONE
    orcid: 0000-0001-9912-3841
    degrees: PhD
    attributes:
      corresponding: False
    affiliations:
      - id: Gay57_1
        number: 1
        name: Toulouse School of Economics
        department: Department of Social and Behavioral Sciences
        address: 1 Esplanade de l'Université, 31000, Toulouse, France
  - id: Gayaker58
    number: 58
    name: Savas Gayaker
    email: savas.gayaker@hbv.edu.tr
    phone: +905412504036
    fax: NONE
    orcid: 0000-0002-7186-1532
    degrees: PhD
    attributes:
      corresponding: False
    affiliations:
      - id: Gayaker58_1
        number: 1
        name: Ankara Hacı Bayram Veli University
        department: Department of Econometrics
        address: Emniyet Mahallesi  Gazeteci Yazar Muammer Yaşar Bostancı Caddesi  No:4 06500 Beşevler/Ankara
  - id: Gazeaud59
    number: 59
    name: Jules Gazeaud
    email: jules.gazeaud@gmail.com
    phone: NONE
    fax: NONE
    orcid: 0000-0002-3222-4573
    degrees: PhD
    attributes:
      corresponding: False
    affiliations:
      - id: Gazeaud59_1
        number: 1
        name: CNRS
        department: NONE
        address: NONE
      - id: Gazeaud59_2
        number: 2
        name:  Université Clermont Auvergne
        department: NONE
        address: NONE
  - id: Gendre60
    number: 60
    name: Alexandra de Gendre
    email: a.degendre@unimelb.edu.au
    phone: +61432493139
    fax: NONE
    orcid: 0000-0001-6409-1982
    degrees: PhD
    attributes:
      corresponding: False
    affiliations:
      - id: Gendre60_1
        number: 1
        name: The University of Melbourne
        department: Department of Economics
        address: Level 4 Department of Economics, Faculty of Business and Economics Building, The University of Melbourne, 111 Barry Street, Carlton VIC 3010 Australia
  - id: Gilpin61
    number: 61
    name: Gregory Gilpin
    email: gregory.gilpin@montana.edu
    phone: (406)-994-5628
    fax: (406) 994-4838
    orcid: 0000-0002-6901-2750
    degrees: PhD
    attributes:
      corresponding: False
    affiliations:
      - id: Gilpin61_1
        number: 1
        name: Montana State University
        department: Department of Agricultural Economics and Economics
        address: 306 Linfield Hall, Bozeman, MT 59717
  - id: Girardi62
    number: 62
    name: Daniele Girardi
    email: daniele.girardi@kcl.ac.uk
    phone: NONE
    fax: NONE
    orcid: 0000-0002-3423-3174
    degrees: PhD
    attributes:
      corresponding: False
    affiliations:
      - id: Girardi62_1
        number: 1
        name: King's College London
        department: Department of Political Economy
        address: Bush House, North East Wing, 30 Aldwych, London, WC2B 4BG, United Kingdom
  - id: Goldhaber63
    number: 63
    name: Dan Goldhaber
    email: dgoldhab@uw.edu
    phone: 2066791867
    fax: NONE
    orcid: 0000-0003-4260-4040
    degrees: PhD
    attributes:
      corresponding: False
    affiliations:
      - id: Goldhaber63_1
        number: 1
        name: University of Washington, American Institutes for Research
        department: Center for Education Data and Research (U. of WA), National Center for Analysis of Longitudinal Data in Education Research (AIR)
        address: 3876 Bridge Way N., Suite 201 Seattle, WA 98103
  - id: Harris64
    number: 64
    name: Mark N. Harris
    email: mark.harris@curtin.edu.au
    phone: +61407575126
    fax: NONE
    orcid: 0000-0002-1804-4357
    degrees: PhD
    attributes:
      corresponding: False
    affiliations:
      - id: Harris64_1
        number: 1
        name: Curtin University
        department: School of Accounting, Econmics and Finance
        address: Perth, Western Australia, Australia
  - id: Heller65
    number: 65
    name: Blake H. Heller
    email: bhheller@uh.edu
    phone: 8184583096
    fax: NONE
    orcid: 0000-0003-2093-8170
    degrees: PhD
    attributes:
      corresponding: False
    affiliations:
      - id: Heller65_1
        number: 1
        name: University of Houston
        department: Hobby School of Public Affairs
        address: Bates Building; 4104 Martin Luther King Boulevard, Room 118; Houston, Texas 77204-5021
  - id: Henderson66
    number: 66
    name: Daniel J. Henderson
    email: daniel.henderson@ua.edu
    phone: 205-348-8991
    fax: NONE
    orcid: 0000-0002-4940-9689
    degrees: PhD
    attributes:
      corresponding: False
    affiliations:
      - id: Henderson66_1
        number: 1
        name: University of Alabama
        department: Department of Economics, Finance and Legal Studies
        address: Box 870224, University of Alabama, Tuscaloosa, AL 35487-0224
  - id: Henningsen67
    number: 67
    name: Arne Henningsen
    email: arne@ifro.ku.dk
    phone: +45-51439618
    fax: NONE
    orcid: 0000-0002-6720-0264
    degrees: PhD
    attributes:
      corresponding: False
    affiliations:
      - id: Henningsen67_1
        number: 1
        name: University of Copenhagen
        department: Department of Food and Resource Economics
        address: Rolighedsvej 23, 1958 Frederiksberg C, Denmark
  - id: Henry68
    number: 68
    name: Junita Henry
    email: Junitahenry@g.harvard.edu
    phone: 6176062044
    fax: NONE
    orcid: 0000-0002-5600-7119
    degrees: Master's Degree
    attributes:
      corresponding: False
    affiliations:
      - id: Henry68_1
        number: 1
        name: Harvard University
        department: Department of Global Health
        address: 677 Huntington Ave, Boston, MA 02115
  - id: Herman69
    number: 69
    name: Clément Herman
    email: cherman@princeton.edu
    phone: 6099339278
    fax: NONE
    orcid: NONE
    degrees: Master's Degree
    attributes:
      corresponding: False
    affiliations:
      - id: Herman69_1
        number: 1
        name: Princeton University
        department: Department of Economics
        address: 20 Washington Rd, Princeton, NJ 08540
  - id: Hernæs70
    number: 70
    name: Øystein Hernæs
    email: o.m.hernas@frisch.uio.no
    phone: 004793652406
    fax: NONE
    orcid: 0000-0002-6113-2985
    degrees: PhD
    attributes:
      corresponding: False
    affiliations:
      - id: Hernæs70_1
        number: 1
        name: The Ragnar Frisch Centre for Economic Research
        department: NONE
        address: Gaustadalleen 21, 0349 Oslo, Norway
  - id: Hill71
    number: 71
    name: Andrew J. Hill
    email: andrew.hill6@montana.edu
    phone: 4069943701
    fax: NONE
    orcid: 0000-0001-7630-6151
    degrees: PhD
    attributes:
      corresponding: False
    affiliations:
      - id: Hill71_1
        number: 1
        name: Montana State University
        department: Department of Agricultural Economics and Economics
        address: P.O. Box 172920, Bozeman, MT 59717-2920
  - id: Holzmeister72
    number: 72
    name: Felix Holzmeister
    email: felix.holzmeister@uibk.ac.at
    phone: +4351250771040
    fax: NONE
    orcid: 0000-0001-9606-0427
    degrees: PhD
    attributes:
      corresponding: False
    affiliations:
      - id: Holzmeister72_1
        number: 1
        name: University of Innsbruck
        department: Department of Economics
        address: Universitätsstraße 15, 6020 Innsbruck, Austria
  - id: Huysmans73
    number: 73
    name: Martijn Huysmans
    email: m.huysmans@uu.nl
    phone: +31613077883
    fax: NONE
    orcid: 0000-0002-8431-1396
    degrees: PhD
    attributes:
      corresponding: False
    affiliations:
      - id: Huysmans73_1
        number: 1
        name: Utrecht University
        department: School of Economics
        address: PO Box 80125, 3508 TC Utrecht, NL
  - id: Imtiaz74
    number: 74
    name: M. Saad Imtiaz
    email: saad.imtiaz@lums.edu.pk
    phone: +12029147170
    fax: NONE
    orcid: NONE
    degrees: Master's Degree
    attributes:
      corresponding: False
    affiliations:
      - id: Imtiaz74_1
        number: 1
        name: Lahore University of Management Sciences
        department: Department of Humanities and Social Sciences
        address: Khayaban-e-Jinnah, opposite Sector U،, Phase 5 D.H.A, Lahore, Punjab 54792
  - id: Jain75
    number: 75
    name: Anil K. Jain
    email: anil.k.jain@frb.gov
    fax: NONE
    orcid: 0000-0001-9607-188X
    degrees: PhD
    attributes:
      corresponding: False
    affiliations:
      - id: Jain75_1
        number: 1
        name: Federal Reserve Board of Governors
        department: International Finance
  - id: Jakobsson76
    number: 76
    name: Niklas Jakobsson
    email: niklas.jakobsson@kau.se
    phone: 0046703939009
    fax: NONE
    orcid: 0000-0002-7143-8793
    degrees: PhD
    attributes:
      corresponding: False
    affiliations:
      - id: Jakobsson76_1
        number: 1
        name: Karlstad University
        department: Karlstad Business School
        address: Karlstad Business School, Karlstad University, 651 88 Karlstad
  - id: Kaire77
    number: 77
    name: José Kaire
    email: kaire@asu.edu
    phone: 7654449960
    fax: NONE
    orcid: 0000-0002-2435-9953
    degrees: PhD
    attributes:
      corresponding: False
    affiliations:
      - id: Kaire77_1
        number: 1
        name: Arizona State University
        department: School of Politics and Global Studies
        address: Lattie F. Coor Hall, 975 S Myrtle Ave, Tempe, AZ 85287
  - id: Kameshwara78
    number: 78
    name: Kalyan Kumar Kameshwara
    email: K.Kameshwara@westminster.ac.uk
    phone: +44 07979682728
    fax: NONE
    orcid: 0000-0001-5615-2378
    degrees: PhD
    attributes:
      corresponding: False
    affiliations:
      - id: Kameshwara78_1
        number: 1
        name: University of Westminster
        department: Westminster Business School 
        address: Centre for Employment Research, 35 Marylebone Rd, London NW1 5LS, United Kingdom
  - id: Karney79
    number: 79
    name: Daniel H Karney
    email: karney@ohio.edu
    phone: 740-597-1254
    fax: NONE
    orcid: 0000-0002-3866-0990
    degrees: PhD
    attributes:
      corresponding: False
    affiliations:
      - id: Karney79_1
        number: 1
        name: Ohio University
        department: Department of Economics
        address: 1 President St., Athens, OH 45701
  - id: Kim80
    number: 80
    name: Sie Won Kim
    email: siewon.kim@ttu.edu
    phone: 806-834-8226
    fax: NONE
    orcid: 0000-0003-4940-4156
    degrees: PhD
    attributes:
      corresponding: False
    affiliations:
      - id: Kim80_1
        number: 1
        name: Texas Tech University
        department: Department of Economics
        address: PO Box 41014, Lubbock, TX 79409
  - id: Klotzbücher81
    number: 81
    name: Valentin Klotzbücher
    email: valentin.klotzbuecher@econ.uni-freiburg.de
    phone: +49 761 203 676 52
    fax: +49 761 203 676 49
    orcid: 0000-0001-9382-6757
    degrees: PhD
    attributes:
      corresponding: False
    affiliations:
      - id: Klotzbücher81_1
        number: 1
        name: University of Freiburg
        department: Department of Economics
        address: Wilhelmstraße 1b, D-79085 Freiburg im Breisgau 
  - id: Kronenberg82
    number: 82
    name: Christoph Kronenberg
    email: christoph.kronenberg@uni-due.de
    phone: +4920118-36460
    fax: +4920118-33716
    orcid: NONE
    degrees: PhD
    attributes:
      corresponding: False
    affiliations:
      - id: Kronenberg82_1
        number: 1
        name: University Duisburg-Essen
        department: CINCH
        address: Berliner Platz 6-8, 45127 Essen, Germany
  - id: LaFave83
    number: 83
    name: Daniel LaFave
    email: drlafave@colby.edu
    phone: 207 859 5243
    fax: NONE
    orcid: NONE
    degrees: PhD
    attributes:
      corresponding: False
    affiliations:
      - id: LaFave83_1
        number: 1
        name: Colby College
        department: Department of Economics
        address: 5243 Mayflower Hill, Waterville, ME, USA 04901
  - id: Lang84
    number: 84
    name: David Lang
    email: dnlang.ucla@gmail.com
    phone: 8186459877
    fax: NONE
    orcid: 0000-0001-5415-0125
    degrees: PhD
    attributes:
      corresponding: False
    affiliations:
      - id: Lang84_1
        number: 1
        name: Stanford University
        department: Department of Political Science
        address: NONE
  - id: Lee85
    number: 85
    name: Ryan Lee
    email: RLEE2@laverne.edu
    phone: 909-448-1490
    fax: NONE
    orcid: 0000-0002-2080-4335
    degrees: PhD
    attributes:
      corresponding: False
    affiliations:
      - id: Lee85_1
        number: 1
        name: University of La Verne
        department: College of Business
        address: 1950 3rd St, La Verne, CA 91750
  - id: Liégey86
    number: 86
    name: Maxime Liégey
    email: mliegey@unistra.fr
    phone: +33 6 48 07 74 90
    fax: NONE
    orcid: 0000-0002-3214-1241
    degrees: PhD
    attributes:
      corresponding: False
    affiliations:
      - id: Liégey86_1
        number: 1
        name: Strasbourg University
        department: FSEG
        address: 61 Avenue de la Forêt Noire, 67085 STRASBOURG CEDEX
  - id: Long87
    number: 87
    name: Dede Long
    email: dlong@hmc.edu
    phone: 5037209537
    fax: NONE
    orcid: 0000-0003-1908-186X
    degrees: PhD
    attributes:
      corresponding: False
    affiliations:
      - id: Long87_1
        number: 1
        name: Harvey Mudd College
        department: Department of Humanities, Social Sciences, and the Arts
        address: 301 Platt Blvd, Claremont, CA, 91711
  - id: Marcus88
    number: 88
    name: Jan Marcus
    email: jan.marcus@fu-berlin.de
    phone: +49 30 838 58549
    fax: NONE
    orcid: 0000-0001-9407-6660
    degrees: PhD
    attributes:
      corresponding: False
    affiliations:
      - id: Marcus88_1
        number: 1
        name: Freie Universität Berlin
        department: School of Business and Economics
        address: Garystraße 21, 14195 Berlin, Germany
  - id: Mari89
    number: 89
    name: Gabriele Mari
    email: mari@essb.eur.nl
    phone: NONE
    fax: NONE
    orcid: 0000-0001-8557-5337
    degrees: PhD
    attributes:
      corresponding: False
    affiliations:
      - id: Mari89_1
        number: 1
        name: Erasmus University Rotterdam
        department: Department of Public Administration and Sociology
        address: NONE
  - id: McCarthy90
    number: 90
    name: Ian McCarthy
    email: ian.mccarthy@emory.edu
    phone: 404-727-8808
    fax: NONE
    orcid: 0000-0001-7942-3468
    degrees: PhD
    attributes:
      corresponding: False
    affiliations:
      - id: McCarthy90_1
        number: 1
        name: Emory University
        department: Department of Economics
        address: 1602 Fishburne Drive, Rich Memorial Building, Room 306, Atlanta, GA 30322
      - id: McCarthy90_2
        number: 2
        name:  NBER
        address: 1050 Massachusetts Avenue, Cambridge, MA 02138
  - id: Meinzen-Dick91
    number: 91
    name: Laura Meinzen-Dick
    email: laura.meinzen-dick@villanova.edu
    phone: 636-675-2557
    fax: NONE
    orcid: NONE
    degrees: PhD
    attributes:
      corresponding: False
    affiliations:
      - id: Meinzen-Dick91_1
        number: 1
        name: Villanova University 
        department: Department of Economics 
        address: 800 E Lancaster Ave, Villanova PA 19085
  - id: Merkus92
    number: 92
    name: Erik Merkus
    email: e_merkus@me.com
    phone: 0046701609700
    fax: NONE
    orcid: 0000-0003-2602-5866
    degrees: PhD
    attributes:
      corresponding: False
    affiliations:
      - id: Merkus92_1
        number: 1
        name: Independent
        department: NONE
        address: NONE
  - id: Miller93
    number: 93
    name: Klaus M. Miller
    email: millerk@hec.fr
    phone: +33 1 39 67 70 88
    fax: NONE
    orcid: 0000-0003-0017-330X
    degrees: PhD
    attributes:
      corresponding: False
    affiliations:
      - id: Miller93_1
        number: 1
        name: HEC Paris
        department: Department of Marketing
        address: 1 Rue de la Libération, 78350 Jouy-en-Josas, France
  - id: Mogge94
    number: 94
    name: Lukas Mogge
    email: lukas.mogge@rwi-essen.de
    phone: +4930202159821
    fax: NONE
    orcid: 0000-0002-1364-5241
    degrees: Dr. rer. oec.
    attributes:
      corresponding: False
    affiliations:
      - id: Mogge94_1
        number: 1
        name: RWI – Leibniz Institute for Economic Research
        department: Economic Policy Lab Climate, Migration and Development
        address: Hohenzollernstrasse 1-3, 45128 Essen, Germany.
  - id: Murad95
    number: 95
    name: S. M. Woahid Murad
    email: s.murad@curtin.edu.au
    phone: +61468583603
    fax: NONE
    orcid: 0000-0002-5886-9759
    degrees: Master's Degree
    attributes:
      corresponding: False
    affiliations:
      - id: Murad95_1
        number: 1
        name: Curtin University
        department: School of Accounting, Economics and Finance
        address: NONE
      - id: Murad95_2
        number: 2
        name:  Noakhali Science and Technology University
        department: Department of Economics
        address: NONE
  - id: Najam96
    number: 96
    name: Rafiuddin Najam
    email: najamr@oregonstate.edu
    phone: 9717199957
    fax: NONE
    orcid: 0000-0002-2943-545X
    degrees: Master's Degree
    attributes:
      corresponding: False
    affiliations:
      - id: Najam96_1
        number: 1
        name: Oregon State University
        department: Public Policy
        address: Corvallis, OR
  - id: Naumann97
    number: 97
    name: Elias Naumann
    email: elias.naumann@gesis.org
    phone: +496211246442
    fax: +496211246100
    orcid: 0000-0003-1415-0678
    degrees: PhD
    attributes:
      corresponding: False
    affiliations:
      - id: Naumann97_1
        number: 1
        name: GESIS Leibniz Institute for the Social Sciences
        department: NONE
        address: B6 4-5, 68159 Mannheim, Germany
  - id: Nmadu98
    number: 98
    name: Job Nda Nmadu
    email: job_nmadu@futminna.edu.ng
    phone: 08035861170
    fax: NONE
    orcid: 0000-0002-1320-8957
    degrees: PhD
    attributes:
      corresponding: False
    affiliations:
      - id: Nmadu98_1
        number: 1
        name: Federal University of Technology, Minna, Nigeria 
        department: Department of Agricultural Economics and Farm Management 
        address: PMB 65, Minna
  - id: Ozer99
    number: 99
    name: Gorkem Turgut Ozer
    email: GT.Ozer@unh.edu
    phone: (603) 862-2709
    fax: NONE
    orcid: 0000-0003-4451-5076
    degrees: PhD
    attributes:
      corresponding: False
    affiliations:
      - id: Ozer99_1
        number: 1
        name: University of New Hampshire
        department: Paul College of Business and Economics
        address: 10 Garrison Ave, Durham, NH 03824
  - id: Paudel100
    number: 100
    name: Jayash Paudel
    email: jayash.paudel@ou.edu
    phone: 12089198931
    fax: NONE
    orcid: 0000-0003-3430-7943
    degrees: PhD
    attributes:
      corresponding: False
    affiliations:
      - id: Paudel100_1
        number: 1
        name: University of Oklahoma
        department: Department of Economics
        address: 308 Cate Center Drive Norman, OK 73019
  - id: Petroulakis101
    number: 101
    name: Filippos Petroulakis
    email: fpetroulakis@bankofgreece.gr
    phone: +306944821586
    fax: +302103233025
    orcid: NONE
    degrees: PhD
    attributes:
      corresponding: False
    affiliations:
      - id: Petroulakis101_1
        number: 1
        name: Bank of Greece
        department: NONE
        address: 21 El. Venizelou Street, 102 50, Athens, Greece
  - id: Peukert102
    number: 102
    name: Christian Peukert
    email: christian.peukert@unil.ch
    phone: +41446324671
    fax: NONE
    orcid: 0000-0003-3997-8850
    degrees: PhD
    attributes:
      corresponding: False
    affiliations:
      - id: Peukert102_1
        number: 1
        name: University of Lausanne, Faculty of Business and Economics (HEC)
        department: Department of Strategy, Globalization and Society
        address: Quartier Chamberonne, CH-1015 Lausanne
  - id: Pitkänen103
    number: 103
    name: Visa Pitkänen
    email: visa.pitkanen@kkv.fi
    phone: +358504098397
    fax: NONE
    orcid: 0000-0002-8727-3831
    degrees: PhD
    attributes:
      corresponding: False
    affiliations:
      - id: Pitkänen103_1
        number: 1
        name: Finnish Competition and Consumer Authority
        department: NONE
        address: Lintulahdenkuja 2 A, 00530 Helsinki, Finland
  - id: Porcher104
    number: 104
    name: Simon Porcher
    email: simon.porcher@u-paris2.fr
    phone: +33617154415
    fax: NONE
    orcid: NONE
    degrees: PhD
    attributes:
      corresponding: False
    affiliations:
      - id: Porcher104_1
        number: 1
        name: Université Paris Panthéon-Assas
        department: Department of Management 
        address: 1 rue Guy de la Brosse 75005 Paris France
  - id: Prakash105
    number: 105
    name: Manab Prakash
    email: manab.prakash@giis.edu.np
    phone: +9779840276721
    fax: NONE
    orcid: 0000-0002-9958-2981
    degrees: Master's Degree
    attributes:
      corresponding: False
    affiliations:
      - id: Prakash105_1
        number: 1
        name: Tribhuvan University
        department: Central Department of Economics
        address: Kritipur, Kathmandu, Nepal
  - id: Pua106
    number: 106
    name: Andrew Adrian Yu Pua
    email: andrewypua@outlook.com
    phone: NONE
    fax: NONE
    orcid: 0000-0002-2225-5245
    degrees: PhD
    attributes:
      corresponding: False
    affiliations:
      - id: Pua106_1
        number: 1
        name: De La Salle University - Manila
        department: School of Economics
        address: 2401 Taft Avenue, Manila 0922, Philippines
  - id: Pugatch107
    number: 107
    name: Todd Pugatch
    email: todd.pugatch@oregonstate.edu
    phone: 5417376628
    fax: NONE
    orcid: 0000-0003-0127-2289
    degrees: PhD
    attributes:
      corresponding: False
    affiliations:
      - id: Pugatch107_1
        number: 1
        name: Oregon State University
        department: Department of Economics, School of Public Policy
        address: 300 Bexell Hall, Corvallis OR 97331
  - id: Putman108
    number: 108
    name: Daniel S. Putman
    email: putmands@sas.upenn.edu
    phone: 530-564-9082
    fax: NONE
    orcid: 0000-0002-2446-0103
    degrees: PhD
    attributes:
      corresponding: False
    affiliations:
      - id: Putman108_1
        number: 1
        name: University of Pennsylvania
        department: Center for Social Norms and Behavioral Dynamics
        address: 3718 Locust Walk, Philadelphia, PA 19104
  - id: Rayamajhee109
    number: 109
    name: Veeshan Rayamajhee
    email: veeshan@nmsu.edu
    phone: (267)-629-9642
    fax: NONE
    orcid: 0000-0002-2117-7337
    degrees: PhD
    attributes:
      corresponding: False
    affiliations:
      - id: Rayamajhee109_1
        number: 1
        name: New Mexico State University
        department: Department of Economics, Applied Statistics, and International Business
        address: Las Cruces, NM 88003
  - id: Rehman110
    number: 110
    name: Obeid Ur Rehman
    email: obeid@torontomu.ca
    phone: +16478640359
    fax: NONE
    orcid: 0000-0002-7357-9717
    degrees: PhD
    attributes:
      corresponding: False
    affiliations:
      - id: Rehman110_1
        number: 1
        name: Toronto Metropolitan University
        department: Department of Economics
        address: 350 Victoria Street, Toronto, ON, M5B 2K3, Canada
  - id: Reimão111
    number: 111
    name: Maira Emy Reimão
    email: maira.reimao@villanova.edu
    phone: 2023683654
    fax: NONE
    orcid: 0000-0001-7143-9668
    degrees: PhD
    attributes:
      corresponding: False
    affiliations:
      - id: Reimão111_1
        number: 1
        name: Villanova University
        department: Department of Economics
        address: 800 E Lancaster Ave, Villanova PA, 19085
  - id: Reuter112
    number: 112
    name: Anna Reuter
    email: anna.reuter@uni-heidelberg.de
    phone: NONE
    fax: NONE
    orcid: 0000-0002-3087-7415
    degrees: PhD
    attributes:
      corresponding: False
    affiliations:
      - id: Reuter112_1
        number: 1
        name: Heidelberg University
        department: Heidelberg Institute of Global Health
        address: Im Neuenheimer Feld 130.3, 69120 Heidelberg, Germany
  - id: Ricks113
    number: 113
    name: Michael David Ricks
    email: mricks4@unl.edu
    phone: 8015027270
    fax: NONE
    orcid: 0000-0003-1220-0862
    degrees: PhD
    attributes:
      corresponding: False
    affiliations:
      - id: Ricks113_1
        number: 1
        name: University of Nebraska - Lincoln
        department: Department of Economics
        address: 730 N. 14th Street P.O. Box 880405 Lincoln, NE 68588-0405
  - id: Rios-Avila114
    number: 114
    name: Fernando Rios-Avila
    email: friosavi@levy.org
    phone: 4049245176
    fax: NONE
    orcid: NONE
    degrees: PhD
    attributes:
      corresponding: False
    affiliations:
      - id: Rios-Avila114_1
        number: 1
        name: Levy Economics Institute
        department: NONE
        address: 30 Campus Rd, Annandale-On-Hudson, NY 12504
  - id: Rodriguez115
    number: 115
    name: Abel Rodriguez
    email: a01595062@tec.mx
    phone: +525530261539
    fax: NONE
    orcid: 0000-0001-9208-6224
    degrees: Master's Degree
    attributes:
      corresponding: False
    affiliations:
      - id: Rodriguez115_1
        number: 1
        name: Tecnológico de Monterrey 
        department: Escuela de Gobierno y Transformación Pública 
        address: NONE
  - id: Roeckert116
    number: 116
    name: Julian Roeckert
    email: julian.roeckert@rwi-essen.de
    phone: +4930202159812
    fax: NONE
    orcid: 0009-0003-7373-4232
    degrees: PhD
    attributes:
      corresponding: False
    affiliations:
      - id: Roeckert116_1
        number: 1
        name: RWI - Leibniz Institute for Economic Research
        department: Policy Lab - Climate Change, Development and Migration
        address: Zinnowitzer Str. 1, 10115 Berlin, Germany
  - id: Ropovik117
    number: 117
    name: Ivan Ropovik
    email: ivan.ropovik@gmail.com
    phone: +421907607829
    fax: NONE
    orcid: 0000-0001-5222-1233
    degrees: PhD
    attributes:
      corresponding: False
    affiliations:
      - id: Ropovik117_1
        number: 1
        name: Charles University
        department: Faculty of Education
        address: Institute for Research and Development of Education, Myslikova 7, 110 00, Praha 1
      - id: Ropovik117_2
        number: 2
        name:  University of Presov
        department: Faculty of Education
        address: Institute for Research and Development of Education, Myslikova 7, 110 00, Praha 1
      - id: Ropovik117_3
        number: 3
        name:  Czech Academy of Sciences
        department: Institute of Psychology
        address: Institute for Research and Development of Education, Myslikova 7, 110 00, Praha 1
  - id: Roy118
    number: 118
    name: Jayjit Roy
    email: royj@appstate.edu
    phone: 8282626242
    fax: NONE
    orcid: 0000-0002-2347-6947
    degrees: PhD
    attributes:
      corresponding: False
    affiliations:
      - id: Roy118_1
        number: 1
        name: Appalachian State University
        department: Department of Economics
        address: Department of Economics, 416 Howard Street Room 3101B, Peacock Hall, Boone, NC 28608
  - id: Salamanca119
    number: 119
    name: Nicolas Salamanca
    email: n.salamanca@unimelb.edu.au
    phone: +61 (3) 8344 2863
    fax: NONE
    orcid: 0000-0002-6596-843X
    degrees: PhD
    attributes:
      corresponding: False
    affiliations:
      - id: Salamanca119_1
        number: 1
        name: The University of Melbourne
        department: Melbourne Institute, Applied Economic & Social Research
        address: Level 5, 111 Barry street, 3053 Calrton, Victoria (Australia)
  - id: Samahita120
    number: 120
    name: Margaret Samahita
    email: margaret.samahita@ucd.ie
    phone: +35317164621
    fax: NONE
    orcid: 0000-0002-8693-1185
    degrees: PhD
    attributes:
      corresponding: False
    affiliations:
      - id: Samahita120_1
        number: 1
        name: University College Dublin
        department: School of Economics
        address: University College Dublin, Belfield Dublin 4, Ireland
  - id: Samudra121
    number: 121
    name: Aparna Samudra
    email: acsamudra@gmail.com
    phone: +919823460210
    fax: NONE
    orcid: 0000-0001-8715-8051
    degrees: PhD
    attributes:
      corresponding: False
    affiliations:
      - id: Samudra121_1
        number: 1
        name:  RTM Nagpur University 
        department: Department of Economics 
        address: Humanities Building, University Campus, Amravati Road, Nagpur, Maharashtra, India 
  - id: Sanogo122
    number: 122
    name: Vassiki Sanogo
    email: vassikisanogo@gmail.com
    phone: 18503390885
    fax: NONE
    orcid: 0000-0003-0250-6649
    degrees: PhD
    attributes:
      corresponding: False
    affiliations:
      - id: Sanogo122_1
        number: 1
        name: Otsuka Pharmaceutical Development & Commercialization, Inc.
        department: Contract Worker, Pharmacoevidence
        address: 700 SW 62nd Blvd, Gainesville Florida 32607
  - id: Sariyev123
    number: 123
    name: Orkhan Sariyev
    email: o.sariyev@uni-hohenheim.de
    phone: +4917643231585
    fax: NONE
    orcid: 0000-0001-5005-2667
    degrees: PhD
    attributes:
      corresponding: False
    affiliations:
      - id: Sariyev123_1
        number: 1
        name: University of Hohenheim
        department: Department of Rural Development Theory and Policy
        address: Wollgrasweg 43, 70599 Stuttgart, Germany
  - id: Schaak124
    number: 124
    name: Henning Schaak
    email: henning.schaak@boku.ac.at
    phone: NONE
    fax: NONE
    orcid: 0000-0002-7659-4795
    degrees: PhD
    attributes:
      corresponding: False
    affiliations:
      - id: Schaak124_1
        number: 1
        name: University of Natural Resources and Life Sciences, Vienna
        department: Department of Economics and Social Sciences
        address: Feistmantelstr. 4., 1180 Vienna, Austria
  - id: Segel125
    number: 125
    name: Joel E. Segel
    email: jes87@psu.edu
    phone: 814-863-8786
    fax: 814-863-2905
    orcid: 0000-0001-8937-0531
    degrees: PhD
    attributes:
      corresponding: False
    affiliations:
      - id: Segel125_1
        number: 1
        name: Penn State University
        department: Department of Health Policy and Administration
        address: 504 Ford Building, University Park, PA 16802
  - id: Sievertsen126
    number: 126
    name: Hans Henrik Sievertsen
    email: hhs@vive.dk
    phone: +4529658475
    fax: NONE
    orcid: 0000-0003-0126-828X
    degrees: PhD
    attributes:
      corresponding: False
    affiliations:
      - id: Sievertsen126_1
        number: 1
        name: VIVE and University of Bristol
        department: School of Economics
        address: Priory Road Complex, Priory Road, Bristol, BS8 1TU, United Kingdom
      - id: Sievertsen126_2
        number: 2
        name:   VIVE
        department: School of Economics
        address: Priory Road Complex, Priory Road, Bristol, BS8 1TU, United Kingdom
  - id: Smet127
    number: 127
    name: Mike Smet
    email: mike.smet@kuleuven.be
    phone: +32 3 201 18 79
    fax: NONE
    orcid: 0000-0002-1304-4809
    degrees: PhD
    attributes:
      corresponding: False
    affiliations:
      - id: Smet127_1
        number: 1
        name: KU Leuven
        department: Department of Work and Organisation Studies
        address: Hendrik Conscienceplein 8; BE-2000 Antwerpen; Belgium
  - id: Smith128
    number: 128
    name: Brock Smith
    email: brock.smith@gmail.com
    phone: 406-589-7210
    fax: NONE
    orcid: 0000-0003-0584-6534
    degrees: PhD
    attributes:
      corresponding: False
    affiliations:
      - id: Smith128_1
        number: 1
        name: Montana State University
        department: Department of Agricultural Economics and Economics
        address: Montana State University, P.O. Box 172920, Bozeman, MT 59717-2920
  - id: Sorensen129
    number: 129
    name: Lucy C. Sorensen
    email: lsorensen@albany.edu
    phone: 5184425235
    fax: NONE
    orcid: 0000-0003-4111-1236
    degrees: PhD
    attributes:
      corresponding: False
    affiliations:
      - id: Sorensen129_1
        number: 1
        name: University at Albany, SUNY
        department: Department of Public Administration and Policy
        address: Milne Hall, 135 Western Avenue, Albany, NY 12203
  - id: Spantig130
    number: 130
    name: Lisa Spantig
    email: lisa.spantig@rwth-aachen.de
    phone: +49 241 80 99402
    fax: NONE
    orcid: 0000-0003-0776-3863
    degrees: PhD
    attributes:
      corresponding: False
    affiliations:
      - id: Spantig130_1
        number: 1
        name: RWTH Aachen University
        department: School of Business and Economics
        address: Templergraben 64, 52062 Aachen, Germany
      - id: Spantig130_2
        number: 2
        name:  University of Essex
        department: School of Business and Economics
        address: Templergraben 64, 52062 Aachen, Germany
  - id: Szczygielski131
    number: 131
    name: Krzysztof Szczygielski
    email: kszczygielski@wne.uw.edu.pl
    phone: +48501248601
    fax: NONE
    orcid: 0000-0002-7599-1115
    degrees: PhD
    attributes:
      corresponding: False
    affiliations:
      - id: Szczygielski131_1
        number: 1
        name: University of Warsaw
        department: Faculty of Economics Sciences
        address: Dluga st. 44/50, 00-241 Warsaw, POLAND
  - id: Tagat132
    number: 132
    name: Anirudh Tagat
    email: at@monkprayogshala.in
    phone: +91 9619814988
    fax: NONE
    orcid: 0000-0002-7707-453X
    degrees: PhD
    attributes:
      corresponding: False
    affiliations:
      - id: Tagat132_1
        number: 1
        name: Monk Prayogshala
        department: Department of Economics
        address: 4114, Oberoi Garden Estates C Wing 4th Floor, Off Saki Vihar Rd., Andheri (East), Mumbai, India
  - id: Tastan133
    number: 133
    name: Huseyin Tastan
    email: tastan@yildiz.edu.tr
    phone: NONE
    fax: NONE
    orcid: 0000-0002-2701-1039
    degrees: PhD
    attributes:
      corresponding: False
    affiliations:
      - id: Tastan133_1
        number: 1
        name: Yildiz Technical University
        department: Department of Economics
        address: Davutpasa Campus, Istanbul, Turkey
  - id: Trombetta134
    number: 134
    name: Martin Trombetta
    email: martintrombetta@gmail.com
    phone: 5491166068372
    fax: NONE
    orcid: 0000-0003-0180-2198
    degrees: PhD
    attributes:
      corresponding: False
    affiliations:
      - id: Trombetta134_1
        number: 1
        name: Universidad Nacional de General Sarmiento
        department: Área de Economía
        address: Juan María Gutiérrez 1150, Los Polvorines, Buenos Aires, Argentina
      - id: Trombetta134_2
        number: 2
        name:  Consejo Nacional de Investigaciones Científicas y Técnicas
  - id: Venkatesan135
    number: 135
    name: Madhavi Venkatesan
    email: m.venkatesan@northeastern.edu
    phone: 917-496-0440
    fax: NONE
    orcid: 0000-0001-9780-5865
    degrees: PhD
    attributes:
      corresponding: False
    affiliations:
      - id: Venkatesan135_1
        number: 1
        name: Northeastern University
        department: Department of Economics
        address: 360 Huntington Avenue, Boston, MA 02115
  - id: Vernet136
    number: 136
    name: Antoine Vernet
    email: a.vernet@ucl.ac.uk
    phone: 00447733223263
    fax: NONE
    orcid: 0000-0002-7546-9829
    degrees: PhD
    attributes:
      corresponding: False
    affiliations:
      - id: Vernet136_1
        number: 1
        name: University College London
        department: The Bartlett School of Sustainable Construction
        address: Gower Street, London WC1E 6BT
  - id: Volkov137
    number: 137
    name: Eden Volkov
    email: eden.volkov@hhs.gov
    phone: 9173916184
    fax: NONE
    orcid: 0000-0003-1992-7052
    degrees: PhD
    attributes:
      corresponding: False
    affiliations:
      - id: Volkov137_1
        number: 1
        name: Department of Health and Human Services
        department: Office of the Assistant Secretary for Policy and Evaluation
        address: 200 Independence Ave SW, Washington, DC 20201
  - id: Wagner138
    number: 138
    name: Gary A. Wagner
    email: gary.wagner@louisiana.edu
    phone: 337-482-5381
    fax: NONE
    orcid: 0000-0002-7493-8419
    degrees: PhD
    attributes:
      corresponding: False
    affiliations:
      - id: Wagner138_1
        number: 1
        name: University of Louisiana at Lafayette
        department: Department of Economics & Finance
        address: 104 E. University Ave, Lafayette, LA 70504
  - id: Wang139
    number: 139
    name: Yue Wang
    email: april.wang@pg.canterbury.ac.nz
    phone: 0278660008
    fax: NONE
    orcid: NONE
    degrees: Master's Degree
    attributes:
      corresponding: False
    affiliations:
      - id: Wang139_1
        number: 1
        name: University of Canterbury
        department: Department of Economics and Finance
        address: UC Business School, University of Canterbury, 22 Kirkwood Avenue, Ilam, Christchurch 8140, New Zealand
  - id: Ward140
    number: 140
    name: Zachary Ward
    email: Zachary_Ward@baylor.edu
    phone: 2542142694
    fax: NONE
    orcid: NONE
    degrees: PhD
    attributes:
      corresponding: False
    affiliations:
      - id: Ward140_1
        number: 1
        name: Baylor University
        department: Department of Economics
        address: 1621 S 3rd St, Waco TX, 76706
  - id: Waters141
    number: 141
    name: Tom Waters
    email: tom_w@ifs.org.uk
    phone: 020 7291 4800
    fax: NONE
    orcid: 0000-0003-0299-1576
    degrees: Master's Degree
    attributes:
      corresponding: False
    affiliations:
      - id: Waters141_1
        number: 1
        name: Institute for Fiscal Studies
        department: NONE
        address: 7 Ridgmount Street, London, WC1E 7AE
      - id: Waters141_2
        number: 2
        name: University College London 
        department: Institute of Education 
        address: 20 Bedford Way, London WC1H 0AL
  - id: Weber142
    number: 142
    name: Ellerie Weber
    email: ellerie.weber@mountsinai.org
    phone: NONE
    fax: NONE
    orcid: 0000-0003-3179-7035
    degrees: PhD
    attributes:
      corresponding: False
    affiliations:
      - id: Weber142_1
        number: 1
        name: Icahn School of Medicine at Mount Sinai
        department: Department of Population Health Science and Policy
        address: One Gustave L. Levy Place Box 1077 New York, NY 10029
  - id: Weinberg143
    number: 143
    name: Stephen E Weinberg
    email: stephen.weinberg2@health.ny.gov
    phone: 19014855145
    fax: NONE
    orcid: 0000-0002-7676-4862
    degrees: PhD
    attributes:
      corresponding: False
    affiliations:
      - id: Weinberg143_1
        number: 1
        name: Health Research, Inc
        department: NONE
        address: NONE
  - id: Weißmüller144
    number: 144
    name: Kristina S. Weißmüller
    email: k.s.weissmueller@vu.nl
    phone: +31205988398
    fax: NONE
    orcid: 0000-0001-7697-6550
    degrees: PhD
    attributes:
      corresponding: False
    affiliations:
      - id: Weißmüller144_1
        number: 1
        name: Vrije Universiteit Amsterdam
        department: Department of Political Science and Public Administration
        address: De Boelelaan 1105, 1081 HV Amsterdam
  - id: Westheide145
    number: 145
    name: Christian Westheide
    email: christian.westheide@univie.ac.at
    phone: +43-1-4277-37505
    fax: NONE
    orcid: 0000-0002-7871-7998
    degrees: PhD
    attributes:
      corresponding: False
    affiliations:
      - id: Westheide145_1
        number: 1
        name: University of Vienna
        department: Department of Finance
        address: Department of Finance, Faculty of Business, Economics and Statistics, University of Vienna, Oskar-Morgenstern-Platz 1, 1090 Vienna, Austria
  - id: Williams146
    number: 146
    name: Kevin M. Williams
    email: KevinW@oxy.edu
    phone: 5107103947
    fax: NONE
    orcid: NONE
    degrees: PhD
    attributes:
      corresponding: False
    affiliations:
      - id: Williams146_1
        number: 1
        name: Occidental College
        department: Department of Economics
        address: 1600 Campus Road, Los Angeles CA 90041
  - id: Ye147
    number: 147
    name: Xiaoyang Ye
    email: xiaoyang.ye@brown.edu
    phone: 4257535168
    fax: NONE
    orcid: 0000-0003-2872-824X
    degrees: PhD
    attributes:
      corresponding: False
    affiliations:
      - id: Ye147_1
        number: 1
        name: Brown University
        department: Annenberg Institute for School Reform
        address: Box 1985, Providence, RI 02912
  - id: Yu148
    number: 148
    name: Jisang Yu
    email: jisangyu@ksu.edu
    phone: 5309023610
    fax: NONE
    orcid: 0000-0003-3936-1877
    degrees: PhD
    attributes:
      corresponding: False
    affiliations:
      - id: Yu148_1
        number: 1
        name: Kansas State University
        department: Department of Agricultural Economics
        address: 342 Waters Hall 1603 Old Claflin Pl Kansas State University Manhattan, KS 66506
  - id: Zahid149
    number: 149
    name: Muhammad Umer Zahid
    email: umerzahid@uconn.edu
    phone: NONE
    fax: NONE
    orcid: NONE
    degrees: NONE
    attributes:
      corresponding: False
    affiliations:
      - id: Zahid149_1
        number: 1
        name: University of Connecticut
        department: Agricultural and Resource Economics
        address: NONE
  - id: Zanoli150
    number: 150
    name: Raffaele Zanoli
    email: r.zanoli@univpm.it
    phone: +390712204929
    fax: NONE
    orcid: 0000-0002-7108-397X
    degrees: PhD
    attributes:
      corresponding: False
    affiliations:
      - id: Zanoli150_1
        number: 1
        name: Università Politecnica delle Marche (Marche Polytechnic University)
        department: Department of Agricultural, Food & Environmental Sciences
        address: Via Brecce Bianche 60131 ANCONA, Italy
format: 
  pdf:
    keep-tex: true
editor: source
bibliography: References.bib
number-sections: true
execute:
  warning: false
  message: false
  echo: false
abstract: |
  Abstract: We have 146 research teams of economists independently use the same data source to answer the same question about the causal effect of a policy. Each team performs the task three times, first with free choice of how to answer the question, second with all researchers required to use a shared research design, and third with pre-cleaned data and a shared research design. We find considerable variation across researchers in reported sample sizes, sample definitions, and modeling choices, although estimated effects show muted variation. Levels of researcher variation were most heavily influenced by data preparation and cleaning, with much smaller roles for researcher background, modeling and estimation decisions, and exposure to peer review. This implies that data preparation and cleaning should receive considerably more attention in researcher training and the evaluation of research.
include-in-header:
  text:
    \usepackage{booktabs}
    \usepackage{longtable}
    \usepackage{placeins}
    \usepackage{setspace}
    \doublespacing
output: 
  rticles::arxiv_article:
    keep_tex: true
---

```{r libraries and data import}
{
  library(rio)
  library(data.table)
  library(ggplot2)
  library(nicksshorts) # remotes::install_github('NickCH-K/nicksshorts')
  library(stringr)
  library(scales)
  library(vtable)
  library(fixest)
  library(modelsummary)
  library(here)
  library(patchwork)
  library(kableExtra)
  library(tidyverse)
}

dat = import(here("data", "cleaned_survey_post_corrections.parquet"), setclass = 'data.table')
dat[, Revision_of_Q14 := str_replace_all(Revision_of_Q14, '‚Äì','-')]
dat[, Revision_of_Q17 := str_replace_all(Revision_of_Q17, '‚Äì','-')]
dat[, Revision_of_Q20 := str_replace_all(Revision_of_Q20, '‚Äì','-')]

# CHANGE THIS COLOR PALETTE TO CHANGE ALL GRAPHS, except peer_review.R, where it
# is coded directly
colorpal = palette.colors(palette = 'Paired')
```

# Introduction

The social and behavioral sciences produce a staggering amount of empirical results. A responsible reader of this literature should wonder how much they can trust a given study, given the potential for errors, fluke results, or intentional manipulation. Furthermore, as any responsible producer of this literature is well aware, even a researcher doing their best to avoid these problems must make hundreds of choices in the process of collecting and cleaning data, planning their estimation, and coding their analysis---in other words, there are numerous "researcher degrees of freedom" [@simmons2011false]. Even if Researcher A's choices stand up to scrutiny from a reviewer or reader, Researcher B---with the same goal, data, and skills---might have reasonably chosen in a different way that would also stand up to scrutiny. If A and B's choices lead to different results, but only one of them performs the study, this is a source of largely arbitrary variation in the collection of published results. Estimates suggest that, at least in one context, this variation might outweigh the population variation we typically consider when estimating standard errors [@holzmeister2023heterogeneity].

This study examines the impact of researcher degrees of freedom on results, and attempts to isolate researcher degrees of freedom at different stages of the research process to try to determine where researcher choice varies most, and where it most strongly influences results. We do this using a "many-analysts" design where multiple researchers attempt the same research task. The task we chose is common across applied econometrics: estimating the causal effect of a policy that is implemented at a specific period of time and affects some people but not others. We look at differences between researchers in the results as well as in their analytic and data cleaning choices.

We expand on a typical many-analysts design by introducing multiple iterations of the task, each time restricting the amount of choice that researchers can make and so reducing researcher degrees of freedom. This allows us to observe the overall amount of variation in estimates between researchers, as is common in many-analysts designs, and also to separately evaluate the influence of choice in research design and in data cleaning, and the impact of peer review.

We find meaningful differences in the ways that different researchers approach the same task. Some of these differences come from decisions that would normally receive scrutiny from a reader, like the research design and choice of control variables. Other differences came from sources where researchers choose differently but a reader might not recognize that a consequential decision had been made, such as in the functional form of the control variables or in a number of data cleaning or sample limitation decisions. When we force researchers to use the same research design, results became more similar, especially when that shared design is rigidly adhered to. Researcher agreement increased sharply when pre-cleaned data was provided to researchers, implying that data cleaning decisions are a major source of variation between researchers. Development of more mature and standardized data cleaning procedures, and increased visibility for data cleaning and the sharing of data cleaning code, may have a meaningful impact on the consistency and believability of results in applied microeconomics.

## Previous Work on Research Reliability and Researcher Degrees of Freedom

In economics, suspicion about empirical results is not new [@leamer1983let]. The most recent wave of concern is inspired by discussions, originating in the field of psychology, of the "replication crisis." Studies on the replication crisis show that a high percentage of studies cannot be replicated when tested using new data [@open2015estimating; @camerer2016evaluating], that study code and data are not available or do not reproduce the published results [@herbert2021reproducibility], or that "policing replications" that test sensitivity of published results are rare [@ankel2023economists].

While this prior replication work takes an existing study as a baseline and asks whether it is robust to re-evaluation in some way, questions about researcher degrees of freedom are not about whether a given study can be challenged, but instead whether a different researcher performing the same study would have done it differently. These two fields may intersect, and some failures to replicate in replication studies could be due to researcher degrees of freedom, where both the original study and the replication made reasonable choices but found different results [@bryan2019replicator]. The difference in framing here is that the replication literature views the differing choices as a challenge to the validity of the original results, while the researcher degrees of freedom framing views both as part of a universe of reasonable results, assuming both analyses are defensible.

One way to empirically study researcher degrees of freedom is using a many-analysts design. The many-analysts design, popularized by @silberzahn2018many, gives the same data set to multiple teams of researchers and has them independently try to answer the same research question.[^1] Many-analysts studies have now been carried out in many fields, including microeconomics [@huntington2021influence], finance [@menkveld2021non], religion [@hoogeveen2023many], neuroimaging [@botvinik2020variability], political science [@breznau2021observing], machine learning [@chen2024subjectivity], ecology and evolutionary biology [@gould2023same], psychology [@boehm2018estimating; @bastiaansen2020time; @schweinsberg2021same], and medical informatics [@ostropolets2023reproducible], among others.

[^1]: Many-analysts designs are sometimes referred to as "crowdsourced" science.

With few exceptions, many-analysts studies find that there *is* meaningful variation in both methods and conclusions across researchers. Furthermore, researcher variation in design and analysis likely outweighs population variation in effects [@holzmeister2023heterogeneity].

However, these studies vary considerably in the extent to which they can identify the source of that researcher variation or suggest policies that might reduce it. Establishing that there is variation is important, but is of limited impact if we do not understand why or what we can do about it. Further, if not carefully performed, many-analysts results may not even imply that a problem exists. For example, variation in the original @silberzahn2018many study may be largely explained by the research question not being made sufficiently clear to researchers [@auspurg2021has], and not following standard meta-analytic practice may lead us to overstate variation between researchers by being too sensitive to outlier estimates [@auspurg2023social].

The ability to explain variation between researchers, rather than just show that variation exists, is restricted by the limited size of the prior many-analyst studies. As we discuss in @sec-target-sample, we pursued a sample of at least 90 researchers to achieve sufficient power to explain differences in variation.[^2] Since participation in a many-analysts study takes considerable time and effort, sample sizes are often well below even the aforementioned 90, which may explain why many studies do not attempt do decompose the variation in effects they find between sources. These smaller sample sizes can produce acceptable statistical power for some tests but not others, and explaining variation or agreement in effects between researchers generally demands a larger sample than showing the existence of meaningful variation or showing a difference in rates of making a particular research decision. Prior many-analyst studies that try to explain the sources of variation between researchers either do so despite the low-power issue, gather larger samples of researchers, or select analyses that produce adequate power despite small samples.

[^2]: @perignon2022reproducibility, in looking at the sources of reproducibility variation using many teams, used a design with 1,000 tests to replicate in order to adequately power comparisons.

Among studies that attempt to explain researcher variation, there are three common explanations explored: difficulty of the research task, differences in researcher experience or characteristics, and the presence of peer review or evaluation. Some studies show less researcher agreement in more complex or difficult-to-analyze scenarios [@menkveld2021non; @ortloff2023different]. Higher-quality teams (with more experience, seniority, publishing success, and/or people) agree more [@menkveld2021non], experienced researchers tend to draw more abstract codebooks and conclusions than students [@ortloff2023different], and replicators with more coding skill found more errors in original work [@broderick2020automatic]. Outside of many-analysts work, @jelveh2024political find that researcher political orientation affects research results, and @sulik2023scientists show the same for researcher personality metrics. However, other many-analysts research finds that researcher characteristics explained only a small share of the variation in results [@breznau2021observing]. Finally, review may increase agreement [@menkveld2021non]. However, in some cases there is no chance to revise, so we cannot see the impact of peer review, but instead outside evaluation is used as a measure of researcher quality, although in that case, peer review scores do not predict whether a given researcher produces an outlier result [@gould2023same].

Outside of many-analyst designs, there are studies that use simulation to try many combinations of analytical or data-cleaning choices and examine the resulting variation in estimates. This approach is similar to a many-analysts design in that they look at variability in potential research choices and, often, try to explain variation in effects estimates using those choices. These studies are necessarily limited to the set of research decisions that the project organizers consider ahead of time (which constrains the universe of possible decisions but also makes interpretation of the results far more clear), and typically consider all combinations of decisions equally, rather than favoring combinations an actual researcher would choose. Of these studies, the closest to the present study evaluates the sensitivity of results in an observational psychological data set to different data preprocessing and modeling choices [@klau2023comparing]. They try multiple combinations of reasonable preprocessing and modeling choices and use simulation to iterate through the universe of potential choices, finding significant variation in effects over these choices. A similar attempt to separate researcher variation into modeling and preprocessing components is also done in a many-analysts design in @huntington2021influence, although in a limited way.

This study's design aims to evaluate multiple of these variation sources through a staged design, similar to @perignon2022reproducibility. The different stages allow different degrees of researcher choice along the lines of interpretation of the research question, research design, and data preparation, as well as randomized peer review. The goal is to incorporate the mechanisms proposed by the literature and responding to the critique of @auspurg2021has. Researcher characteristics are collected, as well, allowing for exploration of the researcher-characteristics source of researcher variation, although not in a controlled way. We do not address the difficulty of the research task as a potential source of researcher variation in this study.

# Design

In this study, we aim to isolate the influence of several different potential sources of researcher variation by having the same set of researchers complete the same research task at least three times. The research task always has researchers estimate the effect of the Deferred Action for Childhood Arrivals (DACA) program on the probability that those affected by the program work full-time, but the details and restrictions on what researchers do differ between rounds. We refer to these main research tasks as Task 1, Task 2, and Task 3. Following each task, a subset of researchers are randomized into a round of peer reviews, and given the opportunity to revise their work.

Task 1 gives researchers a large amount of freedom in how they complete the research task. Each successive task removes a degree of freedom from the researcher and further specifies how the analysis is to be performed. The intuition behind this design is that if the removal of a specific kind of researcher freedom meaningfully reduces the variation in results between researchees, then that degree of freedom is a meaningful contributor to researcher variation.

The following goals and instructions are shared across all tasks:

-   Estimate the causal effect of a policy (DACA) on a specified outcome (working full-time), among the group affected by that policy (see @sec-focaltask below for more details).

-   Use American Community Survey (ACS) data to estimate the effect, using data no older than 2006 and no newer than 2016.

-   Procure ACS data from IPUMS [@ruggles2024ipums], selecting only one-year files and using harmonized variables.

-   Optionally, combine the ACS data with a data set on the presence or absence of other relevant policies, provided by the organizers.

-   Use a statistics package or language that allows results to be immediately replicated.

Researchers were also given background information on DACA and its eligibility criteria, guidance on how to use the IPUMS website, instructed to use assistants for any work they would normally use assistants for, and to complete their analysis as though it had been their own idea, rather than attempting to match or not-match other researchers, or asking the project organizers how they would like the analysis to be performed.

These instructions comprise the entirety of the limitations on researchers in Task 1. Tasks 2 and 3 specified the task further and removed researcher degrees of freedom.

Task 2 specified the research design more precisely. Instead of allowing any research design to identify the causal effect of interest, Task 2 gave specific definitions for which individuals comprised a "treated" group and which comprised an "untreated" comparison group.[^3] Then, it instructed researchers to estimate the effect by comparing how outcomes for the "treated" group changed from before DACA was implemented to afterwards against how outcome for the "untreated" group changed. This can be thought of as a difference-in-differences style design, although the phrase "difference-in-differences" was not used in the instructions.

[^3]: Although eligibility criteria for DACA were explicitly given in Task 1, Task 2 further limits the treated group by narrowing the acceptable age range. The limitation was more impactful for defining the untreated comparison group, though. Many researchers did use a treated/untreated group approach in Task 1 before it was specified in Task 2, but researchers defined the untreated group in highly diverse ways, as will be shown in the Results section.

Task 3 uses the same research design limitations of Task 2, but also provides a pre-cleaned data set, prepared by the organizers. The data set offered a pre-prepared treated/untreated-group indicator as specified in Task 2, limited the data set only to the treated and untreated group, prepared and cleaned all variables in the data set that did not already come pre-cleaned, handled missing-data flags, merged in state policy data, and offered standardized simplified recodings of demographic variables. Researchers were instructed to not further clean the data or limit the sample.

Comparison of the researcher output between Task 1 and Task 2 is intended to show the researcher variation introduced by either an imprecise statement of the research question, as in @auspurg2021has, or due to differences in research design choices.

Comparison of the researcher output between Task 2 and Task 3 is intended to show the researcher variation introduced by decisions made in the data cleaning and variable definition process. A researcher following the Task 2 instructions should arrive at the same sample size, number of treated individuals, and number of untreated individuals as in Task 3, as well as the same definition for the outcome variable.[^4] Differences in the data set and in the results between Task 2 and Task 3 should be a result of differences in the data cleaning and preparation process.

[^4]: The Task 2 instructions do leave some leeway for definition of some variables, in particular control variables like education or race, which have a specific recoded version available in Task 3 that are not specified in the Task 2 instructions. However, the definitions of the treated and untreated comparison groups should be the same between Task 2 and Task 3.

Following each of the research tasks, researchers engage in a round of peer review with 2/3 of researchers randomly assigned to peer review and 1/3 not assigned to peer review. Those in peer review are randomly assigned in pairs. Those pairs were given work performed by the other member of their pair: the other person's response to the research survey (see below) as well as a brief writeup representing their work, usually including a regression table. Each member performed a blind review of the provided work, and provided a written assessment of that work, which was shared with the original researcher. Reviewers were instructed to produce a review "as though (they) were the reviewer of a journal article," and to judge the work as though they were reviewing for a journal where a study of this kind "could be published if the work was of high quality."

Following peer review, researchers have an opportunity to revise their work in light of the peer review (or for any other reason). Importantly, revision is not mandatory, nor is satisfying one's peer reviewer, and the majority of researchers choose not to submit revisions.

Notably, this form of peer review does not exactly match what is typically done in peer review work for journal publications. In particular, revision is not mandatory, all reviewers have themselves completed a study with the same goal and data and so have extensive background information, and all reviewers are themselves also reviewed by the same person. These features will all affect interpretation of the peer review results. In particular, the non-mandatory nature of the peer review means that the between-round revision work is only visible for a small subset of the researchers, and the paired nature of the reviews means we cannot separate the effect of being reviewed from the effect of reviewing someone else.

Following each research task and revision, researchers filled out a survey about their work.[^5] This survey asked them to report their findings, additional information like sample size and standard errors, and choices made in the process of doing the analysis like sample restrictions, treated-group definitions, estimator, and standard error adjustments. Researchers were also asked to justify why they had made these choices.

[^5]: Note that the design of this study, and this survey, predates @sarafoglou2024subjective and so does not follow it.

This research design and analysis plan has been preregistered [@portner_huntington-klein_2022]. Analyses that were not preregistered will be noted in the results section as they are performed. Full instructions for each task, as well as post-task survey text and the peer-reviewing instructions, are available in the online appendix.

# Data

## The Focal Research Task {#sec-focaltask}

In all research tasks, the specific goal given to researchers was:[^6]

[^6]: Full instructions are available in the online appendix.

> Among ethnically Hispanic-Mexican Mexican-born people living in the United States, what was the causal impact of eligibility for the Deferred Action for Childhood Arrivals (DACA) program (treatment) on the probability that the eligible person is employed full-time (outcome), defined as usually working 35 hours per week or more?
>
> DACA was implemented in 2012. Examine the effects on full-time employment in the years 2013-2016.

In simple terms, this asks researchers to estimate the impact of the DACA program on the probability that those eligible for the program usually work 35 hours per week or more in the years 2013-2016.[^7]

[^7]: There are several existing papers that use the same ACS data set to identify the effect of DACA on various outcomes. The design used in Tasks 2 and 3 was most directly inspired by @amuedo2016can, although the designs do not match exactly, and the outcomes of interest are not the same. Researchers are informed that such previous studies exist and that they can optionally look into previous studies for background as they would normally do when performing research, although no specific previous study is listed. The instructions emphasize that any previous study does not constitute a "right answer" that researchers should be trying to match.

Researchers, many of whom are not from the United States and so may not be familiar with DACA, are given further background information about the DACA program:

-   DACA allowed undocumented immigrants who were accepted into the program to have legal work authorization for two years without fear of deportation, and also allowed them to apply for drivers' licenses or other forms of identification. People could reapply after the two years expired, and many did.

-   Applications for the program opened on August 15, 2012, and over the first four years of the program's existence, over 900,000 applications were received, about 90% of which were approved.[@citservices2016]

-   While the program was not specific to immigrants from any origin country, because of the structure of undocumented immigration to the United States, the great majority of eligible people were from Mexico.

Researchers were also given information on the eligibility criteria for DACA, which was intended to apply only to a specific subset of undocumented immigants who arrived in the United States as children, and not to all undocumented immigrants. Eligible people must:

-   Have arrived in the United States before their 16th birthday.

-   Not have had their 31st birthday as of June 15, 2012.

-   Have lived continuously in the United States since June 15, 2007.

-   Were present in the United States on June 15, 2012 and did not yet have legal status (either citizenship or legal residency) during that time.

An additional eligibility requirement was mistakenly omitted from the Task 1 instructions, but was included for Tasks 2 and 3:

-   Eligible people must have completed at least high school (12th grade) or be a veteran of the military.

In addition to this information about the policy itself and the effect that researchers are supposed to identify, researchers were also given instructions about the data set to use and how to procure it, as well as some details on usage of the data:

-   Data should come from the American Community Survey (ACS), using data no older than 2006, and no newer than 2016.

-   In addition, a file of state/year-level data was provided including labor market data and the presence or absence of different immigration policies in different years. Immigration policy data comes from @urbaninstdata.[^8]

    ACS data should be procured from the IPUMS website [@ruggles2024ipums], specifically selecting one-year ACS files and harmonized variables. Written and video instructions were included showing how to select data samples and variables on the IPUMS website.

-   Researchers were not told which specific variables to use to determine eligibility status, but they were given guidance onto how to find relevant variables (like looking at the Person $\rightarrow$ Race, Ethnicity, and Nativity page to find variables relevant to ethnicity, birthplace, citizenship, and year of immigration).

-   Several relevant features of the ACS that may affect analysis were emphasized: (a) ACS is a repeated cross-section, not a year-to-year panel data set, and (b) ACS does not list the month that data was collected in, so it is not possible to distinguish whether a given observation in 2012 is from before or after the policy was implemented, and (c) we do not actually observe in ACS whether a given person is enrolled in DACA, so we assume that all eligible people who are ethnically Mexican and Mexican-born are treated.

[^8]: This file included the state/year-level unemployment rate and labor force participation rate. Immigration policy flags were for policies for undocumented immigrants to get state drivers' licenses, to get college financial aid, to be banned from state public colleges, or to follow Omnibus immigation legislation that serves to increase the surveillance of immigation documentation. Additional indicators were for participation in E-Verify laws that require employers to verify immigration authorization, to limit E-Verify participation, participation in Secure Communities, and for participation in task-force or jail based 287(g) policies.

Finally, researchers were instructed to keep track of any variables used to limit their sample download on IPUMS, and to review the survey where they would be reporting their results before beginning their analysis.

From there, researchers were given free reign to complete the analysis as they thought most appropriate, including their own choice of statistical software, an instruction to use assistants for any work that they might normally use assistants for, and asking them to complete the analysis as they thought best, as though the research task had been their own idea, not trying to match or not-match other researchers or guess what analyses the project organizers wanted to see. Once finished, they uploaded all of their code and data to a Sharepoint website, wrote a short description and interpretation of their results focusing on a single "headline" result, and filled out the research survey to report their results.

For Task 2, all of the previous instructions remained in place, but several were added to further specify the research design:

-   There is a "treated" group that is comprised of all ethnically Mexican and Mexican-born individuals who are aged 26-30 on June 15, 2012 (recall that individuals must not have had their 31st birthday as of June 15, 2012 to be eligible for DACA).

-   There is an "untreated" group that is comprised of people who would have been eligible for DACA, except that they were aged 31-35 on June 15, 2012.

-   Researchers should estimate the effect of treatment by seeing how the 26-30 group changed from before treatment to after relative to how the 31-35 group changed (keeping in mind this is a repeated cross-section and not panel data).

-   Researchers should attempt to estimate the effect for all individuals in the "treated" group and not, for example, estimate the effect only for men or only for women.

-   The instructions specifically mention that researchers can, if they like, use covariates or account for differing trends to improve the comparability of the treated and untreated groups.

The task is otherwise unchanged for Task 2.

In Task 3, the instructions remain unchanged from Task 2, except that the data is provided directly instead of having researchers download data from IPUMS, omitting data from the year of 2012. In Task 3, project organizers cleaned the data, merged in the state policy data, created a variable indiciating whether a given individual was in the "treated" or "untreated" group, limited the sample only to individuals in "treated" or "untreated," and created simplified versions of variables like education. Researchers were instructed not to further limit the sample from this prepared data set, or to perform further extensive data cleaning.[^9]

[^9]: There were three observations in the final cleaned data set that were missing values of the education variable. The final used sample in Task 3 sometimes differs by 3 across researchers, based on whether the analysis uses education and thus drops these individuals.

## Recruitment and Attrition

In a many-analysts study, researchers who carry out the research task make up both the bulk of the author list and are the subject of inquiry, so their recruitment is a key feature of the study.

### Researcher Qualifications

The goal of the project organizers was to make the set of researchers representative of the set of people who produce the applied microeconomics literature. As such, recruitment criteria focused on identifying people who have produced applied microeconomic research, including potentially non-academic applied microeconomics research.

A given researcher was qualified for the project if they satisfied any one of the following criteria:

-   They are academic faculty working in applied microeconomics.

-   They are a graduate student **and** have a published or forthcoming paper in applied microeconomics.

-   They hold a PhD **and** work in a job where they write non-academic reports using tools from applied microeconomics to estimate causal effects.[^10]

[^10]: This qualification would allow, for example, employees of the World Bank, or people working in private sector research, to participate.

Participation was not limited on the basis of country, career stage, or demographics such as sex, race, or sexual or gender identity.

### Target Sample Size {#sec-target-sample}

An initial simulation-based power analysis assumed that each research task would have 5% less between-researcher variation in observed effects than the previous round and looked at the statisical power to detect a linear relationship between round number and the squared deviation of effects (variance of estimated effects across researchers). We found that we had 90% power to detect this effect if 90 researchers finished all tasks. We also found that, for comparisons of only two different research tasks, 90 researchers would give 85% power to detect a decline in variance from one stage to the next of 15% or more, a reasonable effect size given previous many-analyst studies.

We further assumed that attrition rates would be roughly 50%, which would suggest recruiting 180 eligible researchers to achieve adequate power. We revised that goal to 200 to account for our assumptions potentially being optimistic. Project organizers obtained funding to support payments to 200 researchers (see below).

### Recruitment and Incentives

Recruitment was advertised to potential researchers through three avenues: (1) social media posts on Twitter and LinkedIn, (2) emails to professional organizations including the Institute for Replication and the Committee on the Status of Women in the Economics Profession, and (3) emails to United States economics department chairs. For emails to departments heads, we gathered the list of all 286 economics departments listed in the U.S. News and World Report. We could locate email addresses for a front desk or (preferably) department chair for 264 of those departments. We emailed those 264 departments, asking for the message to be passed on to all faculty or just all microeconomics faculty.

The recruitment message described the project and its goals, and provided a link to a website that included further detail on project expectations and incentives for participation.[^11] Researchers were told that if they completed all three tasks of the project, they would be offered a \$2,000 payment for up to 200 of the participants, and authorship on the eventual paper. The website included a link to a survey that asked questions related to eligibility for the project.

[^11]: <https://nickch-k.github.io/ManyEconomists/>

### Participation and Attrition

```{r Participation and Attrition Code}
source('../code/participation_and_attrition.R')
```

Overall participation and attrition values are in Table \ref{tbl-attrition}. `r justcount[1,Participants]` people submitted applications for the project with `r justcount[1, Attrition]` of these found to be ineligible for the project. Most ineligible people were graduate students who did not yet have a forthcoming paper.[^12]

[^12]: Data processing and analysis as well as table and figure creation for this paper were performed using the R packages **data.table**, **tidyverse**, **rio**, **fixest**, **car**, **modelsummary**, and **vtable** [@R-data-table; @tidyverse2019; @R-rio; @fixest2018; @car2019; @modelsummary2022; @R-vtable].

```{r Attrition Table}
justcount |> knitr::kable(booktabs = TRUE,
                          caption = 'Participation and Attrition\\label{tbl-attrition}')
```

This left `r justcount[2,Participants]` eligible participants. This is more than the 200 for which budget was available to pay the offered \$2,000 incentive. The 282 of these participants who had signed up by the original signup due date were put into a random order, and then the 13 late signups were put at the end of this order. Participants were given their place in the order, and informed that, among people completing all stages of the project, the first 200 in the order would be paid.

Initial assumptions from the power analysis that attrition rates would be near 50% were almost exactly correct, with `r percent(justcount[5,Participants]/justcount[2,Participants],.01)` of these initial `r justcount[2,Participants]` eligible researchers completing all three stages. Nearly all of the attrition occurred by the completion of Task 1. After `r justcount[2,Participants]-justcount[3,Participants]` eligible researchers failed to complete Task 1, only a further `r justcount[3,Participants]-justcount[5,Participants]` failed to complete Task 3. This means we have `r justcount[5,Participants]` researchers who completed all three research tasks, well above the goal of 90.

The high recruitment numbers and the fact that nearly all attrition occurs before Task 1 is complete allows us to evaluate the impact of the payment incentive. One potential concern with our incentive design is that payment and authorship are offered to anyone who completes all tasks, regardless of the quality of their work. We evaluate whether being guaranteed payment affects the probability of completing Task 1 using a regression discontinuity design. Someone randomly assigned to position 199 in the ordering is guaranteed payment if they complete all the tasks, while someone in position 201 may think they are likely to receive payment, but they are not guaranteed it.

We do not find that completion rates are significantly lower just above the cutoff relative to just below it. Appendix @fig-rdd and Table \ref{tab-rdd-reg} show that immediately above the cutoff, completion rates are no different, although they drop as researchers get further from the cutoff before becoming higher again. Regression discontinuity effect estimates vary. Using either a local-polynomial regression with a triangular kernel bandwidth or an OLS regression discontinuity estimate with a quadratic specification and the full range of the data (not including late signups) show meaningfully large effects of being above the cutoff of -.2 on completion rates, but this is very noisy and statistically insignificant. Using a linear specification, linear regression, and the full range of the data instead to maximize statistical power shows an insignificant and small result of .01.[^13] This is not strong evidence that participants were simply signing up in an attempt to get a \$2,000 payment for little effort.

[^13]: Use of the full range, rather than a bandwidth, is justified given that the running variable is randomly assigned aside from the late sign-ups. We also find no effect if we drop the late sign-ups from the regression discontinuity analysis.

### Sample Characteristics {#sec-sample-characteristics}

Tables \ref{tab-samp1} to \ref{tab-samp3} show the characteristics of the recruited sample, and how those characteristics changed with eligibility and attrition. Task 2 is omitted as an attrition stage since so few people dropped out between Task 1 and Task 2.

Table \ref{tab-samp1} shows that the majority of researchers were recruited via social media, and also that those recruited from social media were more likely to finish all three tasks. Upon signup, researchers were about 90% confident of their ability to finish all three tasks. More-confident researchers were slightly more likely to actually finish, and average confidence rates of those who did finish were about 92% instead of 90%.

```{r Reseacher Recruitment Table}
# Generate the summary data frame
sumtable(alldemog,
         vars = c('Researcher_Q11', 'Researcher_Q12_1', 'Researcher_Q12_2'),
         labels = c('Recruitment Source', 'Certainty to Finish Task 1', 'Certainty to Finish Task 3'),
         group = 'Round',
         title = "Researcher Recruitment Source and Completion Confidence\\label{tab-samp1}",
         out = 'kable' 
) |> 
  kable_styling(
    latex_options = "scale_down"
  ) |>
  column_spec(1:12, latex_column_spec = "lrrrrrrrrrrr")
```

Table \ref{tab-samp2} shows the professional experience of enrollees. While graduate students were considered eligible for the project as long as they had a published or forthcoming paper, the majority of eligible researchers (`r alldemog[Round == 'Assigned task 1',percent(mean(Researcher_Q10 %in% c('PhD','Prof. Degree')),1)]`) had PhDs. PhD holders were also more likely than other eligible researchers to complete all three tasks.[^14]

[^14]: We also checked the programming languages used by researchers in the work they submitted. The most common language was Stata, with 109 researchers performing their work solely in Stata. 33 used R, and one researcher used both R and Stata. Less common were Python and SPSS, with one researcher each.

These PhDs are split across faculty (`r alldemog[Round == 'Assigned task 1',percent(mean(Researcher_Q6 %in% c('Faculty')),1)]`) and other non-faculty researchers (`r alldemog[Round == 'Assigned task 1',percent(mean(Researcher_Q6 %in% c('Other Researcher')),1)]`), both of which were more likely than graduate students to finish all three rounds. Most of the researchers had at least one published paper.[^15] About a third of initial researchers, and 40% of the final set of researchers, had done work in either immigration or labor economics, the fields closest to the research task at hand, with 5% having done work in both, although all researchers had done work in applied microeconomics generally.

[^15]: Researchers in the "faculty" or "non-faculty researchers" categories who do not hold PhDs were either people who had been hired to faculty roles without holding PhDs (such as ABDs, or people in a faculty position requiring only a Master's degree), or people with Master's degrees in non-faculty research positions who had published academic papers (some of whom were still graduate students). Researchers with "No Academic Papers" are non-academic researchers who produce work not intended for academic journal publication. Those with "No Published Academic Papers" have papers that are forthcoming, or are faculty who only have working papers and no publications.

```{r Researcher Professional Experience Table}
alldemog[Researcher_Q13 %like% 'Labor', Researcher_Cats := 'Labor']
alldemog[Researcher_Q13 %like% 'Immigration', Researcher_Cats := 'Immigration']
alldemog[Researcher_Q13 %like% 'Labor' & Researcher_Q13 %like% 'Immigration', Researcher_Cats := 'Immigration & Labor']
sumtable(alldemog, 
         vars = c('Researcher_Q10', 'Researcher_Q6', 'Q8Recode', 'Researcher_Cats'), 
         labels = c('Degree', 'Occupation', 'Research Experience','Field'), 
         group = 'Round',
         title = 'Researcher Professional Experience\\label{tab-samp2}',
         out = 'kable'
) |>
  kable_styling(
    latex_options = "scale_down"
    ) |>
  column_spec(1:9, latex_column_spec = "lrrrrrrrr")
```

Table \ref{tab-samp3} shows the demographics of the researcher sample. The original enrollment was just under 80% male and more than 55% white, with the white share growing to 66% by the end of Task 3. The 80% male figure is similar to the share male found for faculty at a selected set of top economics departments in 2017 by @lundberg2019women, and among all actively publishing economists in 2019 by @card2022gender. About half of the sample was situated in the United States, and about half was from another country. The representativeness of the racial mixture is difficult to assess for this reason; 66% white would be low if the entire sample were from the United States [@stansbury2023economics], but it is unclear what the population rate is in a 50% US/50% other location sample.

```{r Researcher Demographics Table}
sumtable(alldemog, 
         vars = c('Researcher_Q15',
                            'RaceRecode',
                            'Researcher_Q17'), 
         labels = c('Gender', 'Race', 'LGBTQ+'), 
         group = 'Round',
         title = 'Researcher Demographics\\label{tab-samp3}',
         out = 'kable',
) |>
  kable_styling(
    latex_options = "scale_down"
    ) |>
  column_spec(1:9, latex_column_spec = "lrrrrrrrr")
```

```{r}
# OMIT THIS TABLE, BUT FROM IT WE GET 1 completed Python, 1 SPSS, 1 R/Stata, 33 R, 109 Stata in completed
# alldemog[Q2 == 'Finished task 3'] |>
#   sumtable(vars =  c('Researcher_Q10','Researcher_Q6', 'Q8Recode','Researcher_Q15',
#                             'RaceRecode',
#                             'Researcher_Q17',
#                      'Researcher_Q11',
#                      'Researcher_Cats',
#                      'Language'), 
#          labels = c('Degree','Occupation', 'Research Experience','Gender','Race','LGBTQ+','Recruitment Source','Field',
#                     'Coding Language'),
#          col.breaks = 4,
#          out = 'latex',
#          fit.page = '\\textwidth',
#          anchor = 'tab-samp4')

```

One researcher did complete all three research tasks, and appears in the above tables, but their work has been removed from the results that follow in the rest of the paper, because a misunderstanding of the instructions meant that their work did not attempt to estimate the effect of DACA on the probability of employment.

Aside from being skewed towards the United States, the sample largely reflects the group of people who publish work in applied microeconomics. The US overrepresentation is partially driven by the emails sent to US economics departments, the fact that the project was advertised and carried out in English, and the fact that the project organizers are in the United States and advertised the project using their own social media.

# Results

This section examines the variation in effects and methods across researchers and conditions, demonstrating that variation exists and attempting to explain it.

Importantly, these results are derived from the survey responses that researchers gave about their findings and the choices made. Project organizers did not cross-reference survey responses against researcher code to ensure that their code was accurately reflected in the survey, except in a small number of cases where the survey response could not be interpreted. This means that the variation presented here represents the variation in how researchers would plan to implement the research task if they were doing it independently, and what a reader would see as the description of a study in a published version of their work. Any variation between researchers that occurs as a result of coding error or a research report that misrepresents what a researcher actually did will not be reflected here, but could be the subject of a future investigation.

## Variation in Effects and Sample Sizes {#sec-variation}

```{r Main Scripts}
# Ensure the proper analytic sample for all following code
dat = dat[Q1 != 972]
dat = dat[Q1 %in% Q1[Q2 == "The third replication task"]]

source('../code/variation_in_effects_and_sample_sizes.R')
source('../code/variance_tests.R')
source('../code/researcher_characteristics_and_effects.R')
source('../code/researcher_characteristics_and_effects_b.R')
source('../code/analytic_choices.R')
source('../code/clean_controls.R')
source('../code/post_handcoding_sample_limitations.R')
source('../code/round_2_bimodality.R')
source('../code/sd_i_regress_hypothesis_2.R')
```

```{r Peer Review Code}

# This code generated the sample_restrictions_handcoded file that was then corrected by hand
#source('../code/sample_limitations.R')
source('../code/peer_review.R')
source('../code/peer_review_sample_size.R')

# Generate ordering for spot checks

# generate a random order for spot checks
# set.seed(1000)
# spot_checks = copy(sampdat)
# spot_checks = spot_checks[Round %in% c('Task 1','Task 2')]
# spot_checks[, random_order := sample(1:nrow(spot_checks), nrow(spot_checks))]
# setorder(spot_checks, random_order)
# export(spot_checks, 'spot_checks_no_revisions.xlsx')
```

@fig-effect-distributions and Table \ref{tab-effectdist} show the distribution of estimated effects across all researchers. The effect distributions are shown in two ways: unweighted and using inverse-standard-error weights.[^16] Several data points are dropped from the weighted analysis for researchers who did not report standard errors or reported 0. Other missing values are researchers who did not repond to a given question.

[^16]: The use of inverse-standard-error weights is not preregistered but follows meta-analytic standards, reducing the influence of estimates that may be outliers due to being estimated with a highly-noisy method, under the suggestion of @auspurg2023social. Weights are truncated at the 95th percentile (200, or a standard error of .005) so as to avoid any single researcher having too much influence on results. Not using the truncation leads to more agreement because a few researchers with very small standard errors make up a significant share of the weighted sample.

In Task 1, the mean estimated effect of DACA eligibility on the probability of working full-time was .053 unweighted or .044 weighted. In both cases these means are pulled upwards by high top-end estimates and are above the 75th percentiles. Median estimates were .030 unweighted or .026 weighted. Even in Task 1, with a large amount of freedom afforded, researchers found a reasonable amount of agreement in the effect sizes outside of the tails, with the 25th to 75th percentile ranges of the effect being .014 to .051 unweighted, an inter-quartile range (IQR) of .037, or 3.7 percentage points in the effect, or .012 to .043 weighted, an IQR of .031. The use of weights narrows the distribution of effects: researchers reporting smaller standard errors also reported estimates that were more similar to each other, which was also the case in Tasks 2 and 3.

```{r Hypothesis 2 Table}
results_hypo_2 |> 
  knitr::kable(booktabs = TRUE,
               caption = 'Squared Difference to Round Mean against\\linebreak Round number (Hypothesis 2)\\label{hypothesis-2}')
```

[This probably does not go here]
Table \ref{hypothesis-2} shows the squared differences to the mean effect in each round regressed against the round number for the effect size and the three 
samples sizes, total, DACA eligible and Non-DACA eligible.
The squared difference to the round mean provides us with a measure of the variance in effect size and samples sizes across researchers.
None of the coefficient on round number are statistically significant, although the coefficients for sample sizes are negative as expected.


Our preregistration plan details that we planned to give descriptive characteristics of the results, as we do here, and also implement a Levene test on whether the variance between researchers declined. We do not reject at the 95% level the null of no change in variance from any stage to any later stage (including a comparison of each task to its revision stage, and comparing each main task to later main tasks), with the lowest p-value of `r number(levene_test_results$pval[1],.001)` coming from the comparison of `r levene_test_results$TaskA[1]` to `r levene_test_results$TaskB[1]`.

Task 2 is somewhat odd in that it shows less agreement than Task 1 despite giving researchers less freedom. The IQRs increase to .043 unweighted or .040 weighted. Further, the effect distributions are somewhat bimodal, especially when weighted. One of these modes appears to be researchers reporting effect estimates of a similar level to those in Task 1, and others reporting effect estimates similar to what would later be found in Task 3.

Moving all the way to Task 3, agreement considerably increases between researchers. The 25th and 75th percentile effects are .031 and .058 unweighted (IQR .027), and .036 and .060 weighted (IQR .024). The bimodality from Task 2 is still there, but with much more agreement and density at the higher mode. From Round 1 to Round 3 we see considerable increases in agreement between researchers.

Taking only the effect distributions as a baseline, we see that, at least in this application, researchers in general report fairly similar, although certainly not identical, effect estimates on average, but there are some extreme outlier estimates as well. We may also take this to mean that providing pre-cleaned data, as in Task 3, led to a strong increase in researcher agreement. Specifying further the research question and design, however, as in Task 2, led to somewhat less agreement. The odd result for Task 2 and its proper interpretation will be investigated further in @sec-bimodal.

```{r Distribution of Reported Effect Sizes Figure}
#| fig-width: 8
#| fig-height: 5
#| label: fig-effect-distributions
#| fig-cap: Distributions of Reported Effect Sizes
p_effect_distribution
```

Table \ref{tab-effectdist} also shows the reported standard errors. Reported standard errors increase significantly from round to round, driven largely by the specification of the research design, which for many researchers considerably narrowed the sample they were supposed to use. This can also be seen in @fig-full-effect-distribution, where the distribution of effects narrows a little across rounds, but confidence intervals increase considerably. Throughout, while there is general agreement on effect size in the middle of the distribution, researchers vary in whether the reported effect is statistically significant, with `r viol[Round == 'Task 1' & Type == 'Weighted', percent(mean(sig, na.rm = TRUE))]`, `r viol[Round == 'Task 2' & Type == 'Weighted', percent(mean(sig, na.rm = TRUE))]`, and `r viol[Round == 'Task 3' & Type == 'Weighted', percent(mean(sig, na.rm = TRUE))]` reporting results that were statistically significantly different from 0 in Tasks 1, 2, and 3, respectively.

Increasing agreement is necessarily driven by individual researchers changing their reported effects in subsequent rounds. @fig-effects-compare-rounds shows that researchers were not strictly bound by their previous estimates. There is effectively no visible or linear statistical relationship between a researcher's reported effect in one task and their effect in the next task.

```{r Same-Researcher Effect Sizes Figure}
#| fig-width: 9
#| fig-height: 3
#| label: fig-effects-compare-rounds
#| fig-cap: Same-Researcher Effect Sizes Across Tasks
p_compare_rounds
```

We can compare average standard errors against the variation in effects between researchers to get a sense of how much effect variability is omitted by only considering a reported standard error, as in @huntington2021influence or @menkveld2021non. Comparing the standard deviation of weighted effects against the average standard error gives ratios of 4.84, 2.23, and 1.75 for Tasks 1, 2, and 3, respectively. @huntington2021influence used a single round and allowed full researcher freedom, and found a range of 3-4 for this ratio, below what we find for the full-freedom Task 1. If we instead compare weighted IQR to average standard errors we get ratios of 1.63, 1.29, and .41. The decrease over rounds is partially driven by increasing agreement over rounds, which suggest that a reported standard error considerably understates the estimate uncertainty that we should acknowledge when including researcher variation. However, these reductions are also driven by the fact that sample sizes decreased from round to round, due to the shared research design instructing researchers to use a more restricted sample than many used in Task 1. These reduced sample sizes increased the reported standard errors and thus the denominator of the effect-variation-to-average-standard-error ratio. This behavior demonstrates a flaw with these ratios, introduced in @huntington2021influence, as a metric for researcher-indused uncertainty. Even if one might expect that researcher variation should be higher for research designs with smaller samples (or less precision for some other fundamental reason), there's no reason to believe that researcher variation would scale at the same rate as the standard error. So this ratio will tend to be higher for research tasks with bigger samples than smaller samples, even if the level of researcher variation is the same.

```{r Distribution of Reported Effects and Samples Sizes Table}
effect_sum_tab |>
  # remove 1st, 7th, and 13th rows
  slice(-1) |>
  slice(-6) |>
  slice(-11) |>
  kable(
    caption = 'Distribution of Reported Effects and Sample Sizes\\label{tab-effectdist}',
    booktabs = TRUE,
    format = "latex"
    ) |>
  pack_rows(
    index = c("Round: Task 1" = 5, "Round: Task 2" = 5, "Round: Task 3" = 5),
    bold = FALSE
  ) |>
  kable_styling(
    latex_options = "scale_down"
    ) |>
  column_spec(1:9, latex_column_spec = "lrrrrrrrr")
```

```{r Specification Curve for All Reported Estimates Figure}
#| label: fig-full-effect-distribution
#| fig-cap: Specification Curve for All Reported Estimates
p_full_effect_distribution_individual
```

Table \ref{tab-effectdist} also shows summary statistics for reported standard errors, both overall and for the treated group. These distributions are also shown in @fig-sample-size-distributions and @fig-treated-group-distributions.

In @fig-sample-size-distributions we see a huge amount of variation in the reported sample size used in Task 1, noting that the x-axis is on a log scale.[^task-3]
The 25th and 75th percentiles of reported sample sizes ranging from 61,600 to 356,787, with some researchers using millions of observations.[^17] 
For Task 2, which specified in the instructions the treated and comparison groups to use, variation reduces considerably, although the 75th percentile (48,125) is still double the 25th (18,981), and there are still some researchers using millions of observations.
Consistent with the reduction when we specify the treated and comparison groups, a Levene test on the variance in sample size rejects the null hypothesis of equal variance across Task 1 and Task 2 at the 0.05 level.

[^task-3]: Task 3 is not shown in the graph because the sample is pre-specified, with the only meaningful variation being whether or not the researcher dropped three rows of data with missing education values, and a few outliers reporting lower numbers. The lower sample sizes for this question are due to researchers who skipped it because they assumed the answer was obvious. [Nick: I do not follow the last sentence; what question does this refer to?]

[^17]: Keep in mind that for Task 1, there was not a specified control group, so a researcher may decide to use the entire ACS sample in the analysis, including people very unlike the eligible group in the sample. In Task 2, the instructions specified a treated and comparison group, but some researchers may have different samples than in Task 3 either due to error, or because they included people other than the treated and comparison group in their sample to improve precision, and used their model to compare those groups more directly.

```{r Sample Size Distributions Figure}
#| label: fig-sample-size-distributions
#| fig-cap: Distributions of Reported Sample Sizes
#| fig-width: 8
#| fig-height: 5
p_sample_size_distributions
```

Variation in the reported size of the treated group in @fig-treated-group-distributions is affected somewhat by researcher confusion in responding to the survey question. The survey question about treated-group size instructed researchers not to count individuals eligible for DACA as treated for the purposes of this question if they were in a pre-DACA year. However, many researchers counted these individuals as treated anyway, leading to variation in the Task 3 distribution, even though every researcher is at this point working with the same eligibility indicator.

```{r Treated Group Distributions Figure}
#| label: fig-treated-group-distributions
#| fig-cap: Distributions of Reported Treated-Group Sizes
p_treated_group_sample_size
```

Aside from this issue, we see that the imposition of a shared definition for the trated group reduced the IQR for the size of the group from 34,631 in Taks 1 to 9,879 in Task 2. Theoretically, however, since there was a shared definition of the treated group in Task 2, there should be no more variation in this variable in Task 2 than in Task 3. This indicates that not all instructions were implemented in the same way across researchers, which will be explored further in @sec-sample-limitations. Despite a shared understanding of who was eligible for DACA and who should be in the treated group, only a shared data preparation that implemented these rules for people led to sharp agreement in the size of the treated-groups sample.

## Bimodality in the Task 2 Effect Estimates {#sec-bimodal}

One of the surprising results in @sec-variation was the effect distribution in Task 2. In designing the study, we had expected that each task would show a narrower distribution of effects than the previous task. While we see this pattern for sample sizes and some researcher choices, the distribution of effects became wider going from Task 1 to Task 2. We also saw emerging bimodality, where the larger part of the sample reported estimates that reflected the distribution of effects already seen in Task 1, while a smaller group of researchers reported larger effects that were more like those found in Task 3. In this section we look for an explanation of the unexpected findings in Task 2.[^18]

[^18]: This section is entirely un-preregistered, as we did not anticipate this finding.

Several anticipated correlates did not explain the bimodal outcomes of Task 2. @fig-effect-vs-sample and @fig-effect-vs-se in the Appendix show that the Task 2 reported sample sizes and standard errors do not strongly explain the effects reported. @fig-effects-compare-rounds in @sec-variation shows that bimodality is not a feature of some researchers trying to make their Task 2 results consistent with their Task 1.

Instead, we find that a major contributing factor to Task 2 bimodality is the ability to precisely implement the treated-group definition given in the instructions. Task 2 gave a very precise definition of who should be included as a part of the treated group. We examine whether a given researcher followed the full set of treated-group definition instructions exactly or not. The mismatch could be small, such as using "\<= 16" instead of "\< 16" for age at migration, or large, such as omitting that eligible people must be non-citizens. In @fig-match-vs-mismatch we show their distribution of effects against researchers who had a mismatch in their criteria in any way. The graph shows that the bimodality heavily driven by the group that precisely matched the treated-group definition. This implies that the bimodality in Task 2 may be explained in large part by a split between researchers who exactly followed the instructions, and so effectively matched what a typical researcher found in Task 3, and those who did not.

```{r}
#| label: fig-match-vs-mismatch
#| fig-cap: Task 2 Effect Distributions Among Those with Exact Treated-Group Definition Matchs vs. Those with Some Mismatch
p_match_vs_mismatch_distribution
```

This does not fully explain researcher behavior: note that there is also a weight of researchers with higher results who did not match perfectly, and also that much of the density of the perfect-match group is at Task 1 effect levels, but keep in mind that there are many other decisions in analysis to be made, and this captures only one angle where determining the correct decision is easiest.

Further, Table \ref{tab-match-by-field} shows that the share of researchers matching exactly is fairly low, between 20-25% by field, keeping in mind that even very minor mismatches are counted as mismatches. Further, perfect-match rates were slightly higher among researchers whose work was closest to the field that the research task was in, immigration and labor, although this difference was not statistically significant at the 95% level.

```{r Match by Field Table}
rfield |>
  kable(
    booktabs = TRUE,
    caption = 'Share of Researchers Matching Treated-Group Definition Exactly by Field\\label{tab-match-by-field}',
    format = "latex"
    ) |>
  kable_styling(
    latex_options = "scale_down"
    ) |>
  column_spec(1:5, latex_column_spec = "lrrrr")

# our t-test
# d = data.table(field = c(rep(TRUE,1+3+12+35),rep(FALSE,c(18+76))), out = c(rep(TRUE,13),rep(FALSE,3+35),rep(TRUE,18),rep(FALSE,76)))
# t.test(d[field == FALSE, out], d[field == TRUE, out])
```

## Peer Review

This section evaluates the impact of peer review on the later work performed by a researcher. The structure of peer review in this study is that, following each main task, 2/3 of the researchers are randomized into pairs that produce a peer review report of the other's work, while the remaining 1/3 do not receive or perform peer review. Then, researchers have an opportunity to revise their work.

Revision is optional, and relatively few researchers (fewer than 30 per task) chose to revise their work after receiving peer review. As such, we mostly look at the impact of peer review on the work performed in subsequent main tasks. The mechanisms by which peer review might be expected to change a researcher's work in normal journal submissions include both that researchers might find peer review comments helpful and incorporate them into their work, and that researchers are required by the journal submission process to incorporate most reviewer comments. In this study, our peer review process can only capture the first of these mechanisms, and in effect may be closer to comments received, for example, during seminar presentations.

In Table \ref{tab-variance-after-revision}, we incorporate revisions and show the variance of the entire sample of reported effects post-revision, replacing each researcher's reported task effect with its revision, if they revised their work. 
There is no statistically significant difference in variance between the reviewed and non-reviewed groups, nor is there a consistent effect in one direction.
Similarly, as shown in Table \ref{tab-variance-after-revision-sample} there are no statistically significant differences in the variance of sample sizes between the peer-reviewed and non-peer-reviewed groups in the follow-up tasks. 


```{r Variance in Effect after Revision table}
#| label: Levene test - effect size
# variance_tests.R - effect size tests
peer_review_levene |>
  knitr::kable(
    booktabs = TRUE, 
    caption = 'Post-Revision Variance in Effect Sizes by Peer Review \\label{tab-variance-after-revision}',
    format = "latex"
    ) |>
  kable_styling(
    latex_options = "scale_down"
    ) |>
  column_spec(1:5, latex_column_spec = "lrrrr")
```


```{r Variance in Sample Sizes after Revision table}
#| label: Levene test - sample size
# variance_test.R - sample size tests
peer_review_levene_sample |>
  select(-2) |>
  kable(
    booktabs = TRUE, 
    caption = 'Post-Revision Variance in Sample Sizes by Peer Review \\label{tab-variance-after-revision-sample}',
    digits = 3,
    format = "latex"
    ) |>
  pack_rows(
    index = c("Overall Sample Size" = 3, "DACA Eligible Sample Size" = 3, "DACA Non-Eligible Sample Size" = 3),
    bold = FALSE
  ) |>
  kable_styling(
    latex_options = "scale_down"
    )
```


@fig-peer-review-effect-distributions shows the distribution of effect sizes estimated by those who did, and did not, engage in peer review in each round. 
The left column of graphs shows the effects reported in each task before researchers were assigned to peer review, and the right column shows the effects reported in the follow-up task. 
As is expected given randomization, effect distributions are fairly similar pre-review between the review and non-review groups. 
No differences emerge between these groups in the follow-up task. 
Levene test p-values comparing effect size variance of peer-reviewed and non-peer-reviewed groups in follow-up tasks show p-values of `r number(levene_peer_vs_next_round$levene_p[1], .001)` and `r number(levene_peer_vs_next_round$levene_p[2], .001)` in Tasks 2 and 3, respectively, or `r number(levene_result_pooled[['Pr(>F)']][1], .001)` when pooling the two tasks. 
This is not strong evidence in favor of the idea that peer review might drive agreement between researchers due to the receipt of feedback.
Similar results are found when comparing the variance of analytic, treatment, or control sample sizes between the peer-reviewed and non-peer-reviewed groups in the follow-up tasks.


```{r}
#| label: fig-peer-review-effect-distributions
#| fig-cap: Distributions of Reported Effect Sizes
p_peer_review_effect_distributions
```


```{r}
#| label: fig-peer-review-distributions-sample
#| fig-cap: Distributions of Reported Sample Sizes
p_peer_review_distributions[["Revision_of_Q12"]]
```


```{r}
#| label: fig-peer-review-distributions-daca
#| fig-cap: Distributions of Reported DACA Eligible Sample Sizes
p_peer_review_distributions[["Revision_of_Q18"]]
```


```{r}
#| label: fig-peer-review-distributions-non-daca
#| fig-cap: Distributions of Reported DACA Non-Eligible Sample Sizes
p_peer_review_distributions[["Revision_of_Q21"]]
```

@fig-like-your-reviewer explores the possibility that peer review might not make the peer-reviewed group as a whole more similar, but rather just make someone more similar to their specific reviewer. We calculate the absolute difference in effects between each reviewer pair, in the task they perform before reviewing (left column), in the follow-up task (middle column) and comparing your follow-up task against your reviewer's result this round (right column), with the right column representing the possibility that a researcher may select an analysis so as to produce a result more similar to the one they saw in the previous round.[^19]

[^19]: The distributions of absolute differences for non-reviewed researchers are generated as a null distribution by matching every non-reviewed researcher to every other non-reviewed researcher and calculating all absolute differences. This null distribution represents the distribution of absolute differences among people who did not actually experience peer review. Notably, each non-reviewer is matched multiple times in this approach, instead of just once for reviewers. However, matching the non-reviewers only once to a single random pair just produces a noisier version of this all-matches null distribution. Averaging the single-random-match approach over many random single matches produces the same null distribution.

In @fig-like-your-reviewer we see inconsistent evidence in favor of peer review. Task 1 review pairs became more similar in Task 2, while unreviewed pairs did not change. The change in average absolute effect differences from Task 1 to Task 2 was a statistically significant .051 greater for review pairs than non-review pairs (see Appendix Table \ref{tab-peer-review-reg}). However, this finding does not replicate in Task 2, where from Task 2 to Task 3, average absolute effect differences shrunk by a statistically significant .029 more for unreviewed than reviewed pairs. This is not consistent strong evidence of peer review making a researcher more like their reviewer as the result of feedback.

```{r}
#| label: fig-like-your-reviewer
#| fig-cap: Comparisons of Effect Sizes vs. One's Reviewer
#| fig-width: 8
#| fig-height: 5
p_more_like_reviewer
```

```{r}
#| label: fig-like-your-reviewer-sample
#| fig-cap: Comparisons of Sample Sizes vs. One's Reviewer
#| fig-width: 8
#| fig-height: 5
plots_more_like_reviewer[["Revision_of_Q12"]]
```


```{r}
#| label: fig-like-your-reviewer-data
#| fig-cap: Comparisons of DACA Eligible Sample Sizes vs. One's Reviewer
#| fig-width: 8
#| fig-height: 5
plots_more_like_reviewer[["Revision_of_Q18"]]
```


```{r}
#| label: fig-like-your-reviewer-non-data
#| fig-cap: Comparisons of DACA Non-Eligible Sample Sizes vs. One's Reviewer
#| fig-width: 8
#| fig-height: 5
plots_more_like_reviewer[["Revision_of_Q21"]]
```


## Analytic Choices {#sec-analytic}

The next two sections examine the different choices that researchers made, both to demonstrate the variation in ways that different researchers chose to carry out the research tasks, and to relate those choices to differences in outcomes.

Table \ref{tab-estimation-methods} shows the different choices made in estimating the effect of DACA on the probability of employment across all three tasks, in particular the estimator chosen, the use of ACS sampling weights provided by IPUMS, and the choice of standard error adjustment.[^20] The dependent variable of interest, working full-time or not, is binary. However, as is generally standard in applied microeconomics, linear regression was the most common estimator used, with 82% of entries. 13% used logit or probit regression instead. Notably, many reserachers used linear regression as a means of implementing a fully saturated (or nearly fully saturated) difference-in-differences design, in which case the downsides of linear probability models are muted. Other researchers mostly used a matching estimator (sometimes combined with linear regression) or one of several newly-introduced estimators for difference-in-differences designs, like @callaway2021difference.

[^20]: For most researchers, these choices did not change over the tasks, and so we just present the overall view.

The use of sample weights was relatively uncommon, despite their use being advised with survey data like ACS. Only 25% of task completions mentioned the use of weights or any of the standard ACS weight variables.

There was considerable variation across researchers in the selection of standard error adjustment. A slim majority of researchers applied clustered standard errors in some way, but clustered at different levels: state, state/year, or according to a survey clustering indicator like Strata or some other variable. A further 17% of submissions used heteroskedasticity-robust but not cluster-robust standard errors.

```{r}
#| output: asis

base %>%
  mutate(se_adjustment = factor(se_adjustment, levels = c(
    'Cluster (State)',
    'Cluster (State & Year)',
    'Cluster (ID/Strata/Other)',
    'Het-Robust',
    'Other/Bootstrap',
    'None'
  ))) %>%
  filter(!(round %like% 'Revision')) %>%
  sumtable(vars = c('method','Weights','se_adjustment'), 
         labels = c("Method",'Weights','S.E. Adjustment'),
         title = "Estimation Methods",
         col.breaks = 2,
         note = '\\begin{tabular}[x]{@{}r@{}}This table shows details on estimation, not research design. "Difference-in-differences" \\\\ implemented with linear regression, for example, counts here as linear regression.\\end{tabular}',
         out = 'latex',
         anchor = 'tab-estimation-methods')
```

Table \ref{tab-controls-across-rounds} shows the average rate of inclusion of covariates across all three tasks, as well as the estimated effects among analyses including those controls, shown in the order of average effect size. The average rate of inclusion can be read as the share of researchers who included the covariate, with the exception of "Other", which allows each researcher to have multiple "Other" controls. The most common covariates included are shown, with the exception of indicators for "eligible for DACA" or "in a post-DACA period", as these are considered part of the core research design rather than covariates. Variables are included here regardless of the functional form used to include them.

The most common included controls were for state, year, age, and sex, which were included as covariates for more than 50% of researchers in all three tasks. However, there was a large amount of variation in the sets of included covariates. In Task 1, for example, there are ten covariates with rates between .2 and .8, meaning that at least 20% of the researchers made a different decision on inclusion of the covariate than the majority. There are four covariates in the 40-60% range, meaning that the researchers were almost evenly split on whether or not to include the covariate. These rates did not change much by Task 3.

Across all rounds, in which there were `r 3*145` submitted research tasks, there were `r exact_matches[, .N]` different unique sets of included covariates after "Other" covariates are excluded. `r percent(exact_matches[numpairs == 1, sum(numpairs)]/sum(exact_matches$numpairs))` of submissions had a set of covariates that was unique for the task. `r percent(exact_matches[numpairs == 2, sum(numpairs)]/sum(exact_matches$numpairs))` shared a covariate set with one other person in that task, `r percent(exact_matches[numpairs %in% c(3,4), sum(numpairs)]/sum(exact_matches$numpairs))` shared with two or three other people, and only the those with no controls shared with more than three other people.

```{r}
# Average appearances across rounds
controls_across_rounds[, .(Control, `Rate in Task 1` = `Task 1`, `Task 2`, `Task 3`)] |>
  merge(effects_by_controls[, .(Control, Effect, `Mean SE`, `Effect SD`)], by = 'Control') |>
  setorder(-Effect) |>
  knitr::kable(booktabs = TRUE, 
               caption = 'Covariate Inclusion Across Rounds and Estimated Effects \\label{tab-controls-across-rounds}')
```

There was very little agreement across researchers on the exact set of appropriate controls, or the inclusion or exclusion of any given control (aside from those very rarely included). Did these choices impact the effect estimates? Not by much. The mean reported effects differ by only .023 percentage points comparing the covariate included in analyses with the highest average effectestimates (Continuous Years in the USA) against the lowest (Race). This likely overstates the impact of covariate selection here, as selecting the highest vs. lowest after estimates are known will bias us towards a larger difference from noise alone.

There do not appear to be major differences in the average reported standard errors either, or in the standard deviation of the effect distribution among reserachers including that covariate.

While the inclusion of a given common control variable does not strongly predict an estimated effect, in Table \ref{tab-effects-by-functional-form} we look at the most common covariates and examine whether their functional form meaningfully affects the estimated effect. The selection of functional form explained more variation in average estimated effects than the inclusion of covariates did, at least in this context. For both age and the State/Year controls, the difference between the highest-average-effect functional form variants and the lowest, in both cases comparing a linear control against a fixed effect, was greater than the difference between highest and lowest among covariates included.

```{r}
trans_con[, .(N = uniqueN(paste0(Q1,Round)),
                Effect = number(mean(Effect, na.rm = TRUE), .001),
                `Mean SE` = number(mean(SE, na.rm = TRUE), .001),
                `Effect SD` = number(sd(Effect, na.rm = TRUE), .001)),
            by = .(Category = category, Control = Relabel)][order(Control)] |>
  knitr::kable(booktabs = TRUE,
               caption = 'Estimated Effects by Functional Form of Control Variable \\label{tab-effects-by-functional-form}')
```

These specific findings about the impact of choices on effects - that the inclusion of different covariates did not have a major impact on estimated effects, or that the choice of functional form had a greater impact than the selection of covariates - should not be expected to generalize, and is specific to this research task. However, what we can take from this section is that there is substantial variation across researchers in what they believe the appropriate set of covariates to be and, for a given covariate, what the appropriate functional form is. We can also see that, in the case of this particular study, these decisions, while varied, did not fully explain the variation in effects between researchers.

## Sample Limitations {#sec-sample-limitations}

In this section we examine the ways in which researchers defined their analytic samples, as well as how they defined the treated group. For these analyses, Task 3 is omitted because the analytic sample and treated group are defined for all researchers. 

Table \ref{tab-number-of-sample-limitations} uses researcher survey responses about their sample definitions and looks purely at the number of distinct variables referenced in the sample limitations, regardless of what they are. In Task 1, the typical researcher used five variables to define their analytic sample, and an additional four to define their treated group. In Task 2, where inclusion criteria were shared, both of these numbers increased, but there was still considerable variation, with the 25th and 75th percentiles using 3 and 10 variables to define their full sample. Definition of the treated group was more shared, with the 25th and 75th percentiles using 9 and 12 variables, respectively.

```{r}
#| output: asis
# Basic sample limitations table
sumtable(basic_samp_limitations, vars = c('Whole Sample','Treated Group','Untreated Group'), add.median = TRUE, group = 'Round', group.long = TRUE, title = 'Number of Variables Referred to in Sample Limitations', anchor = 'tab-number-of-sample-limitations',
         out = 'latex', numformat = formatfunc(digits=2, nsmall = 1))
```

Table \ref{tab-sample-limitations-extensive} shows how these variables were implemented as sample restrictions, based on actual researcher code. This is the only section of the paper where the data do not rely on researcher responses to the survey. For each researcher's Task 1 and Task 2 code, organizers read the code directly and recorded some aspects of the sample definitions used for the overall analytic sample and for the definition of the treated group, including definitions that appeared to be the result of coding errors.[^21] 

XXX NOTE FOR CLAUS: SHOULD WE DROP MULTISTEP CONDITION ALTOGETHER AND JUST GROUP THEM IN WITH OTHER?

[^21]: Other notes of interest for reading the table: (a) "Multistep condition" refers to cases where the variable is included, but only as a part of a complex boolean statement involving many variables. These most commonly appeared in definitions for the comparison group, which are not in the table, in the format of "fails any one of the following set of DACA eligibility requirements," (b) for Education/Veteran status, recall that the mention of this eligibility requirement was omitted from the Task 1 instructions, which explains why very few researchers used these variables to define their samples or treated groups in Task 1, and (c) all categories listed in the table refer to filtering the data in the exact same way with the exceptions of "Other" and "Multistep Condition" which both refer to a wide range of unique conditions, Year-Quarter Age and Year-Only Age, where any usage of year-quarter or year-only age in 2012 are grouped together, Used YRSUSA, where any usage of YRSUSA is grouped together, and "Hispanic-Any", which groups together the IPUMS conditions "HISPAN > 0" (which allows for someone to be both Hispanic and another race) and "RACHSING == 5" (which does not).

The coding does not cover the full set of possible variables used to define samples, which vary beyond the list presented in the table. Some common limitations used by some researchers and not others include filtering out people living in group quarters or those out of the labor force, or dropping anyone with a recorded year of immigration before their recorded year of birth. Many researchers also chose to limit the sample based on current age as of the year of their inclusion in the ACS (as opposed to their age in 2012, which is shown), choosing many different acceptable age ranges. Table \ref{tab-sample-limitations-extensive} looks only at limitations based on variables for which there is a ``right answer'' in the Task 2 instructions. 

We see a huge amount of variety in the ways these variables were used, including in Task 2, where there is a correct answer according to the instructions (and similarly a correct answer for some variables in the Task 1 treated-group definition).[^22] For each variable, the most-common option, listed at the top, is the "correct" answer for defining the treated group, with two exceptions: (a) for Citizenship, there is a second justifiable answer in "Non-Citizen or Naturalized After 2012." These immigrants would have been eligible for DACA in 2012, but would not be eligible for DACA as of the time they were surveyed, so they would have received a partial "dose" of DACA, which could justifiably be included or excluded, and (b) for Years Continuous in USA, where DACA guidelines require that the immigrant have lived *continuously* in the United States for five years as of 2012. Most researchers used only year of immigration being before 2007 to satisfy this criterion, but others used the YRSUSA set of variables which specifically track living continuously in the country.

[^22]: Keep in mind that the table allows for coding errors. For example the individuals reporting that they used only high school graduates or *non-veterans,* instead of veterans as per the instructions, likely did not intentionally choose to use non-veterans but rather coded "VETSTAT == 1," which indicates "non-veteran", perhaps based on a misunderstanding of the IPUMS documentation (veterans are VETSTAT == 2). However, an earlier version of this paper relied on researcher self-reports of sample limitations in the survey, and found similar rates at which Task 2 choices did not match the "correct answer", so coding errors alone do not account for these results.

For all other variables besides Years Continuous in USA, the option matching the instructions was the most common, but we also see plenty of variation. We also see considerable variation for the columns in which there is not a clear "correct" option, like the analytic sample definition. No single way of applying any variable was used by more than 84% of the sample in any case. One interesting feature is the use of both "\< 16" and "\<= 16" for age at migration, and "\< 2007" and "\<= 2007" for year of migation. For year of migration, the two are similarly popular. Also interesting is the distinction between researchers using age defined in years to determine eligibility vs. age defined in quarters, which makes a difference given that eligibility is based on age specifically in June 2012.

```{r}
#| output: asis
# Variables used in limitations
sumtable(r12samp, titles, group = 'Round/Sample',
         out = 'latex',
         fit.page = '.75\\textwidth',
         anchor = 'tab-sample-limitations-extensive',
         note = 'Multistep condition means the variable is one part of a complex boolean involving many different variables.',
         title = 'Sample Restriction Methods')
```

Showing the impact of these choices on estimated effects is difficult since, aside from the most-common option, any specific alternative does not have enough people using it to make a reasonable comparison. However, we show estimated effects and, for analytic-sample restrictions, analytic sample size by sample limitation choice in Appendix Tables \ref{tab-task1effectsample-full} for Task 1 and Table \ref{tab-task2effectsample-full} for Task 2. There are large differences in estimated effects and sample sizes across many of these different sample restriction choices, but in many cases these comparisons are based on very small samples.

The two comparisons for which an alternative was common enough to compare are for the YRSUSA inclusion and the use of "\< 2007" vs. "\<= 2007" for year of migration, which are shown in \ref{tab-task1effectsample}. For both tasks, the relationship between these choices on effects varies from negligible to a several percentage-point difference associated with a single sample restriction change, a fairly minor one in particular for "\< 2007" vs. "\<= 2007". Effect differences are larger in Task 2. However, in Task 1, even though estimated effects are similar, sample sizes are considerably larger for the less-restrictive option, and so reported standard errors would be lower, and statistical significance more likely.

```{r}
#| output: asis
# sample limitations and effects/samples, task 1
t1efftab = make_efftab(r12samp[Round == 'Task 1'])[Variable %in% c('HEADERROW', 'Year of Immigration','... < 2007','... <= 2007','Years Continuous in USA','... Used YRSUSA','... No YRSUSA')]
t2efftab = make_efftab(r12samp[Round == 'Task 2'])[Variable %in% c('HEADERROW', 'Year of Immigration','... < 2007','... <= 2007','Years Continuous in USA','... Used YRSUSA','... No YRSUSA')]
hrow1 = data.table(a1 = 'Task 1', a2 = '',
                   a3 = '', a4 = '', a5 = '', a6 = '',
                   a7 = '', a8 = '', a9 = '', a10 = '')
setnames(hrow1, names(t1efftab))
hrow2 = data.table(a1 = 'Task 2', a2 = '',
                   a3 = '', a4 = '', a5 = '', a6 = '',
                   a7 = '', a8 = '', a9 = '', a10 = '')
setnames(hrow2, names(t1efftab))
t1efftab = rbindlist(list(t1efftab[1],
                    hrow1,
                     t1efftab[2:.N],
                    hrow2,
                    t2efftab[2:.N]))

cat(dftoLaTeX(t1efftab,
          align = 'llllllllll',
            title = 'Task 1 Effect and Samples by Sample Definitions',
            anchor = 'tab-task1effectsample',
            fit.page = '\\textwidth'))
```

## Researcher Characteristics and Effects {#sec-researcher-chars}

In this section we evaluate the relationship between researcher characteristics and the effects they reported. As in our preregistration, analysis in this section is performed in a muliple-analysts style, with the two project organizers taking the same data and research question and performing independent analyses.[^23]

[^23]: From the preregistration: "Both primary authors will, independently, analyze the relationship between (a) researcher characteristics and reported research results in earlier stages, and (b) attrition from the study and reported research results in later stages." Because there was so little attrition from the study after Task 1, part b was dropped from the analysis. 

Full results from each project organizer can be found in Appendix B in order to preserve the multi-analyst nature of this section. The two project organizers took very different approaches to the question of how researcher characteristics affected results, selecting different dependent variables and methods of analysis, and different sets of researcher characteristics.

Both organizers found, however, that researcher characteristics were not strong predictors of estimated effects. Across researcher demographics, occupation, and professional experience, there was no strong relationship between researcher background and either the level of the effect estimate they reported, the deviation of their estimate from the mean, or changes in their estimate from task to task. The only relevant difference we found is that the minority of researchers who used the R programming language were more likely to report outlier estimates than researchers who used Stata.

# Conclusion

## Recommendations for Improved Practice

What do these results imply should change about the practice of applied microeconomic research?

To some degree, the findings of this paper do not reflect a problem to be solved. The fact that different researchers approach a problem differently is not in itself a problem, as long as any points of disagreement are visible to the reader and subject to scrutiny and disagreement, and the reader understands that a given study or set of research decisions is not the last word.

However, there is a problem to be solved to the extent that researcher variation reflects either (a) error, or (b) choices that are unexamined or invisible while also being something that researchers would choose differently.

In this study, we found considerable variation across researchers in the approaches taken to answering the main question in Task 1, which most closely reflects actual practice. While the distribution of effects did not considerably narrow from Task 1 to Task 2, the sample sizes did, as did the treated and comparison group definitions. Although we generally did not reject Levene tests of equal variance across rounds, descriptively there was an obvious narrowing of the distribution of effects. There was, in both rounds, a lot of variation in the set of covariates included, as well.

To the extent that these choices reflect research design and modeling choices, the problem is somewhat already addressed. Researchers are used to critiquing research design and modeling choices in public work. Because of this, we would expect that all of these choices would be reported in a writeup of research, where they could be critiqued. What would not typically occur is someone actually testing whether many of these alternate choices actually lead to different results, especially for seemingly more innocuous choices like covariate functional form, which was found in this study to be more consequential than the set of covariates included.

On the part of researcher practice, this set of results suggests the use of multiverse analysis [@steegen2016increasing], where the researcher considers every combination of reasonable modeling decisions and demonstrates their effects on estimated effects, or even many-analysts approaches to producing original work, as we did in @sec-researcher-chars. On the part of journals, this suggests that journals should consider accepting work that is a variation in the approach to a published work, even if that variation is not framed as a replication or rejection of the original study, currently a barrier to the publication of replications [@galiani2017incentives].

However, this study did not find that research design and modeling choices were the majority of explained researcher variation. Instead, this came in the form of data cleaning and preprocessing, including the selection of sample and the creation of variables indicating the treated group. Some of this variation could be classified as error, for example researchers in @sec-bimodal whose treated-group definition in Task 2 did not match the instructions. Other parts of this variation could be reasonable disagreement.

That much of the relevant variation seems to come along the lines of data cleaning and preprocessing is possibly unsurprising, given how this task is currently handled in economics. Relative to modeling and research design, data cleaning and preprocessing receive little attention. It is common for minor, or even important, details of data processing to be left off the description of methods in published papers. Data cleaning is also not formally taught in most graduate programs. A professor who would never allow a research assistant to decide their research design or model might be happy passing along the data cleaning task to an assistant, even though, as this paper shows, the task may be just as relevant to the results and just as prone to arbitrary choice-making.

Because data cleaning gets so little attention, it is perhaps to be expected that we saw the most variation here. Without formal training in PhD programs, or a culture of reviewing and critiquing data cleaning and preprocessing in research papers, there is little opportunity for researchers to *learn to do the same thing*, and so we see heavy variation. Contrast this to the popular use of linear probability models in Table \ref{tab-estimation-methods}, for example, which is common in applied microeconomics, especially in difference-in-differences designs. Because its use is very visible, researchers can see that it is the standard in the field. Whether or not it is actually the best method to use here, it is a method that researchers know has been agreed upon in the field. We see a similar story play out with standard error adjustments in the same table. The standard method by which economists learn data processing is on a much narrower scale, often from one's advisor or from others on a small research team.

This problem implies several possible policy solutions. Among broader system-wide changes, the introduction of data cleaning and preprocessing classes teaching methods and best practices in the standard PhD applied economics curriculum would likely improve the quality of economics research as well as reduce researcher variability. This presumes the existence of a set of best practices, or at least standard practices. So, an attempt should be made to codify and popularize a set of data-cleaning best practices, similar to how applied economists routinely learn about modeling best practices (for example any number of econometrics textbooks, or in the applied literature papers like @abadie2023should). Other fields have already made strides in this direction [e.g. @osborne2012best; @jafari2022hands] so this effort would not need to start from scratch, but would be improved by designing recommendations most relevant to an applied microeconomics context.

Those recommendations may not be in the control of any one researcher, though. The policy that this paper implies for individual researchers and journal editors or reviewers is that economics as a field should consider data cleaning and preprocessing to be just as much a part of the methods as the choice of model. Researchers should fully describe their data cleaning processes in their papers to the same level of detail that they describe their modeling choices. They should also perhaps subject any arbitrary data-cleaning decisions to multiverse analysis as well (note that this is also a suggestion of @steegen2016increasing). Further, an increasingly common requirement of journal submissions is to provide a replication package of the code used to perform a paper's analyses (for example @aeaguidelines). However, these replication packages often begin from an already-prepared data set, and only include the code necessary to run models. It would be advisable to include data preprocessing code in these replication packages.

## Discussion

This paper describes the results of a large many-analysts project in applied microeconomics. We found large amounts of variation in the choices made by researchers, especially in regards to data cleaning and processing, research design, the definition of treated and comparison groups, and the selection and functional form of controls. Some of this variation appears to be from researcher data cleaning processes that do not match the instructions, derived from policy realities, for constructing the treated group. Variation was not strongly constrained by the influence of peer review or a shared research design, but there was a (descriptive if not statistically significant) reduction of variation when researchers were provided with pre-cleaned data.

Interestingly, we do not find huge amounts of variation in actual estimated effects of the policy. There were some outliers, and statistical significance varied between researchers. However, the central range of estimated effects of DACA on the probability of working full time effects generally was not very wide, with the difference between the 25th and 75th percentiles typically only 2-3 percentage points. However, the fact that widely different sample definitions and modeling choices led to a narrow range of effects is not guaranteed to generalize to other contexts.

There were also parts where researchers behaved very similarly. The use of linear regression modeling was very popular, and very few researchers used unadjusted standard errors, although the specific adjustment or clustering level varied.

What we might learn from this study, and perhaps the wider world of studies on researcher variation, is perhaps obvious: in cases where there were well-acknowledged "standard" ways of doing something, like using linear modeling in a difference-in-differences-type setting with a binary outcome, or adjusting one's standard errors, researchers tended to do that thing. And where there was no well-acknowledged standard, like in the choice of clustering level, the selection of covariates in this particular setting, or in data cleaning, researchers behaved differently, sometimes to consequence and sometimes without it mattering much.

While researcher error also plays a part, the impact of the absence of standards is an emergent result from this study. Readers and practitioners of research should expect arbitrary variation in parts of research, like data cleaning, that do not have standards.

The development of best-practice standards in areas where we currently do not acknowledge them would be likely to improve applied microeconomics towards being a more mature, sophisticated, and believable field than it is today. We have highlighted data-cleaning practices as being an especially fruitful place to develop these standards, but the same applies in other areas as well like the level of clustering (an example of a place where development of consensus guidance is already underway in @abadie2023should). The optimal level of researcher variation is not zero, as individual researchers often have good reasons not to match the methods and practices used by others. But when this occurs, it should be because there *is* a good reason to deviate from the template, rather than because we have no template to begin with.

# References {.unnumbered}

::: {#refs}
:::

\FloatBarrier

\appendix

# Appendix {.unnumbered}

```{r}
#| label: fig-rdd
#| fig-cap: Impact of Guaranteed Payment on Probability of Task 1 Completion

rdplot(moneyatt$Finished,moneyatt$order,200,
       x.label = 'Order',y.label = 'Prob. Completed First Task',
       title = '', p = 2, binselect = 'espr')
```

```{r}
lin_rdd = feols(Finished ~ I(order-200)*I(order>200), data = moneyatt[Stage != 'Late'])
sq_rdd = feols(Finished ~ (I(order-200)+I((order-200)^2))*I(order>200), data = moneyatt[Stage != 'Late'])
msummary(list('Linear' = lin_rdd, 'Quadratic' = sq_rdd),
         stars = c('*' = .1, '**' = .05, '***' = .01),
                         gof_omit = c('IC|R2|RMSE|Err|AIC|BIC'),
         coef_map = c('(Intercept)' = 'Intercept',
                      'I(order > 200)' = 'Order above 200',
                      'I(order - 200)' = 'Linear order - 200',
                      'I((order-200)^2))' = 'Squared (order - 200)',
                      'I(order - 200):I(order > 200)' = 'Linear x Above',
                      'I((order - 200)^2):I(order > 200)' = 'Squared x Above'),
         output = 'kableExtra',
           title = 'Linear and Quadratic Regression Discontinuity Estimates\\label{tab-rdd-reg}', escape = FALSE)
```

```{r}
names(peer_review_reg) = c('Task 1','Task 2')
peer_review_reg |>
  msummary(stars = c('*' = .1, '**' = .05, '***' = .01),
                         gof_omit = c('IC|R2|RMSE|Err'),
           coef_rename = c('Intercept',
                           'Comparison: Next Round',
                           'Comparison: Next Round vs. This Round',
                           'Unreviewed',
                           'Next Round x Unreviewed',
                           'Next vs. This x Unreviewed'),
           output = 'kableExtra',
           title = 'Paired Absolute Effect Differences and Peer Review \\label{tab-peer-review-reg}', escape = FALSE)
```

```{r}
#| label: fig-effect-vs-sample
#| fig-cap: Task 2 Effect Size and Sample Size
p_sample_size_scatter
```

```{r}
#| label: fig-effect-vs-se
#| fig-cap: Task 2 Effect Size and Standard Error
p_standard_error_scatter
```

```{r}
#| label: tab-share-above-p5-by-control
# shtask |>
#   knitr::kable(booktabs = TRUE,
#                caption = 'Share of Effects Above .05 by Covariate Included')

```

```{r}
#| output: asis
# sample limitations and effects/samples, task 1
cat(dftoLaTeX(make_efftab(r12samp[Round == 'Task 1']),
          align = 'llllllllll',
            title = 'Task 1 Effect and Samples by Sample Definitions, Full View',
            anchor = 'tab-task1effectsample-full',
            fit.page = '\\textwidth'))
```

```{r}
#| output: asis
# sample limitationsand effects/samples, task 2
cat(dftoLaTeX(make_efftab(r12samp[Round == 'Task 2']),
          align = 'llllllllll',
            title = 'Task 2 Effect and Samples by Sample Definitions, Full View',
            anchor = 'tab-task2effectsample-full',
            fit.page = '\\textwidth'))
```

# Multi-Analyst Evaluation of Researcher Characteristics {.unnumbered}

## Analysis by Project Organizer A

For each categorical researcher characteristic specified in @sec-sample-characteristics, as well as an indicator for the use of R or Stata as a programming language. In each case, categories with 5 or fewer researchers in them were omitted before performing the analysis. Table \ref{tab-orga-effects} shows the F-statistic from a regression of the reported effect estimate on a set of indicators for that characteristic, as well as the associated $p$-value and $R^2$ from that regression. This table allows us to see whether researchers with different characteristics reported different effect levels. Table \ref{tab-orga-deviation} does the same, but uses absolute deviation from the sample mean as the dependent variable. This table allows us to see whether researchers with different characteristics showed greater agreement on effect levels with the group as a whole.

```{r}
res_tab_effect |>
  knitr::kable(booktabs = TRUE,
               caption = 'Predicting Effect Level with Researcher Characteristics\\label{tab-orga-effects}')
```

```{r}
res_tab_deviation |>
  knitr::kable(booktabs = TRUE,
               caption = 'Predicting Effect Deviation with Researcher Characteristics\\label{tab-orga-deviation}')
```

Tables \ref{tab-orga-effects} and \ref{tab-orga-deviation} show that researcher characteristics hold basically no explanatory power for estimated effects either in level or deviation from the mean. Nearly all $p$-values are well above .05. In \ref{tab-orga-deviation}, the $p$-value for race as an explanatory variable in Task 1 had a $p$-value below .1, but given how many comparisons there are here, this is likely to just be noise.

The only researcher characteristic that did seem to matter was the choice of programming language, which only weakly predicted effect level, but was a statistically significant predictor of being close to the mean effect in all three rounds.

```{r}
#| fig-cap: Deviation from Sample Mean of Reported Effect by Language
#| label: fig-deviations-by-language
#| fig-width: 8
#| fig-height: 6
p_deviations_by_language

# NOTE FOR WRITEUP: Of the big R outliers two people were in that category every round, and everyone else was only in there once.
```

@fig-deviations-by-language goes further into the split by language. We see that, of the two languages, Stata users were more likely to report effect estimates near the sample mean. 6.4%, 1.8%, and 0.9% of Stata users were more than .1 in absolute distance from the sample mean in Tasks 1, 2, and 3, respectively, while for R those values are 15.6%, 9.4%, and 12.5%. The number of R users is relatively low at 32,[^24] and so these numbers are sensitive to any researchers who were consistently outliers. There were two R users who had an absolute deviation from the mean of .1 or more every round, while all other R researchers with deviations of .1 or more only had deviations that large in a single round. If we omit those two consistently-high-deviation R users, the percentages are 10%, 3.3%, and 6.7% for R users, which are still higher than the percentages for Stata users.

[^24]: This is one lower than the value reported in @sec-sample-characteristics because the researcher who was dropped from analysis, mentioned later in @sec-sample-characteristics, was an R user.

Overall, there is little role for researcher professional or demographic characteristics in predicting either the level of the effects they reported, or the deviation of those effects from the mean. There is some explanatory power for the choice of programming language. R users were more likely than Stata users to report estimates far from average of what other users reported.

## Analysis By Project Organizer B

Table \ref{tab-researcher-characteristics-regs-b} looks at within-researcher variation in effect estimates across tasks. In the first three columns, the dependent variable is the absolute difference in effects for a given researcher across two tasks, while in the fourth column, the dependent variable is a researcher's maximum estimated effect minus their minimum.

```{r}
modelsummary(researcher_characteristics_models_b, 
             coef_map = c(
               '(Intercept)' = 'Intercept',
               'factor(position)Faculty' = 'Faculty',
               'factor(position)Grad student' = 'Grad student',
               'factor(position)Uni researcher' = 'Uni researcher',
               'factor(position)Other' = 'Other',
               'factor(position)Private researcher' = 'Private researcher',
               'factor(position)Public researcher' = 'Public researcher',
               'factor(degree)PhD' = 'PhD',
               'factor(degree)Not PhD' = 'Not PhD',
               'factor(experience)6+ papers' = '6+ papers',
               'factor(experience)1-5 papers' = '1-5 papers',
               'factor(experience)0 papers' = '0 papers'
             ),
             stars = TRUE,
             output = 'kableExtra',
             title = "Model Coefficients and Standard Errors for Task Comparisons\\label{tab-researcher-characteristics-regs-b}",
             gof_omit = '^(?!R2|Num.Obs)',
             escape = FALSE
)
```

Most researcher characteristics do not predict absolute within-researcher variation. Career stage, occupation, and number of published papers do not predict absolute differences in estimates across tasks to a statistically significant degree, with few exceptions.

One exception is that private researchers saw larger absolute changes between Task 1 and Task 3, and also more absolute variation overall, although the latter is only significant at the $\alpha = .1$ level. Probably the most interesting is that inexperience was related to smaller changes from Task 1 to Task 3: those who do not have a PhD showed a smaller change between Task 1 and Task 3 (significant at $\alpha = .1$), and those with fewer papers also showed smaller absolute changes than those with 6+ papers (insignificant).
